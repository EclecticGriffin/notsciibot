{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=======================================#\n",
    "# Yes, this notebook is over-commented. #\n",
    "#=======================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make notebook span entire screen, horizontally.\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================#\n",
    "# Utility functions #\n",
    "#===================#\n",
    "\n",
    "def process_rewards(rewards, decay, norm=True):\n",
    "        discounted = np.zeros_like(rewards)\n",
    "        running_reward = 0\n",
    "        \n",
    "        for idx in reversed(range(len(rewards))):\n",
    "            running_reward += rewards[idx]\n",
    "            running_reward *= decay\n",
    "            discounted[idx] = running_reward\n",
    "            \n",
    "        if norm:\n",
    "            discounted -= np.mean(discounted)\n",
    "            if np.std(discounted) != 0:\n",
    "                discounted /= np.std(discounted)\n",
    "\n",
    "        return discounted.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyAgent(object):\n",
    "    def __init__(self, sess):\n",
    "        self.num_actions = 4\n",
    "        self._build()\n",
    "        self.sess = sess\n",
    "        \n",
    "    def _build(self):\n",
    "        self.actions      = tf.placeholder(tf.int32, (None, 1))\n",
    "        self.columns      = tf.placeholder(tf.int32, (None, 1))\n",
    "        self.e_encr       = tf.placeholder(tf.float32)\n",
    "        self.e_dscr       = tf.placeholder(tf.float32)\n",
    "        self.l_rate       = tf.placeholder(tf.float32)\n",
    "        self.observations = tf.placeholder(tf.float32, (None, 8))\n",
    "        self.target       = tf.placeholder(tf.float32, (None, 1))\n",
    "        self.training     = tf.placeholder(tf.bool)\n",
    "        \n",
    "        with tf.variable_scope('actor-hidden'):\n",
    "            h1    = tf.layers.dense(self.observations, 128, \n",
    "                                    activation=tf.nn.relu, \n",
    "                                    kernel_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                                    name='h1')\n",
    "            \n",
    "            drop1 = tf.layers.dropout(h1, training=self.training, name='drop1')\n",
    "            \n",
    "            h2    = tf.layers.dense(drop1, 64,\n",
    "                                    activation=tf.nn.relu, \n",
    "                                    kernel_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                                    name='h2')\n",
    "            \n",
    "            drop2 = tf.layers.dropout(h2, training=self.training, name='drop2')\n",
    "            \n",
    "            h3    = tf.layers.dense(drop2, 64,\n",
    "                                    activation=tf.nn.relu, \n",
    "                                    kernel_initializer=tf.contrib.layers.xavier_initializer(), \n",
    "                                    name='h3')\n",
    "            \n",
    "            drop3 = tf.layers.dropout(h3, training=self.training, name='dropout')\n",
    "        \n",
    "            self.out = tf.layers.dense(drop3, self.num_actions,\n",
    "                                       kernel_initializer=tf.random_normal_initializer(), \n",
    "                                       kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.1),\n",
    "                                       name='out')\n",
    "        \n",
    "        # Compute probabilities associated with each action.\n",
    "        self.probabilities = tf.clip_by_value(tf.nn.softmax(self.out), 1e-10, 1.0)\n",
    "        \n",
    "        # Compute entropy based on action probabilities.\n",
    "        self.entropy = -tf.reduce_sum(self.probabilities * tf.log(self.probabilities), 1, name=\"entropy\")\n",
    "        \n",
    "        # Compute losses of action probabilities associated with each observation in a single batch.\n",
    "        indices = tf.concat(values=[self.columns, self.actions], axis=1)\n",
    "        self.picked_action_prob = tf.gather_nd(self.probabilities, indices)\n",
    "        min_max_punishment = tf.reduce_max(self.probabilities,axis=1) - tf.reduce_min(self.probabilities,axis=1)\n",
    "        min_max_weight = tf.reduce_max(self.out, axis=1) - tf.reduce_min(self.out, axis=1)\n",
    "        self.losses = -tf.log(self.picked_action_prob) * self.target - self.entropy * self.e_encr \\\n",
    "                        + min_max_punishment * min_max_weight*10\n",
    "        #self.losses = -tf.log(self.picked_action_prob) * self.target + tf.losses.get_regularization_loss()\n",
    "        \n",
    "        # Compute batch loss.\n",
    "        self.loss = tf.reduce_mean(self.losses)\n",
    "        \n",
    "        # Set optimizer.\n",
    "        self.train_op = tf.train.RMSPropOptimizer(self.l_rate).minimize(self.loss)\n",
    "    \n",
    "    # NOTE: computing `out` from `self.out` is not necessary -- just for debugging\n",
    "    def choose_action(self, obs, verbose=False):\n",
    "        # Compute probabilities associated with each action and output layer node values.\n",
    "        out, probs, ent = self.sess.run([self.out, self.probabilities, self.entropy], feed_dict={\n",
    "            self.observations: np.array(obs).reshape(-1, 8),\n",
    "            self.training:     False\n",
    "        })\n",
    "        \n",
    "        if verbose: print(probs, out, ent)\n",
    "            \n",
    "        # Choose action based on computed probabilities.\n",
    "        return np.random.choice(range(probs.shape[1]), p=probs.ravel())\n",
    "    \n",
    "    def train(self, act, obs, target, l_rate, e_encr, e_dscr):\n",
    "        length = np.array(act).reshape(-1, 1).shape[0]\n",
    "        \n",
    "        inp = (self.train_op, self.loss, self.probabilities, self.entropy, self.out)\n",
    "        \n",
    "        _, *results = self.sess.run(inp, feed_dict={\n",
    "            self.actions:      np.array(act).reshape(-1, 1),\n",
    "            self.columns:      np.arange(length).reshape(-1, 1),\n",
    "            self.e_encr:       e_encr,\n",
    "            self.e_dscr:       e_dscr,\n",
    "            self.l_rate:       l_rate,\n",
    "            self.observations: np.array(obs).reshape(-1, 8),\n",
    "            self.target:       np.array(target).reshape(-1, 1),\n",
    "            self.training:     True\n",
    "        })\n",
    "        \n",
    "        # print('-' * 32)\n",
    "        # print('\\n'.join(results))\n",
    "        # print('-' * 32)\n",
    "\n",
    "        return results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(object):\n",
    "    def __init__(self, sess):\n",
    "        self.sess = sess\n",
    "        self._build()\n",
    "        \n",
    "    def _build(self):\n",
    "        self.l_rate       = tf.placeholder(tf.float32)\n",
    "        self.observations = tf.placeholder(tf.float32, (None, 8))\n",
    "        self.target       = tf.placeholder(tf.float32, (None, 1))\n",
    "        self.training     = tf.placeholder(tf.bool)\n",
    "        \n",
    "        with tf.variable_scope('critic-hidden'):\n",
    "            h1    = tf.layers.dense(self.observations, 128,\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                    name='h1')\n",
    "            \n",
    "            drop1 = tf.layers.dropout(h1, name='drop1', training=self.training)\n",
    "            \n",
    "            h2    = tf.layers.dense(drop1, 64,\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                    name='h2')\n",
    "            \n",
    "            drop2 = tf.layers.dropout(h2, name='drop2', training=self.training)\n",
    "            \n",
    "            out   = tf.layers.dense(drop2, 1,\n",
    "                                    kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                    name='out')\n",
    "            \n",
    "        self.value_estimate = tf.squeeze(out) # [[num]] -> num\n",
    "        self.losses = tf.squared_difference(self.value_estimate, self.target)\n",
    "        self.loss = tf.reduce_mean(self.losses)\n",
    "        self.train_op = tf.train.AdamOptimizer(self.l_rate).minimize(self.loss)\n",
    "        \n",
    "    def predict(self, obs):\n",
    "        return sess.run(self.value_estimate, feed_dict={\n",
    "            self.observations: np.array(obs).reshape(-1, 8),\n",
    "            self.training:     False\n",
    "        })\n",
    "    \n",
    "    def update(self, obs, target, l_rate=0.01):\n",
    "        inp = (self.train_op, self.loss)\n",
    "        \n",
    "        _, *results = self.sess.run(inp, feed_dict={\n",
    "            self.l_rate:       l_rate,\n",
    "            self.observations: np.array(obs).reshape(-1, 8),\n",
    "            self.target:       np.array(target).reshape(-1, 1),\n",
    "            self.training:     True\n",
    "        })\n",
    "        \n",
    "        return results[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACHandler(object):\n",
    "    def __init__(self, actor, critic, env, sess, path='./.model.ckpt'):\n",
    "        self.actor = actor\n",
    "        self.critic = critic\n",
    "        self.env = env\n",
    "        self.sess = sess\n",
    "    \n",
    "        self.saver = tf.train.Saver()\n",
    "        self.path = path\n",
    "\n",
    "    def init_vars(self):\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def run(self, train_func, rollout=100, a_rate=0.001, c_rate=0.005, decay=0.99, render=False, e_encr=0.007, e_dscr=0.01, **kwargs):\n",
    "        assert isinstance(train_func, str) and train_func.startswith('train_'), \\\n",
    "               'invalid train_func name specified'\n",
    "        getattr(self, train_func)(self.rollout(rollout, render, decay), a_rate, c_rate, e_encr, e_dscr, **kwargs)\n",
    "        \n",
    "        # Close the display window\n",
    "        if render: self.env.close()\n",
    "            \n",
    "    def run_constant_training(self, num_episodes, a_rate=0.001, c_rate=0.005, decay=0.99, e_encr=0.007, e_dscr=0.01, render=False, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs training and updates both networks during every time step\n",
    "        \"\"\"\n",
    "        \n",
    "        for _ in range(num_episodes):\n",
    "            obs_curr = env.reset()\n",
    "            done = False\n",
    "\n",
    "            if verbose:\n",
    "                rewards = 0\n",
    "                a_episode_loss = []\n",
    "                c_episode_loss = []\n",
    "            \n",
    "            while not done:\n",
    "\n",
    "                if render: self.env.render()\n",
    "                action = self.actor.choose_action(obs_curr)\n",
    "\n",
    "                # Take action in environment.\n",
    "                next_obs, reward, done, _ = self.env.step(action)\n",
    "\n",
    "                next_estimate = self.critic.predict(next_obs)\n",
    "                td_target = reward + decay * next_estimate\n",
    "                td_error = td_target - self.critic.predict(obs_curr)\n",
    "                c_loss = self.critic.update(obs_curr, td_target, c_rate)\n",
    "                a_loss = self.actor.train(action, obs_curr, td_error, a_rate, e_encr, e_dscr)\n",
    "                \n",
    "                if verbose:\n",
    "                    rewards += reward\n",
    "                    a_episode_loss.append(a_loss)\n",
    "                    c_episode_loss.append(c_loss)\n",
    "\n",
    "                obs_curr = next_obs\n",
    "                \n",
    "            if verbose:\n",
    "                print('Actor Loss: {0:5f}'.format(np.mean(a_episode_loss)), end='; ')\n",
    "                print('Critic Loss: {0:5f}'.format(np.mean(c_episode_loss)), end='; ')\n",
    "                print('Reward: {0:5f}'.format(rewards))\n",
    "                \n",
    "    def play(self, verbose=False):\n",
    "        \"\"\"\n",
    "        Runs a single instance of the game without training or storing training information\n",
    "        Always displays the game and closes the window afterward\n",
    "        \"\"\"\n",
    "        obs_curr = self.env.reset()\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            self.env.render()\n",
    "\n",
    "            # Agent chooses action based on difference frame.\n",
    "            action = self.actor.choose_action(obs_curr, verbose=verbose)\n",
    "\n",
    "            # Take action in environment.\n",
    "            obs_curr, reward, done, _ = self.env.step(action)\n",
    "            \n",
    "        env.close()\n",
    "        \n",
    "    def train_rsample(self, batch, a_rate, c_rate, e_encr, e_dscr, num_epochs=50, mini_batch_size=100):\n",
    "        \"\"\"\n",
    "        Performs random mini-batch training on both networks from a given\n",
    "          set of batch information\n",
    "        \"\"\"\n",
    "        for x in range(num_epochs):\n",
    "            indices = np.random.randint(len(batch['obs']), size=mini_batch_size)\n",
    "            loss = self.actor.train([batch['act'][i] for i in indices],\n",
    "                             [batch['obs'][i] for i in indices],\n",
    "                             [batch['advantage'][i] for i in indices],\n",
    "                             a_rate,\n",
    "                             e_encr,\n",
    "                             e_dscr)\n",
    "            self.critic.update([batch['obs'][i] for i in indices],\n",
    "                               [batch['td_target'][i] for i in indices],\n",
    "                               c_rate)\n",
    " \n",
    "    def train_all(self, batch, a_rate, c_rate, e_encr, e_dscr, verbose=False):\n",
    "        \"\"\"\n",
    "        Trains both networks on all peices of inromation in the batch\n",
    "        \"\"\"\n",
    "        a_loss = self.actor.train(batch['act'],\n",
    "                         batch['obs'],\n",
    "                         batch['advantage'],\n",
    "                         a_rate,\n",
    "                         e_encr,\n",
    "                         e_dscr)\n",
    "        c_loss = self.critic.update(batch['obs'],\n",
    "                           batch['td_target'],\n",
    "                           c_rate)\n",
    "        \n",
    "        if verbose:\n",
    "            print('Actor Loss: {:14.7f}'.format(a_loss), end='; ')\n",
    "            print('Critic Loss: {:14.7f}'.format(c_loss), end='; ')\n",
    "            print('Batch Reward: {:14.7f}'.format(batch['avg_rew']))\n",
    "    \n",
    "    def compute_advantage(self, obs, rewards, decay):\n",
    "        disc_rewards = process_rewards(rewards, decay, norm=False)\n",
    "\n",
    "        policy_target = np.zeros_like(disc_rewards)\n",
    "        value_target = np.zeros_like(disc_rewards)\n",
    "        running_reward = 0\n",
    "\n",
    "        for idx in range(len(disc_rewards)):\n",
    "            estimate = self.critic.predict(obs[idx])\n",
    "            td_target = disc_rewards[idx]\n",
    "            td_error = td_target - estimate\n",
    "\n",
    "            \n",
    "            policy_target[idx] = td_error\n",
    "            value_target[idx] = td_target\n",
    "        \n",
    "        return policy_target.tolist(), value_target.tolist()    \n",
    "\n",
    "    def save(self):\n",
    "        self.saver.save(self.sess, self.path)\n",
    "        \n",
    "    def load(self):\n",
    "        self.saver.restore(self.sess, self.path)\n",
    "            \n",
    "    def rollout(self, count, render, decay):\n",
    "        batch = {'act': [], 'obs': [], 'rew': [], 'advantage':[], 'td_target':[]}\n",
    "        rewards = 0\n",
    "        \n",
    "        for episode in range(count):\n",
    "            # Stores all the stuff\n",
    "            history = {'act': [], 'obs': [], 'rew': [], 'advantage':[], 'td_target':[]}\n",
    "            \n",
    "            obs_curr = env.reset()\n",
    "            done = False\n",
    "\n",
    "            while not done:\n",
    "                \n",
    "                if render: self.env.render()\n",
    "                # Agent chooses action based on difference frame.\n",
    "                action = self.actor.choose_action(obs_curr, False)\n",
    "        \n",
    "                # Take action in environment.\n",
    "                next_obs, reward, done, _ = self.env.step(action)\n",
    "                \n",
    "                history['act'].append(action)\n",
    "                history['obs'].append(obs_curr)\n",
    "                history['rew'].append(reward)\n",
    "                \n",
    "                rewards += reward\n",
    "                \n",
    "                obs_curr = next_obs\n",
    "\n",
    "            # Process rewards per episode.\n",
    "            history['advantage'], history['td_target'] = self.compute_advantage(history['obs'] + obs_curr, history['rew'], decay)\n",
    "            \n",
    "            # Add episode to batch.\n",
    "            for key in batch:\n",
    "                batch[key].extend(history[key])\n",
    "                \n",
    "        batch['avg_rew'] = rewards / count\n",
    "        \n",
    "        return batch\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "env = gym.make('LunarLander-v2') # RGB observation space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "actor = PolicyAgent(sess)\n",
    "critic = Critic(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = ACHandler(actor, critic, env, sess, '.models/l1.cpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.init_vars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    for _ in range(100):\n",
    "        handler.run('train_rsample', render=True)\n",
    "        print('-',end='')\n",
    "    print('\\nCompleted 100 Training Iterations\\n')\n",
    "    handler.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:     14.2725716; Critic Loss:   6674.8085938; Batch Reward:   -182.7051531\n",
      "Actor Loss:      7.7797799; Critic Loss:   4844.3916016; Batch Reward:   -164.1492123\n",
      "Actor Loss:      2.8584499; Critic Loss:   5623.4047852; Batch Reward:   -177.5454094\n",
      "Actor Loss:     -3.4049821; Critic Loss:   5042.0375977; Batch Reward:   -177.1636169\n",
      "Actor Loss:    -12.2737789; Critic Loss:   5371.4853516; Batch Reward:   -176.9775272\n",
      "Actor Loss:    -19.4657402; Critic Loss:   5300.9829102; Batch Reward:   -179.8123028\n",
      "Actor Loss:    -28.8472519; Critic Loss:   4514.5292969; Batch Reward:   -191.3567105\n",
      "Actor Loss:    -43.9192963; Critic Loss:   4272.0781250; Batch Reward:   -184.4519796\n",
      "Actor Loss:    -62.4619446; Critic Loss:   4082.3461914; Batch Reward:   -188.1801007\n",
      "Actor Loss:    -80.9830704; Critic Loss:   3399.4272461; Batch Reward:   -190.5290059\n",
      "Actor Loss:   -105.0353394; Critic Loss:   2769.9719238; Batch Reward:   -190.2266706\n",
      "Actor Loss:   -147.8627319; Critic Loss:   2968.5644531; Batch Reward:   -199.9840033\n",
      "Actor Loss:   -173.0115356; Critic Loss:   3157.1469727; Batch Reward:   -220.5773160\n",
      "Actor Loss:   -242.4103241; Critic Loss:   4235.6625977; Batch Reward:   -252.7900150\n",
      "Actor Loss:   -327.1149292; Critic Loss:   3767.5544434; Batch Reward:   -265.6511493\n",
      "Actor Loss:   -396.0187988; Critic Loss:   4018.2229004; Batch Reward:   -283.3055074\n",
      "Actor Loss:   -534.5981445; Critic Loss:   3406.5153809; Batch Reward:   -270.5070406\n",
      "Actor Loss:   -686.1452026; Critic Loss:   3765.7600098; Batch Reward:   -330.9258201\n",
      "Actor Loss:   -729.4199829; Critic Loss:   6692.7993164; Batch Reward:   -182.0955202\n",
      "Actor Loss:   -810.8412476; Critic Loss:   4740.9697266; Batch Reward:   -393.9605724\n",
      "Actor Loss:   -780.0027466; Critic Loss:   6307.6884766; Batch Reward:   -172.4788702\n",
      "Actor Loss:   -804.3311768; Critic Loss:   2475.7148438; Batch Reward:   -288.5014845\n",
      "Actor Loss:   -803.7269287; Critic Loss:   3205.9453125; Batch Reward:   -326.5840181\n",
      "Actor Loss:   -734.6360474; Critic Loss:   3232.5866699; Batch Reward:   -285.6172395\n",
      "Actor Loss:   -770.0714722; Critic Loss:   2356.1311035; Batch Reward:   -264.3758901\n",
      "Actor Loss:   -725.7169189; Critic Loss:   3934.3383789; Batch Reward:   -309.5006285\n",
      "Actor Loss:   -789.8980103; Critic Loss:   2639.0012207; Batch Reward:   -213.7636587\n",
      "Actor Loss:   -724.5463867; Critic Loss:   3624.5632324; Batch Reward:   -315.0798496\n",
      "Actor Loss:   -862.1667480; Critic Loss:   2083.7141113; Batch Reward:   -206.2024577\n",
      "Actor Loss:   -789.1317139; Critic Loss:   8026.7783203; Batch Reward:   -374.4607474\n",
      "Actor Loss:   -793.1033325; Critic Loss:   2549.7194824; Batch Reward:   -161.7571392\n",
      "Actor Loss:   -860.1403809; Critic Loss:   3628.8894043; Batch Reward:   -306.7633579\n",
      "Actor Loss:   -965.2070312; Critic Loss:   1796.4260254; Batch Reward:   -199.8119104\n",
      "Actor Loss:  -1010.0197754; Critic Loss:   5440.4804688; Batch Reward:   -359.0766114\n",
      "Actor Loss:  -1031.9857178; Critic Loss:   2501.0351562; Batch Reward:   -178.7255196\n",
      "Actor Loss:  -1284.6033936; Critic Loss:   4407.7875977; Batch Reward:   -344.9809391\n",
      "Actor Loss:  -1145.5006104; Critic Loss:   2249.1279297; Batch Reward:   -167.4131303\n",
      "Actor Loss:  -1222.0517578; Critic Loss:   1999.3804932; Batch Reward:   -220.1772392\n",
      "Actor Loss:  -1630.9670410; Critic Loss:  11578.2978516; Batch Reward:   -475.2267513\n",
      "Actor Loss:  -1114.2807617; Critic Loss:   3504.3239746; Batch Reward:   -339.0001003\n",
      "Actor Loss:  -1222.0399170; Critic Loss:   3770.9194336; Batch Reward:   -156.0520156\n",
      "Actor Loss:  -1310.9736328; Critic Loss:   3131.9323730; Batch Reward:   -175.6877800\n",
      "Actor Loss:  -1611.2021484; Critic Loss:   3019.9992676; Batch Reward:   -266.2042961\n",
      "Actor Loss:  -1510.3686523; Critic Loss:   2955.1474609; Batch Reward:   -234.1191563\n",
      "Actor Loss:  -1405.2382812; Critic Loss:   2567.7944336; Batch Reward:   -245.7158985\n",
      "Actor Loss:  -1446.0814209; Critic Loss:   3117.4599609; Batch Reward:   -244.8189913\n",
      "Actor Loss:  -1272.4184570; Critic Loss:   2513.0988770; Batch Reward:   -222.9709618\n",
      "Actor Loss:  -1444.5571289; Critic Loss:   3408.2739258; Batch Reward:   -308.5326308\n",
      "Actor Loss:  -1131.7672119; Critic Loss:   1398.1047363; Batch Reward:   -170.7455592\n",
      "Actor Loss:  -1613.8569336; Critic Loss:   5172.5659180; Batch Reward:   -343.4778458\n",
      "Actor Loss:  -1080.7690430; Critic Loss:   1680.3474121; Batch Reward:   -208.9220083\n",
      "Actor Loss:  -1318.3897705; Critic Loss:   4340.9858398; Batch Reward:   -334.0372501\n",
      "Actor Loss:   -940.0917969; Critic Loss:   1165.9960938; Batch Reward:   -163.1777834\n",
      "Actor Loss:  -1013.9644165; Critic Loss:   1592.3542480; Batch Reward:   -182.3820144\n",
      "Actor Loss:   -920.7678833; Critic Loss:   2173.1311035; Batch Reward:   -204.8626435\n",
      "Actor Loss:   -957.7024536; Critic Loss:   1341.0458984; Batch Reward:   -176.8928335\n",
      "Actor Loss:   -981.3971558; Critic Loss:   2214.4013672; Batch Reward:   -210.6309979\n",
      "Actor Loss:   -924.9601440; Critic Loss:   1154.8072510; Batch Reward:   -177.1332713\n",
      "Actor Loss:  -1155.2092285; Critic Loss:   4471.5434570; Batch Reward:   -311.3087604\n",
      "Actor Loss:  -1057.1879883; Critic Loss:   1707.1583252; Batch Reward:   -197.9529312\n",
      "Actor Loss:  -1641.5654297; Critic Loss:   9875.0712891; Batch Reward:   -433.6134682\n",
      "Actor Loss:   -890.9545898; Critic Loss:   6110.8891602; Batch Reward:   -324.6848507\n",
      "Actor Loss:  -1261.4688721; Critic Loss:   2084.8974609; Batch Reward:   -256.7703222\n",
      "Actor Loss:  -2134.1394043; Critic Loss:  12465.0664062; Batch Reward:   -505.0498317\n",
      "Actor Loss:  -1707.5607910; Critic Loss:  14916.5468750; Batch Reward:   -513.4537232\n",
      "Actor Loss:  -1359.7065430; Critic Loss:   2080.0795898; Batch Reward:   -286.7298485\n",
      "Actor Loss:  -1630.6761475; Critic Loss:   4144.4023438; Batch Reward:   -189.4522212\n",
      "Actor Loss:  -1640.8217773; Critic Loss:   5363.8715820; Batch Reward:   -176.4907846\n",
      "Actor Loss:  -1904.4488525; Critic Loss:   6819.0810547; Batch Reward:   -179.3769829\n",
      "Actor Loss:  -2462.5195312; Critic Loss:   3382.2536621; Batch Reward:   -301.6863157\n",
      "Actor Loss:  -2073.4995117; Critic Loss:   5248.9223633; Batch Reward:   -190.0397907\n",
      "Actor Loss:  -1848.6485596; Critic Loss:   4495.2280273; Batch Reward:   -160.5710819\n",
      "Actor Loss:  -1550.1403809; Critic Loss:   4093.9360352; Batch Reward:   -174.2517811\n",
      "Actor Loss:  -1697.5627441; Critic Loss:   3296.3713379; Batch Reward:   -300.4313265\n",
      "Actor Loss:  -1665.0957031; Critic Loss:   2003.8990479; Batch Reward:   -185.4224937\n",
      "Actor Loss:  -1277.7403564; Critic Loss:   1968.8959961; Batch Reward:   -224.2749925\n",
      "Actor Loss:  -1230.2977295; Critic Loss:   1879.5524902; Batch Reward:   -200.1683436\n",
      "Actor Loss:  -1148.1092529; Critic Loss:   1251.3406982; Batch Reward:   -175.3705997\n",
      "Actor Loss:   -896.9838257; Critic Loss:   1221.5294189; Batch Reward:   -166.2353564\n",
      "Actor Loss:   -840.4279785; Critic Loss:   1294.3787842; Batch Reward:   -173.0667942\n",
      "Actor Loss:   -691.2362671; Critic Loss:   2437.6464844; Batch Reward:   -205.4340433\n",
      "Actor Loss:   -769.4818726; Critic Loss:   2729.9729004; Batch Reward:   -218.9816174\n",
      "Actor Loss:   -797.9050293; Critic Loss:   1876.2314453; Batch Reward:   -190.1605298\n",
      "Actor Loss:   -653.8770142; Critic Loss:   1533.6423340; Batch Reward:   -189.0567599\n",
      "Actor Loss:   -689.1853027; Critic Loss:   2407.6289062; Batch Reward:   -208.9260501\n",
      "Actor Loss:   -569.4231567; Critic Loss:   1932.2418213; Batch Reward:   -183.4758555\n",
      "Actor Loss:   -703.3997192; Critic Loss:   1839.6483154; Batch Reward:   -189.5300544\n",
      "Actor Loss:   -596.0372314; Critic Loss:   3232.4042969; Batch Reward:   -229.0230533\n",
      "Actor Loss:   -645.4227295; Critic Loss:   2237.8488770; Batch Reward:   -186.8676826\n",
      "Actor Loss:   -669.2432861; Critic Loss:   3999.1762695; Batch Reward:   -250.8855469\n",
      "Actor Loss:   -759.3692017; Critic Loss:   2154.0754395; Batch Reward:   -198.4691964\n",
      "Actor Loss:   -907.2702637; Critic Loss:   6910.0039062; Batch Reward:   -318.7113123\n",
      "Actor Loss:   -925.1080322; Critic Loss:   4122.9541016; Batch Reward:   -234.5531763\n",
      "Actor Loss:  -1322.1541748; Critic Loss:  16380.7949219; Batch Reward:   -463.0367958\n",
      "Actor Loss:  -1425.2344971; Critic Loss:  12483.2509766; Batch Reward:   -400.2917901\n",
      "Actor Loss:  -1016.7145386; Critic Loss:   1022.7329712; Batch Reward:   -180.6170714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2180.0361328; Critic Loss:  32712.3457031; Batch Reward:   -638.9216252\n",
      "Actor Loss:  -2691.4772949; Critic Loss:  18813.1777344; Batch Reward:   -609.0558543\n",
      "Actor Loss:  -2227.9538574; Critic Loss:   5440.8989258; Batch Reward:   -401.4494535\n",
      "Actor Loss:  -2151.0075684; Critic Loss:   2995.3618164; Batch Reward:   -167.2871622\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2401.8774414; Critic Loss:   5234.5380859; Batch Reward:   -171.5977396\n",
      "Actor Loss:  -2367.8454590; Critic Loss:   7426.3652344; Batch Reward:   -215.7665945\n",
      "Actor Loss:  -3007.7465820; Critic Loss:   6856.4960938; Batch Reward:   -156.4754155\n",
      "Actor Loss:  -2468.8437500; Critic Loss:   7094.5834961; Batch Reward:   -167.5690815\n",
      "Actor Loss:  -2879.8032227; Critic Loss:   4806.9545898; Batch Reward:   -273.2228528\n",
      "Actor Loss:  -3832.5632324; Critic Loss:   6303.0620117; Batch Reward:   -477.0620758\n",
      "Actor Loss:  -2755.3666992; Critic Loss:   3427.3625488; Batch Reward:   -188.7677794\n",
      "Actor Loss:  -2288.8132324; Critic Loss:   3632.4799805; Batch Reward:   -171.6323081\n",
      "Actor Loss:  -2096.6306152; Critic Loss:   2843.8166504; Batch Reward:   -206.1279015\n",
      "Actor Loss:  -1625.0729980; Critic Loss:   3358.5991211; Batch Reward:   -200.1121399\n",
      "Actor Loss:  -1805.4211426; Critic Loss:   1874.0064697; Batch Reward:   -193.0333595\n",
      "Actor Loss:  -1402.9919434; Critic Loss:   1823.8906250; Batch Reward:   -174.2318556\n",
      "Actor Loss:  -1440.0622559; Critic Loss:   1367.4398193; Batch Reward:   -173.0806839\n",
      "Actor Loss:  -1240.5827637; Critic Loss:   1570.1702881; Batch Reward:   -190.0985010\n",
      "Actor Loss:  -1062.5179443; Critic Loss:   1841.3309326; Batch Reward:   -208.6377132\n",
      "Actor Loss:  -1010.3258667; Critic Loss:   1201.7054443; Batch Reward:   -183.3309692\n",
      "Actor Loss:  -1011.0302124; Critic Loss:   1811.6066895; Batch Reward:   -184.9995875\n",
      "Actor Loss:   -758.1070557; Critic Loss:   1868.0720215; Batch Reward:   -177.2858861\n",
      "Actor Loss:   -879.0988770; Critic Loss:   2431.1982422; Batch Reward:   -185.4278979\n",
      "Actor Loss:   -816.5088501; Critic Loss:   1879.0622559; Batch Reward:   -191.6103910\n",
      "Actor Loss:   -796.0042114; Critic Loss:   2524.3908691; Batch Reward:   -212.3092195\n",
      "Actor Loss:   -765.4249878; Critic Loss:   2083.2614746; Batch Reward:   -195.3725608\n",
      "Actor Loss:   -763.4771118; Critic Loss:   2393.4577637; Batch Reward:   -191.5455275\n",
      "Actor Loss:   -679.7587280; Critic Loss:   2630.9636230; Batch Reward:   -190.5783592\n",
      "Actor Loss:   -690.6849976; Critic Loss:   2637.0588379; Batch Reward:   -204.5226290\n",
      "Actor Loss:   -762.6373901; Critic Loss:   2624.4357910; Batch Reward:   -207.0311672\n",
      "Actor Loss:   -752.7411499; Critic Loss:   2035.8477783; Batch Reward:   -188.6849754\n",
      "Actor Loss:   -982.2078247; Critic Loss:   3432.0437012; Batch Reward:   -226.5255223\n",
      "Actor Loss:   -892.2312622; Critic Loss:   5066.0527344; Batch Reward:   -271.9821237\n",
      "Actor Loss:  -1040.3504639; Critic Loss:   4351.7387695; Batch Reward:   -263.1891182\n",
      "Actor Loss:  -1017.0145264; Critic Loss:   1943.4113770; Batch Reward:   -188.1647856\n",
      "Actor Loss:   -891.7500000; Critic Loss:   2275.8193359; Batch Reward:   -210.0861431\n",
      "Actor Loss:  -1279.1894531; Critic Loss:   8691.1855469; Batch Reward:   -360.6641282\n",
      "Actor Loss:  -1810.3868408; Critic Loss:   8903.4082031; Batch Reward:   -355.1808583\n",
      "Actor Loss:  -1179.7913818; Critic Loss:   5880.2026367; Batch Reward:   -347.4171062\n",
      "Actor Loss:  -1177.1115723; Critic Loss:   1494.6403809; Batch Reward:   -192.2062773\n",
      "Actor Loss:  -1466.4385986; Critic Loss:   2784.6313477; Batch Reward:   -239.9429904\n",
      "Actor Loss:  -1700.6032715; Critic Loss:   1194.7634277; Batch Reward:   -195.1129452\n",
      "Actor Loss:  -1220.8658447; Critic Loss:   1118.4550781; Batch Reward:   -170.7428553\n",
      "Actor Loss:  -3325.9509277; Critic Loss:  19867.2363281; Batch Reward:   -651.1158102\n",
      "Actor Loss:  -2813.6254883; Critic Loss:   6920.6972656; Batch Reward:   -417.8237665\n",
      "Actor Loss:  -1745.0302734; Critic Loss:   1716.9602051; Batch Reward:   -183.9427457\n",
      "Actor Loss:  -3821.2062988; Critic Loss:  11194.0625000; Batch Reward:   -534.8422282\n",
      "Actor Loss:  -3519.3063965; Critic Loss:   7597.6733398; Batch Reward:   -527.8793452\n",
      "Actor Loss:  -2883.1618652; Critic Loss:   2834.8115234; Batch Reward:   -316.6535768\n",
      "Actor Loss:  -2628.0781250; Critic Loss:   6052.4965820; Batch Reward:   -160.4537584\n",
      "Actor Loss:  -2568.2670898; Critic Loss:   6271.4658203; Batch Reward:   -161.7572723\n",
      "Actor Loss:  -2390.0366211; Critic Loss:   7104.1494141; Batch Reward:   -166.7565939\n",
      "Actor Loss:  -2263.1450195; Critic Loss:   6376.3339844; Batch Reward:   -152.5480098\n",
      "Actor Loss:  -2414.8088379; Critic Loss:   4799.4653320; Batch Reward:   -169.7488090\n",
      "Actor Loss:  -1826.8988037; Critic Loss:   4072.8273926; Batch Reward:   -169.9855473\n",
      "Actor Loss:  -1638.1558838; Critic Loss:   2791.5808105; Batch Reward:   -166.4324777\n",
      "Actor Loss:  -1624.2657471; Critic Loss:   1768.5095215; Batch Reward:   -160.1338599\n",
      "Actor Loss:  -1379.4354248; Critic Loss:   2003.4018555; Batch Reward:   -177.7555361\n",
      "Actor Loss:  -1139.3487549; Critic Loss:   1409.6190186; Batch Reward:   -166.9081477\n",
      "Actor Loss:  -1054.9837646; Critic Loss:    924.1044922; Batch Reward:   -161.0575638\n",
      "Actor Loss:   -785.8306274; Critic Loss:   1456.8062744; Batch Reward:   -154.4707057\n",
      "Actor Loss:   -757.7059937; Critic Loss:   1433.5009766; Batch Reward:   -174.0001875\n",
      "Actor Loss:   -834.0759277; Critic Loss:   1593.0228271; Batch Reward:   -179.8771081\n",
      "Actor Loss:   -722.6423340; Critic Loss:   1445.7506104; Batch Reward:   -168.2473372\n",
      "Actor Loss:   -573.8010864; Critic Loss:   1757.9614258; Batch Reward:   -166.4853674\n",
      "Actor Loss:   -558.5779419; Critic Loss:   1413.0203857; Batch Reward:   -166.6641877\n",
      "Actor Loss:   -651.6528931; Critic Loss:   1907.9758301; Batch Reward:   -176.9707109\n",
      "Actor Loss:   -568.7727051; Critic Loss:   1585.3851318; Batch Reward:   -166.2057477\n",
      "Actor Loss:   -509.6570435; Critic Loss:   2140.9865723; Batch Reward:   -179.8814528\n",
      "Actor Loss:   -552.2277222; Critic Loss:   1835.5231934; Batch Reward:   -174.4552859\n",
      "Actor Loss:   -466.2514648; Critic Loss:   1739.4555664; Batch Reward:   -170.2972131\n",
      "Actor Loss:   -524.1038208; Critic Loss:   2445.6867676; Batch Reward:   -192.5134178\n",
      "Actor Loss:   -528.9450073; Critic Loss:   1999.1223145; Batch Reward:   -178.4053859\n",
      "Actor Loss:   -551.0659180; Critic Loss:   2529.6513672; Batch Reward:   -188.8409643\n",
      "Actor Loss:   -528.3735352; Critic Loss:   2024.8123779; Batch Reward:   -186.0220610\n",
      "Actor Loss:   -493.3933105; Critic Loss:   2226.9428711; Batch Reward:   -185.8643394\n",
      "Actor Loss:   -558.7846069; Critic Loss:   2131.6755371; Batch Reward:   -194.9181214\n",
      "Actor Loss:   -669.1981812; Critic Loss:   2549.6550293; Batch Reward:   -205.6281378\n",
      "Actor Loss:   -615.6007690; Critic Loss:   2863.8049316; Batch Reward:   -195.4738502\n",
      "Actor Loss:   -792.2777710; Critic Loss:   2479.5192871; Batch Reward:   -209.5161944\n",
      "Actor Loss:   -675.7627563; Critic Loss:   2091.2692871; Batch Reward:   -190.3818054\n",
      "Actor Loss:   -693.3749390; Critic Loss:   2084.6892090; Batch Reward:   -210.4306004\n",
      "Actor Loss:   -827.2244263; Critic Loss:   2595.0166016; Batch Reward:   -237.3417266\n",
      "Actor Loss:   -787.3721313; Critic Loss:   1421.0257568; Batch Reward:   -182.4547268\n",
      "Actor Loss:   -958.3550415; Critic Loss:   1433.6708984; Batch Reward:   -184.2273415\n",
      "Actor Loss:  -1311.6243896; Critic Loss:   5521.6538086; Batch Reward:   -314.5833564\n",
      "Actor Loss:  -1449.3747559; Critic Loss:   8296.7792969; Batch Reward:   -360.9016398\n",
      "Actor Loss:  -1111.6962891; Critic Loss:   1373.3990479; Batch Reward:   -180.1998073\n",
      "Actor Loss:  -1977.0469971; Critic Loss:   8027.4741211; Batch Reward:   -441.1166178\n",
      "Actor Loss:  -1611.1417236; Critic Loss:   8126.1484375; Batch Reward:   -372.0360885\n",
      "Actor Loss:  -1373.2092285; Critic Loss:   1151.6414795; Batch Reward:   -177.0669979\n",
      "Actor Loss:  -3580.1096191; Critic Loss:  20350.0507812; Batch Reward:   -602.2592613\n",
      "Actor Loss:  -3471.9328613; Critic Loss:  20645.1054688; Batch Reward:   -626.2000566\n",
      "Actor Loss:  -2226.4060059; Critic Loss:   2082.9916992; Batch Reward:   -220.4944104\n",
      "Actor Loss:  -2622.9584961; Critic Loss:   2846.7285156; Batch Reward:   -157.9705500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2290.4135742; Critic Loss:   6777.8256836; Batch Reward:   -208.4818041\n",
      "Actor Loss:  -2843.0493164; Critic Loss:   4994.7099609; Batch Reward:   -149.6797872\n",
      "Actor Loss:  -2565.4260254; Critic Loss:   5333.7163086; Batch Reward:   -177.6173619\n",
      "Actor Loss:  -2522.3020020; Critic Loss:   5878.9086914; Batch Reward:   -233.7169445\n",
      "Actor Loss:  -3133.5537109; Critic Loss:   4271.8144531; Batch Reward:   -336.9106583\n",
      "Actor Loss:  -2473.1477051; Critic Loss:   3315.8000488; Batch Reward:   -187.3184157\n",
      "Actor Loss:  -2229.0512695; Critic Loss:   2818.5148926; Batch Reward:   -189.7300486\n",
      "Actor Loss:  -2151.5485840; Critic Loss:   2913.5053711; Batch Reward:   -210.1832741\n",
      "Actor Loss:  -1883.9318848; Critic Loss:   2682.9248047; Batch Reward:   -190.3716504\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -1803.4573975; Critic Loss:   1547.8236084; Batch Reward:   -168.8103182\n",
      "Actor Loss:  -1545.0113525; Critic Loss:   1237.2103271; Batch Reward:   -163.9435422\n",
      "Actor Loss:  -1359.0178223; Critic Loss:   1998.8215332; Batch Reward:   -181.3509444\n",
      "Actor Loss:  -1292.1523438; Critic Loss:   1938.3010254; Batch Reward:   -173.7836844\n",
      "Actor Loss:  -1281.2766113; Critic Loss:   1931.4559326; Batch Reward:   -177.7971176\n",
      "Actor Loss:  -1118.6934814; Critic Loss:   1254.8295898; Batch Reward:   -180.1803689\n",
      "Actor Loss:  -1069.7485352; Critic Loss:   1441.7547607; Batch Reward:   -177.7629816\n",
      "Actor Loss:   -981.3257446; Critic Loss:   1606.3234863; Batch Reward:   -191.4847385\n",
      "Actor Loss:   -990.6649780; Critic Loss:   1547.9589844; Batch Reward:   -182.3332398\n",
      "Actor Loss:   -790.7203979; Critic Loss:   1992.4897461; Batch Reward:   -188.3502211\n",
      "Actor Loss:  -1024.7647705; Critic Loss:   1616.0609131; Batch Reward:   -185.2829178\n",
      "Actor Loss:   -755.8156128; Critic Loss:   1960.6124268; Batch Reward:   -176.0998724\n",
      "Actor Loss:   -824.8705444; Critic Loss:   2055.9538574; Batch Reward:   -189.1115681\n",
      "Actor Loss:   -820.6073608; Critic Loss:   1802.2728271; Batch Reward:   -183.8552472\n",
      "Actor Loss:   -732.1549072; Critic Loss:   2836.5529785; Batch Reward:   -212.8610399\n",
      "Actor Loss:   -828.5143433; Critic Loss:   2136.2873535; Batch Reward:   -194.8267923\n",
      "Actor Loss:   -871.6289062; Critic Loss:   2489.0041504; Batch Reward:   -207.0650313\n",
      "Actor Loss:   -924.9953613; Critic Loss:   2421.5830078; Batch Reward:   -191.0925556\n",
      "Actor Loss:   -771.6923218; Critic Loss:   5447.2905273; Batch Reward:   -286.6730877\n",
      "Actor Loss:   -889.2624512; Critic Loss:   3190.3735352; Batch Reward:   -209.1144961\n",
      "Actor Loss:   -860.4234619; Critic Loss:   1914.3487549; Batch Reward:   -183.3806605\n",
      "Actor Loss:   -960.6855469; Critic Loss:   2436.8415527; Batch Reward:   -210.6725296\n",
      "Actor Loss:   -947.7612305; Critic Loss:   2662.8542480; Batch Reward:   -214.8297937\n",
      "Actor Loss:   -937.0139771; Critic Loss:   2506.7968750; Batch Reward:   -249.2836131\n",
      "Actor Loss:  -1189.3297119; Critic Loss:   2179.4831543; Batch Reward:   -199.2832442\n",
      "Actor Loss:   -935.1944580; Critic Loss:   1852.5617676; Batch Reward:   -198.6916857\n",
      "Actor Loss:  -1089.4420166; Critic Loss:   5298.5883789; Batch Reward:   -305.8614000\n",
      "Actor Loss:  -1621.2845459; Critic Loss:   2715.4372559; Batch Reward:   -236.6312256\n",
      "Actor Loss:  -1260.5156250; Critic Loss:   2755.0312500; Batch Reward:   -236.5195708\n",
      "Actor Loss:  -1296.8586426; Critic Loss:   3971.0456543; Batch Reward:   -268.3532552\n",
      "Actor Loss:  -1611.8885498; Critic Loss:   2181.5114746; Batch Reward:   -220.1537751\n",
      "Actor Loss:  -1479.9163818; Critic Loss:   3291.6191406; Batch Reward:   -266.6490927\n",
      "Actor Loss:  -2191.8579102; Critic Loss:   6171.9638672; Batch Reward:   -374.4437236\n",
      "Actor Loss:  -1884.6657715; Critic Loss:   1020.8587036; Batch Reward:   -186.7875636\n",
      "Actor Loss:  -2686.3151855; Critic Loss:   8626.2939453; Batch Reward:   -544.9023922\n",
      "Actor Loss:  -2354.4448242; Critic Loss:   2599.4108887; Batch Reward:   -276.6970354\n",
      "Actor Loss:  -1820.1733398; Critic Loss:   1314.0518799; Batch Reward:   -178.9103816\n",
      "Actor Loss:  -3545.8916016; Critic Loss:  18753.1796875; Batch Reward:   -577.6140840\n",
      "Actor Loss:  -4059.9204102; Critic Loss:  14425.8242188; Batch Reward:   -557.5245477\n",
      "Actor Loss:  -2377.7385254; Critic Loss:   3376.2214355; Batch Reward:   -169.6213925\n",
      "Actor Loss:  -2671.3291016; Critic Loss:   4383.2080078; Batch Reward:   -237.5944527\n",
      "Actor Loss:  -2754.6738281; Critic Loss:   5021.9208984; Batch Reward:   -250.3180866\n",
      "Actor Loss:  -2710.1164551; Critic Loss:   3869.4440918; Batch Reward:   -177.8181467\n",
      "Actor Loss:  -2685.3217773; Critic Loss:   5022.6459961; Batch Reward:   -178.9504572\n",
      "Actor Loss:  -2764.3139648; Critic Loss:   3739.0087891; Batch Reward:   -171.0663993\n",
      "Actor Loss:  -2392.1665039; Critic Loss:   3597.9206543; Batch Reward:   -187.4204539\n",
      "Actor Loss:  -2392.2583008; Critic Loss:   2773.6630859; Batch Reward:   -167.0054548\n",
      "Actor Loss:  -2054.3728027; Critic Loss:   2852.3081055; Batch Reward:   -168.9203856\n",
      "Actor Loss:  -2060.1882324; Critic Loss:   1893.8666992; Batch Reward:   -168.2734714\n",
      "Actor Loss:  -1864.0054932; Critic Loss:   1628.9005127; Batch Reward:   -172.4995352\n",
      "Actor Loss:  -1644.4176025; Critic Loss:   1870.0964355; Batch Reward:   -225.8460684\n",
      "Actor Loss:  -1409.9841309; Critic Loss:   1436.2829590; Batch Reward:   -188.8285569\n",
      "Actor Loss:  -1535.1726074; Critic Loss:   1049.0120850; Batch Reward:   -158.7888179\n",
      "Actor Loss:  -1487.5484619; Critic Loss:   1263.8873291; Batch Reward:   -169.2695555\n",
      "Actor Loss:  -1151.9986572; Critic Loss:   1151.3802490; Batch Reward:   -181.7410414\n",
      "Actor Loss:  -1109.9892578; Critic Loss:   1185.0137939; Batch Reward:   -176.2644354\n",
      "Actor Loss:  -1133.8588867; Critic Loss:   1075.6590576; Batch Reward:   -174.0191518\n",
      "Actor Loss:  -1061.1909180; Critic Loss:   1609.9248047; Batch Reward:   -177.7200482\n",
      "Actor Loss:   -929.4835205; Critic Loss:   1666.9919434; Batch Reward:   -183.3176574\n",
      "Actor Loss:   -962.3734741; Critic Loss:   1479.0401611; Batch Reward:   -174.2603133\n",
      "Actor Loss:  -1012.1826782; Critic Loss:   2340.8574219; Batch Reward:   -203.1381356\n",
      "Actor Loss:   -841.2052002; Critic Loss:   1825.4903564; Batch Reward:   -200.8480792\n",
      "Actor Loss:   -863.6883545; Critic Loss:   1709.0200195; Batch Reward:   -194.1834904\n",
      "Actor Loss:   -899.2609863; Critic Loss:   1712.0697021; Batch Reward:   -193.6865212\n",
      "Actor Loss:   -866.3248901; Critic Loss:   2393.3837891; Batch Reward:   -196.3050074\n",
      "Actor Loss:   -759.9010010; Critic Loss:   2183.1105957; Batch Reward:   -179.9111880\n",
      "Actor Loss:   -826.3876343; Critic Loss:   5450.8105469; Batch Reward:   -282.5073671\n",
      "Actor Loss:  -1025.2449951; Critic Loss:   1733.0095215; Batch Reward:   -201.3687800\n",
      "Actor Loss:   -926.7468262; Critic Loss:   1827.7325439; Batch Reward:   -190.0391246\n",
      "Actor Loss:   -864.4241333; Critic Loss:   2329.1474609; Batch Reward:   -205.3310149\n",
      "Actor Loss:  -1085.4227295; Critic Loss:   3018.9765625; Batch Reward:   -221.7582298\n",
      "Actor Loss:  -1079.7536621; Critic Loss:   1769.1186523; Batch Reward:   -195.5288754\n",
      "Actor Loss:  -1045.7775879; Critic Loss:   8175.7797852; Batch Reward:   -344.2905026\n",
      "Actor Loss:  -1547.9029541; Critic Loss:   4420.6479492; Batch Reward:   -292.0167841\n",
      "Actor Loss:  -1224.7187500; Critic Loss:    980.9769287; Batch Reward:   -168.6582506\n",
      "Actor Loss:  -1783.2310791; Critic Loss:  15289.4482422; Batch Reward:   -475.2510742\n",
      "Actor Loss:  -2748.5214844; Critic Loss:   7537.1064453; Batch Reward:   -439.9730286\n",
      "Actor Loss:  -1312.7496338; Critic Loss:   2114.7849121; Batch Reward:   -257.3227508\n",
      "Actor Loss:  -1744.4011230; Critic Loss:   2781.5471191; Batch Reward:   -313.6354266\n",
      "Actor Loss:  -2129.8488770; Critic Loss:   2400.2343750; Batch Reward:   -320.5725753\n",
      "Actor Loss:  -2081.9794922; Critic Loss:   2929.7670898; Batch Reward:   -190.0890651\n",
      "Actor Loss:  -2323.9135742; Critic Loss:   2574.1638184; Batch Reward:   -240.2235072\n",
      "Actor Loss:  -2269.4069824; Critic Loss:   2892.2910156; Batch Reward:   -200.2427183\n",
      "Actor Loss:  -2265.7536621; Critic Loss:   2763.6350098; Batch Reward:   -190.8503232\n",
      "Actor Loss:  -2186.7775879; Critic Loss:   3412.4470215; Batch Reward:   -213.6091897\n",
      "Actor Loss:  -2589.9113770; Critic Loss:   2762.2331543; Batch Reward:   -176.8263418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2141.2304688; Critic Loss:   2608.0324707; Batch Reward:   -201.0916862\n",
      "Actor Loss:  -2303.8442383; Critic Loss:   3581.1613770; Batch Reward:   -302.0670851\n",
      "Actor Loss:  -2346.5219727; Critic Loss:   1901.6900635; Batch Reward:   -220.4104912\n",
      "Actor Loss:  -1931.6516113; Critic Loss:   1921.7589111; Batch Reward:   -206.0112789\n",
      "Actor Loss:  -1957.2836914; Critic Loss:   2002.2246094; Batch Reward:   -223.5684471\n",
      "Actor Loss:  -1886.7103271; Critic Loss:   2193.8205566; Batch Reward:   -217.8426391\n",
      "Actor Loss:  -1697.2019043; Critic Loss:   1704.8646240; Batch Reward:   -193.1580142\n",
      "Actor Loss:  -1638.5701904; Critic Loss:   2081.0153809; Batch Reward:   -205.7224278\n",
      "Actor Loss:  -1546.6608887; Critic Loss:   1907.3679199; Batch Reward:   -190.6288145\n",
      "Actor Loss:  -1520.6593018; Critic Loss:   1218.6881104; Batch Reward:   -194.7872847\n",
      "Actor Loss:  -1437.3735352; Critic Loss:   2614.1872559; Batch Reward:   -231.8147297\n",
      "Actor Loss:  -1513.1201172; Critic Loss:   1928.0601807; Batch Reward:   -204.6841828\n",
      "Actor Loss:  -1625.5002441; Critic Loss:   8439.2792969; Batch Reward:   -420.1803809\n",
      "Actor Loss:  -1468.1519775; Critic Loss:   3142.7587891; Batch Reward:   -257.3067487\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -1948.2683105; Critic Loss:   6773.9101562; Batch Reward:   -452.2063790\n",
      "Actor Loss:  -1468.2829590; Critic Loss:   2959.1147461; Batch Reward:   -254.8492539\n",
      "Actor Loss:  -1275.3922119; Critic Loss:   3216.9116211; Batch Reward:   -287.4054722\n",
      "Actor Loss:  -1452.5142822; Critic Loss:   1734.6395264; Batch Reward:   -202.5886887\n",
      "Actor Loss:  -1503.1169434; Critic Loss:   2995.4743652; Batch Reward:   -287.7243875\n",
      "Actor Loss:  -1510.8032227; Critic Loss:    743.6576538; Batch Reward:   -165.7836221\n",
      "Actor Loss:  -1404.4536133; Critic Loss:   1614.4892578; Batch Reward:   -208.2876719\n",
      "Actor Loss:  -1450.4661865; Critic Loss:   1683.0620117; Batch Reward:   -167.4035257\n",
      "Actor Loss:  -1378.6872559; Critic Loss:   1519.9975586; Batch Reward:   -190.6615394\n",
      "Actor Loss:  -1856.5335693; Critic Loss:   3481.4177246; Batch Reward:   -324.7139505\n",
      "Actor Loss:  -1559.0487061; Critic Loss:   3484.9179688; Batch Reward:   -267.7121780\n",
      "Actor Loss:  -1842.7410889; Critic Loss:   1076.0117188; Batch Reward:   -178.9932532\n",
      "Actor Loss:  -1668.8719482; Critic Loss:   3404.3706055; Batch Reward:   -275.1097275\n",
      "Actor Loss:  -1696.5183105; Critic Loss:   1626.4904785; Batch Reward:   -203.6032765\n",
      "Actor Loss:  -1519.9462891; Critic Loss:   2267.6777344; Batch Reward:   -211.3083526\n",
      "Actor Loss:  -1563.0974121; Critic Loss:   1650.3995361; Batch Reward:   -196.6458803\n",
      "Actor Loss:  -1603.2150879; Critic Loss:   1831.3824463; Batch Reward:   -200.2574273\n",
      "Actor Loss:  -1866.3326416; Critic Loss:   3546.1862793; Batch Reward:   -291.2870864\n",
      "Actor Loss:  -1799.8581543; Critic Loss:   2834.0317383; Batch Reward:   -259.5063959\n",
      "Actor Loss:  -3005.9687500; Critic Loss:   9003.9414062; Batch Reward:   -529.6117268\n",
      "Actor Loss:  -1965.2550049; Critic Loss:   1529.4407959; Batch Reward:   -225.7987802\n",
      "Actor Loss:  -1644.8657227; Critic Loss:   1287.3072510; Batch Reward:   -169.0814275\n",
      "Actor Loss:  -2888.2019043; Critic Loss:   7101.2578125; Batch Reward:   -481.2577571\n",
      "Actor Loss:  -2327.0048828; Critic Loss:  10089.2050781; Batch Reward:   -470.7331160\n",
      "Actor Loss:  -1956.8686523; Critic Loss:   1645.4049072; Batch Reward:   -181.9172471\n",
      "Actor Loss:  -2054.0522461; Critic Loss:   2699.1416016; Batch Reward:   -230.0194185\n",
      "Actor Loss:  -2037.2884521; Critic Loss:   2651.5935059; Batch Reward:   -175.0223766\n",
      "Actor Loss:  -1943.3494873; Critic Loss:   3824.3459473; Batch Reward:   -184.2158122\n",
      "Actor Loss:  -2108.5129395; Critic Loss:   2667.4423828; Batch Reward:   -177.5273298\n",
      "Actor Loss:  -1954.6644287; Critic Loss:   1975.9130859; Batch Reward:   -167.2167103\n",
      "Actor Loss:  -1876.0772705; Critic Loss:   2352.5466309; Batch Reward:   -193.4656650\n",
      "Actor Loss:  -1909.1815186; Critic Loss:   1839.0693359; Batch Reward:   -185.7362417\n",
      "Actor Loss:  -1801.5347900; Critic Loss:   2420.0869141; Batch Reward:   -180.8500613\n",
      "Actor Loss:  -1584.6197510; Critic Loss:   1857.3918457; Batch Reward:   -178.1624260\n",
      "Actor Loss:  -1607.6494141; Critic Loss:   1378.4285889; Batch Reward:   -171.1692594\n",
      "Actor Loss:  -1361.3748779; Critic Loss:   1883.1962891; Batch Reward:   -202.4550293\n",
      "Actor Loss:  -1464.1030273; Critic Loss:   1592.2781982; Batch Reward:   -203.3988216\n",
      "Actor Loss:  -1235.4143066; Critic Loss:   3063.9296875; Batch Reward:   -227.4887397\n",
      "Actor Loss:  -1208.4609375; Critic Loss:   1047.4804688; Batch Reward:   -179.0020585\n",
      "Actor Loss:  -1259.1562500; Critic Loss:   2145.6423340; Batch Reward:   -215.9067312\n",
      "Actor Loss:  -1204.4455566; Critic Loss:   1472.2121582; Batch Reward:   -195.5678507\n",
      "Actor Loss:  -1115.9360352; Critic Loss:   2460.8637695; Batch Reward:   -214.5566944\n",
      "Actor Loss:  -1132.4843750; Critic Loss:   1595.4616699; Batch Reward:   -203.3889174\n",
      "Actor Loss:  -1075.7747803; Critic Loss:   1465.2155762; Batch Reward:   -181.4451541\n",
      "Actor Loss:  -1091.9063721; Critic Loss:   2110.3796387; Batch Reward:   -205.4270730\n",
      "Actor Loss:  -1119.3247070; Critic Loss:   1931.3566895; Batch Reward:   -187.1549084\n",
      "Actor Loss:  -1133.8463135; Critic Loss:   1748.4832764; Batch Reward:   -201.5860575\n",
      "Actor Loss:  -1227.8193359; Critic Loss:   2942.3898926; Batch Reward:   -233.4733668\n",
      "Actor Loss:  -1071.7792969; Critic Loss:   2064.8769531; Batch Reward:   -194.1652195\n",
      "Actor Loss:  -1218.5404053; Critic Loss:   2284.8154297; Batch Reward:   -224.1092784\n",
      "Actor Loss:  -1216.2602539; Critic Loss:   2302.0922852; Batch Reward:   -220.7909386\n",
      "Actor Loss:  -1980.1520996; Critic Loss:  13267.4287109; Batch Reward:   -471.4177670\n",
      "Actor Loss:  -2734.4013672; Critic Loss:  16697.2343750; Batch Reward:   -506.4745111\n",
      "Actor Loss:  -1665.3917236; Critic Loss:   4003.1162109; Batch Reward:   -363.4492270\n",
      "Actor Loss:  -3053.8225098; Critic Loss:  20610.0703125; Batch Reward:   -579.8426629\n",
      "Actor Loss:  -1807.3914795; Critic Loss:   2299.6975098; Batch Reward:   -207.5869106\n",
      "Actor Loss:  -1877.7269287; Critic Loss:   2436.2094727; Batch Reward:   -181.1771099\n",
      "Actor Loss:  -2090.0444336; Critic Loss:   2708.8610840; Batch Reward:   -172.6122151\n",
      "Actor Loss:  -2535.0446777; Critic Loss:   3341.1577148; Batch Reward:   -157.4585313\n",
      "Actor Loss:  -2444.5961914; Critic Loss:   3263.1118164; Batch Reward:   -159.0797942\n",
      "Actor Loss:  -2300.5556641; Critic Loss:   4846.7451172; Batch Reward:   -189.4651821\n",
      "Actor Loss:  -2259.9511719; Critic Loss:   3133.3000488; Batch Reward:   -177.4069611\n",
      "Actor Loss:  -2474.0839844; Critic Loss:   2711.3603516; Batch Reward:   -179.8137525\n",
      "Actor Loss:  -2186.3122559; Critic Loss:   2885.2697754; Batch Reward:   -197.9278963\n",
      "Actor Loss:  -2327.9821777; Critic Loss:   1894.4780273; Batch Reward:   -170.8744404\n",
      "Actor Loss:  -1705.7723389; Critic Loss:   2663.8041992; Batch Reward:   -187.6352061\n",
      "Actor Loss:  -2014.8204346; Critic Loss:   1356.7167969; Batch Reward:   -176.1064614\n",
      "Actor Loss:  -1796.3103027; Critic Loss:   1362.8597412; Batch Reward:   -164.6307497\n",
      "Actor Loss:  -1505.5622559; Critic Loss:   1954.8951416; Batch Reward:   -226.0389194\n",
      "Actor Loss:  -1608.1573486; Critic Loss:   1295.9982910; Batch Reward:   -181.1098426\n",
      "Actor Loss:  -1468.3483887; Critic Loss:   1925.5567627; Batch Reward:   -199.1789511\n",
      "Actor Loss:  -1295.6048584; Critic Loss:   1601.7712402; Batch Reward:   -186.0138044\n",
      "Actor Loss:  -1209.2274170; Critic Loss:   2787.4206543; Batch Reward:   -235.4051213\n",
      "Actor Loss:  -1316.2286377; Critic Loss:   1235.5610352; Batch Reward:   -181.7071949\n",
      "Actor Loss:  -1241.7331543; Critic Loss:   2627.8520508; Batch Reward:   -230.1456449\n",
      "Actor Loss:  -1180.8500977; Critic Loss:   1797.4907227; Batch Reward:   -182.1266643\n",
      "Actor Loss:  -1161.2482910; Critic Loss:   3417.9277344; Batch Reward:   -252.0433542\n",
      "Actor Loss:  -1005.8699951; Critic Loss:   1461.4359131; Batch Reward:   -183.7705376\n",
      "Actor Loss:  -1143.2128906; Critic Loss:   1816.0415039; Batch Reward:   -178.7982654\n",
      "Actor Loss:  -1051.1044922; Critic Loss:   1326.0509033; Batch Reward:   -176.7565300\n",
      "Actor Loss:  -1058.2408447; Critic Loss:   1729.9243164; Batch Reward:   -194.3840786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -1199.4456787; Critic Loss:   1806.2487793; Batch Reward:   -185.9615937\n",
      "Actor Loss:  -1109.6431885; Critic Loss:   2627.0480957; Batch Reward:   -226.0261347\n",
      "Actor Loss:  -1285.2249756; Critic Loss:   1285.9381104; Batch Reward:   -173.9255299\n",
      "Actor Loss:  -1492.6556396; Critic Loss:   6709.8188477; Batch Reward:   -364.1687829\n",
      "Actor Loss:  -1430.5322266; Critic Loss:   1585.5247803; Batch Reward:   -187.1177138\n",
      "Actor Loss:  -1978.4020996; Critic Loss:   6469.2241211; Batch Reward:   -383.2078244\n",
      "Actor Loss:  -1654.2299805; Critic Loss:   3136.8649902; Batch Reward:   -239.8812086\n",
      "Actor Loss:  -2436.9494629; Critic Loss:   6508.2641602; Batch Reward:   -413.7002804\n",
      "Actor Loss:  -1724.6215820; Critic Loss:   2140.4147949; Batch Reward:   -205.6575738\n",
      "Actor Loss:  -1683.7933350; Critic Loss:   1554.1553955; Batch Reward:   -182.2060610\n",
      "Actor Loss:  -2238.5341797; Critic Loss:   3004.7297363; Batch Reward:   -314.0782035\n",
      "Actor Loss:  -1710.3905029; Critic Loss:   2295.4189453; Batch Reward:   -244.5698124\n",
      "Actor Loss:  -2005.6441650; Critic Loss:   1086.9449463; Batch Reward:   -174.4497264\n",
      "Actor Loss:  -1944.4953613; Critic Loss:   2005.0961914; Batch Reward:   -200.3326888\n",
      "Actor Loss:  -2546.3088379; Critic Loss:   3138.7380371; Batch Reward:   -251.6034859\n",
      "Actor Loss:  -1926.2995605; Critic Loss:   2256.4248047; Batch Reward:   -201.6334922\n",
      "Actor Loss:  -2203.0712891; Critic Loss:   2049.1677246; Batch Reward:   -208.2545870\n",
      "Actor Loss:  -2162.6381836; Critic Loss:   3521.6135254; Batch Reward:   -285.8898631\n",
      "Actor Loss:  -2248.3818359; Critic Loss:   1676.1197510; Batch Reward:   -176.2009417\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2053.4631348; Critic Loss:   1584.1888428; Batch Reward:   -197.3058745\n",
      "Actor Loss:  -2736.6953125; Critic Loss:   4861.6430664; Batch Reward:   -366.5599040\n",
      "Actor Loss:  -2083.6455078; Critic Loss:   3707.0898438; Batch Reward:   -292.8236108\n",
      "Actor Loss:  -2632.9821777; Critic Loss:   3434.9409180; Batch Reward:   -364.3253123\n",
      "Actor Loss:  -2058.0407715; Critic Loss:   3087.4235840; Batch Reward:   -259.3542634\n",
      "Actor Loss:  -1663.9395752; Critic Loss:   2277.8859863; Batch Reward:   -227.2848133\n",
      "Actor Loss:  -1722.7263184; Critic Loss:   1253.1661377; Batch Reward:   -166.5893463\n",
      "Actor Loss:  -1720.5832520; Critic Loss:   2948.6528320; Batch Reward:   -258.4196371\n",
      "Actor Loss:  -1719.1710205; Critic Loss:   1247.8625488; Batch Reward:   -179.0258925\n",
      "Actor Loss:  -1672.4783936; Critic Loss:   2645.8881836; Batch Reward:   -276.8966701\n",
      "Actor Loss:  -1616.5777588; Critic Loss:   1440.3526611; Batch Reward:   -185.4966718\n",
      "Actor Loss:  -1562.1171875; Critic Loss:   1819.9827881; Batch Reward:   -225.6592274\n",
      "Actor Loss:  -1626.8422852; Critic Loss:   4128.9394531; Batch Reward:   -284.8710455\n",
      "Actor Loss:  -1463.2652588; Critic Loss:   1493.1984863; Batch Reward:   -214.3752859\n",
      "Actor Loss:  -2048.8320312; Critic Loss:   6260.0942383; Batch Reward:   -393.2785448\n",
      "Actor Loss:  -1768.5910645; Critic Loss:   2072.3986816; Batch Reward:   -239.5681393\n",
      "Actor Loss:  -2125.2873535; Critic Loss:   7096.8754883; Batch Reward:   -442.7987303\n",
      "Actor Loss:  -1508.8020020; Critic Loss:   1653.8444824; Batch Reward:   -166.9598524\n",
      "Actor Loss:  -1484.0224609; Critic Loss:   1710.6862793; Batch Reward:   -227.1435457\n",
      "Actor Loss:  -1764.7929688; Critic Loss:   2200.4912109; Batch Reward:   -278.9978162\n",
      "Actor Loss:  -1685.9459229; Critic Loss:   1671.2041016; Batch Reward:   -216.0428754\n",
      "Actor Loss:  -1894.8760986; Critic Loss:   2492.7192383; Batch Reward:   -270.9206392\n",
      "Actor Loss:  -1610.1142578; Critic Loss:   3093.2326660; Batch Reward:   -279.3800143\n",
      "Actor Loss:  -1822.0809326; Critic Loss:   1660.6651611; Batch Reward:   -192.7018565\n",
      "Actor Loss:  -1917.9586182; Critic Loss:   3378.4604492; Batch Reward:   -337.9911014\n",
      "Actor Loss:  -1859.5109863; Critic Loss:   1363.4892578; Batch Reward:   -184.6080558\n",
      "Actor Loss:  -1559.9233398; Critic Loss:   2519.6149902; Batch Reward:   -267.0268235\n",
      "Actor Loss:  -1964.5874023; Critic Loss:   1778.4710693; Batch Reward:   -208.8409146\n",
      "Actor Loss:  -2024.0249023; Critic Loss:   3819.1520996; Batch Reward:   -343.5561248\n",
      "Actor Loss:  -1786.8741455; Critic Loss:   2370.1201172; Batch Reward:   -183.0606308\n",
      "Actor Loss:  -1964.1864014; Critic Loss:   3730.9123535; Batch Reward:   -323.1672849\n",
      "Actor Loss:  -1979.5169678; Critic Loss:   3915.9030762; Batch Reward:   -348.8196888\n",
      "Actor Loss:  -1659.5561523; Critic Loss:   3031.7744141; Batch Reward:   -265.1950497\n",
      "Actor Loss:  -2737.6791992; Critic Loss:   5395.1708984; Batch Reward:   -433.6261605\n",
      "Actor Loss:  -1664.4102783; Critic Loss:   2034.4852295; Batch Reward:   -211.0336862\n",
      "Actor Loss:  -1859.2156982; Critic Loss:   3042.8945312; Batch Reward:   -323.9369601\n",
      "Actor Loss:  -1941.9730225; Critic Loss:   1462.2402344; Batch Reward:   -183.5786835\n",
      "Actor Loss:  -2057.8537598; Critic Loss:   3160.0695801; Batch Reward:   -305.9938595\n",
      "Actor Loss:  -1853.2520752; Critic Loss:   2206.9758301; Batch Reward:   -225.4495284\n",
      "Actor Loss:  -1510.0550537; Critic Loss:   3097.7646484; Batch Reward:   -235.0492382\n",
      "Actor Loss:  -1802.3482666; Critic Loss:   1867.3535156; Batch Reward:   -178.6654517\n",
      "Actor Loss:  -1900.9677734; Critic Loss:   3558.5798340; Batch Reward:   -330.0339369\n",
      "Actor Loss:  -1717.5019531; Critic Loss:   1814.3404541; Batch Reward:   -201.3511026\n",
      "Actor Loss:  -1537.9942627; Critic Loss:   2653.3786621; Batch Reward:   -256.5909853\n",
      "Actor Loss:  -1722.5424805; Critic Loss:   2922.2780762; Batch Reward:   -299.4167757\n",
      "Actor Loss:  -1328.5242920; Critic Loss:   2934.7038574; Batch Reward:   -203.7278858\n",
      "Actor Loss:  -1552.4907227; Critic Loss:   2872.0239258; Batch Reward:   -272.8166612\n",
      "Actor Loss:  -1484.4257812; Critic Loss:   1392.5646973; Batch Reward:   -177.2806070\n",
      "Actor Loss:  -1500.4736328; Critic Loss:   3048.3488770; Batch Reward:   -257.0494315\n",
      "Actor Loss:  -1316.4804688; Critic Loss:   2918.3552246; Batch Reward:   -228.7341368\n",
      "Actor Loss:  -1534.4752197; Critic Loss:   2836.6882324; Batch Reward:   -257.0512238\n",
      "Actor Loss:  -1540.7088623; Critic Loss:   3908.5983887; Batch Reward:   -311.4727221\n",
      "Actor Loss:  -1410.4398193; Critic Loss:   1656.7841797; Batch Reward:   -183.0295382\n",
      "Actor Loss:  -2259.1894531; Critic Loss:   7746.9726562; Batch Reward:   -461.2040443\n",
      "Actor Loss:  -1360.3857422; Critic Loss:   3987.1445312; Batch Reward:   -314.8384226\n",
      "Actor Loss:  -1507.1464844; Critic Loss:   2249.1457520; Batch Reward:   -226.7865117\n",
      "Actor Loss:  -2643.8063965; Critic Loss:   5453.1845703; Batch Reward:   -427.7911362\n",
      "Actor Loss:  -1527.3989258; Critic Loss:   4001.9750977; Batch Reward:   -295.9954769\n",
      "Actor Loss:  -1870.3227539; Critic Loss:   1325.5292969; Batch Reward:   -177.0992800\n",
      "Actor Loss:  -2582.8442383; Critic Loss:   3404.6130371; Batch Reward:   -373.1817166\n",
      "Actor Loss:  -1939.1838379; Critic Loss:   2364.3952637; Batch Reward:   -203.6805261\n",
      "Actor Loss:  -1810.2913818; Critic Loss:   3485.9663086; Batch Reward:   -217.3155423\n",
      "Actor Loss:  -2203.0317383; Critic Loss:   4304.0000000; Batch Reward:   -299.3445144\n",
      "Actor Loss:  -1770.3729248; Critic Loss:   2864.1091309; Batch Reward:   -200.0122558\n",
      "Actor Loss:  -1844.6467285; Critic Loss:   2695.8652344; Batch Reward:   -211.1355461\n",
      "Actor Loss:  -1731.6405029; Critic Loss:   2622.0190430; Batch Reward:   -165.2405935\n",
      "Actor Loss:  -1992.5666504; Critic Loss:   2601.3186035; Batch Reward:   -310.4372362\n",
      "Actor Loss:  -1750.9010010; Critic Loss:   1887.5673828; Batch Reward:   -198.7715092\n",
      "Actor Loss:  -1731.0601807; Critic Loss:   2926.6284180; Batch Reward:   -280.2928497\n",
      "Actor Loss:  -1651.6127930; Critic Loss:   1082.3963623; Batch Reward:   -187.3837404\n",
      "Actor Loss:  -2590.1542969; Critic Loss:   9279.7744141; Batch Reward:   -517.3750110\n",
      "Actor Loss:  -1383.7750244; Critic Loss:   1983.6665039; Batch Reward:   -250.0273970\n",
      "Actor Loss:  -1652.2440186; Critic Loss:   2514.7172852; Batch Reward:   -254.2069796\n",
      "Actor Loss:  -2122.3254395; Critic Loss:   5496.3271484; Batch Reward:   -409.2956666\n",
      "Actor Loss:  -1414.7701416; Critic Loss:   1616.2219238; Batch Reward:   -196.0926166\n",
      "Actor Loss:  -1648.0844727; Critic Loss:   2042.9366455; Batch Reward:   -205.4197275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2106.5185547; Critic Loss:   3226.5368652; Batch Reward:   -353.4763035\n",
      "Actor Loss:  -1585.8537598; Critic Loss:   2060.5383301; Batch Reward:   -175.8987587\n",
      "Actor Loss:  -1597.9851074; Critic Loss:   2813.8398438; Batch Reward:   -235.5551370\n",
      "Actor Loss:  -2123.2526855; Critic Loss:   4237.6826172; Batch Reward:   -344.0866790\n",
      "Actor Loss:  -1577.4833984; Critic Loss:   1400.6983643; Batch Reward:   -177.7753954\n",
      "Actor Loss:  -2720.8403320; Critic Loss:   5021.3964844; Batch Reward:   -432.1472578\n",
      "Actor Loss:  -1504.2384033; Critic Loss:   2467.8376465; Batch Reward:   -213.2222942\n",
      "Actor Loss:  -2084.6850586; Critic Loss:   3416.4682617; Batch Reward:   -290.1741274\n",
      "Actor Loss:  -2689.4592285; Critic Loss:   3530.4975586; Batch Reward:   -407.0304380\n",
      "Actor Loss:  -1421.7253418; Critic Loss:   3329.2336426; Batch Reward:   -238.8265226\n",
      "Actor Loss:  -1921.2342529; Critic Loss:   1587.5911865; Batch Reward:   -186.1586495\n",
      "Actor Loss:  -2344.3774414; Critic Loss:   3768.6408691; Batch Reward:   -314.8047138\n",
      "Actor Loss:  -2029.5988770; Critic Loss:   2641.5693359; Batch Reward:   -244.4560057\n",
      "Actor Loss:  -1549.3912354; Critic Loss:   2694.7309570; Batch Reward:   -210.1006631\n",
      "Actor Loss:  -1862.0375977; Critic Loss:   2191.1850586; Batch Reward:   -222.2577121\n",
      "Actor Loss:  -1535.6827393; Critic Loss:   3343.7871094; Batch Reward:   -231.5226734\n",
      "Actor Loss:  -1790.1175537; Critic Loss:   2228.6713867; Batch Reward:   -240.5956013\n",
      "Actor Loss:  -1607.3568115; Critic Loss:   1847.5571289; Batch Reward:   -205.3238269\n",
      "Actor Loss:  -1737.6589355; Critic Loss:   3546.5708008; Batch Reward:   -325.2164867\n",
      "Actor Loss:  -1655.4196777; Critic Loss:   1390.5277100; Batch Reward:   -191.5007321\n",
      "Actor Loss:  -1961.2736816; Critic Loss:   5440.0229492; Batch Reward:   -390.9238397\n",
      "Actor Loss:  -1364.8265381; Critic Loss:   1645.9787598; Batch Reward:   -171.0475256\n",
      "Actor Loss:  -1576.5539551; Critic Loss:   1972.2718506; Batch Reward:   -217.8546250\n",
      "Actor Loss:  -2460.8696289; Critic Loss:   8961.0292969; Batch Reward:   -466.3254463\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -1575.2170410; Critic Loss:   4793.3974609; Batch Reward:   -323.8876849\n",
      "Actor Loss:  -1775.6146240; Critic Loss:   2022.1822510; Batch Reward:   -289.7693316\n",
      "Actor Loss:  -2880.9924316; Critic Loss:   6216.3212891; Batch Reward:   -472.4492456\n",
      "Actor Loss:  -1695.5860596; Critic Loss:   1366.8814697; Batch Reward:   -170.0186230\n",
      "Actor Loss:  -2102.8701172; Critic Loss:   2471.2907715; Batch Reward:   -293.3312017\n",
      "Actor Loss:  -1996.5386963; Critic Loss:   2871.0358887; Batch Reward:   -237.7772324\n",
      "Actor Loss:  -2278.3410645; Critic Loss:   3217.7612305; Batch Reward:   -296.5290913\n",
      "Actor Loss:  -2104.9033203; Critic Loss:   2462.4396973; Batch Reward:   -195.5374080\n",
      "Actor Loss:  -2329.2038574; Critic Loss:   3518.8046875; Batch Reward:   -342.2695989\n",
      "Actor Loss:  -2321.5458984; Critic Loss:   2428.1462402; Batch Reward:   -306.0126421\n",
      "Actor Loss:  -1983.3662109; Critic Loss:   2476.0410156; Batch Reward:   -286.6258580\n",
      "Actor Loss:  -1897.6638184; Critic Loss:   2770.4960938; Batch Reward:   -219.1651613\n",
      "Actor Loss:  -1591.0906982; Critic Loss:   3456.9797363; Batch Reward:   -262.5177126\n",
      "Actor Loss:  -1985.8900146; Critic Loss:   3168.9392090; Batch Reward:   -302.8974604\n",
      "Actor Loss:  -1821.5209961; Critic Loss:   2134.6008301; Batch Reward:   -175.9765463\n",
      "Actor Loss:  -2502.0603027; Critic Loss:   5658.6704102; Batch Reward:   -427.7724924\n",
      "Actor Loss:  -1605.1259766; Critic Loss:   1397.2669678; Batch Reward:   -178.7922467\n",
      "Actor Loss:  -1873.0626221; Critic Loss:   3342.4414062; Batch Reward:   -354.8815324\n",
      "Actor Loss:  -1525.9105225; Critic Loss:   2139.4694824; Batch Reward:   -209.7699409\n",
      "Actor Loss:  -1611.1520996; Critic Loss:   2230.0253906; Batch Reward:   -224.3588528\n",
      "Actor Loss:  -1867.1701660; Critic Loss:   5627.9785156; Batch Reward:   -397.2746653\n",
      "Actor Loss:  -1440.5137939; Critic Loss:   1782.5887451; Batch Reward:   -176.6135433\n",
      "Actor Loss:  -1692.3409424; Critic Loss:   2902.7814941; Batch Reward:   -250.3164720\n",
      "Actor Loss:  -1904.8952637; Critic Loss:   3856.7094727; Batch Reward:   -376.6486780\n",
      "Actor Loss:  -1694.7863770; Critic Loss:   1310.5853271; Batch Reward:   -195.1269972\n",
      "Actor Loss:  -1766.2795410; Critic Loss:   3158.7268066; Batch Reward:   -269.9857759\n",
      "Actor Loss:  -1735.8522949; Critic Loss:   2086.0073242; Batch Reward:   -189.7240226\n",
      "Actor Loss:  -2546.5273438; Critic Loss:   5216.2309570; Batch Reward:   -448.7203254\n",
      "Actor Loss:  -1569.6257324; Critic Loss:   1506.4549561; Batch Reward:   -175.6979389\n",
      "Actor Loss:  -1957.2775879; Critic Loss:   2201.4916992; Batch Reward:   -220.2240146\n",
      "Actor Loss:  -3079.1782227; Critic Loss:   6915.8691406; Batch Reward:   -480.8057422\n",
      "Actor Loss:  -1653.5319824; Critic Loss:   3739.7202148; Batch Reward:   -276.7030305\n",
      "Actor Loss:  -1820.6783447; Critic Loss:   2822.2583008; Batch Reward:   -172.4280226\n",
      "Actor Loss:  -2332.9968262; Critic Loss:   2730.0161133; Batch Reward:   -314.4822454\n",
      "Actor Loss:  -2126.5771484; Critic Loss:   3010.8425293; Batch Reward:   -234.1441434\n",
      "Actor Loss:  -2054.8793945; Critic Loss:   2933.3015137; Batch Reward:   -253.1936049\n",
      "Actor Loss:  -1943.0583496; Critic Loss:   2372.0908203; Batch Reward:   -244.6179886\n",
      "Actor Loss:  -1916.4429932; Critic Loss:   2224.1726074; Batch Reward:   -198.7637001\n",
      "Actor Loss:  -2538.1726074; Critic Loss:   4392.4194336; Batch Reward:   -383.9596960\n",
      "Actor Loss:  -1818.5915527; Critic Loss:   1196.0039062; Batch Reward:   -181.8836346\n",
      "Actor Loss:  -2217.6723633; Critic Loss:   2894.9399414; Batch Reward:   -348.9237308\n",
      "Actor Loss:  -1608.1204834; Critic Loss:   2211.0546875; Batch Reward:   -216.1004319\n",
      "Actor Loss:  -1595.4138184; Critic Loss:   1568.5401611; Batch Reward:   -191.3449201\n",
      "Actor Loss:  -1790.9531250; Critic Loss:   2722.3925781; Batch Reward:   -268.5083273\n",
      "Actor Loss:  -1483.9543457; Critic Loss:   2020.2089844; Batch Reward:   -235.5510464\n",
      "Actor Loss:  -1554.5391846; Critic Loss:   2891.0246582; Batch Reward:   -296.2508092\n",
      "Actor Loss:  -1438.9700928; Critic Loss:   1996.0540771; Batch Reward:   -219.4003812\n",
      "Actor Loss:  -1464.8154297; Critic Loss:   1520.4980469; Batch Reward:   -205.3667209\n",
      "Actor Loss:  -2235.0185547; Critic Loss:   8818.7470703; Batch Reward:   -464.7641444\n",
      "Actor Loss:  -1353.6242676; Critic Loss:   1585.9315186; Batch Reward:   -212.8203196\n",
      "Actor Loss:  -1656.7858887; Critic Loss:   2518.2673340; Batch Reward:   -263.2624376\n",
      "Actor Loss:  -1937.3326416; Critic Loss:   4125.1269531; Batch Reward:   -374.6622417\n",
      "Actor Loss:  -1553.0048828; Critic Loss:   1747.1289062; Batch Reward:   -175.9639449\n",
      "Actor Loss:  -1885.7838135; Critic Loss:   2654.7041016; Batch Reward:   -291.3187294\n",
      "Actor Loss:  -1779.4296875; Critic Loss:   2930.7009277; Batch Reward:   -272.9389047\n",
      "Actor Loss:  -1814.0106201; Critic Loss:   1972.9552002; Batch Reward:   -215.9399717\n",
      "Actor Loss:  -1863.5012207; Critic Loss:   2000.8326416; Batch Reward:   -227.7568877\n",
      "Actor Loss:  -1884.1926270; Critic Loss:   2261.7377930; Batch Reward:   -253.2518908\n",
      "Actor Loss:  -1993.9516602; Critic Loss:   2276.1274414; Batch Reward:   -217.9642952\n",
      "Actor Loss:  -2919.8837891; Critic Loss:   5989.1879883; Batch Reward:   -449.8016263\n",
      "Actor Loss:  -1673.8099365; Critic Loss:   2715.1315918; Batch Reward:   -262.2129861\n",
      "Actor Loss:  -2261.3247070; Critic Loss:   2944.8400879; Batch Reward:   -329.8461556\n",
      "Actor Loss:  -2139.6579590; Critic Loss:   3029.7514648; Batch Reward:   -297.7712059\n",
      "Actor Loss:  -1890.9912109; Critic Loss:   1682.5666504; Batch Reward:   -194.4348968\n",
      "Actor Loss:  -2070.2539062; Critic Loss:   2250.2741699; Batch Reward:   -269.0024975\n",
      "Actor Loss:  -1893.8205566; Critic Loss:   1968.8120117; Batch Reward:   -189.5265141\n",
      "Actor Loss:  -2095.0690918; Critic Loss:   3123.0605469; Batch Reward:   -316.9371264\n",
      "Actor Loss:  -1755.2401123; Critic Loss:   2529.7807617; Batch Reward:   -179.7601062\n",
      "Actor Loss:  -1668.3232422; Critic Loss:   1808.3178711; Batch Reward:   -191.9800971\n",
      "Actor Loss:  -1779.3482666; Critic Loss:   1668.5354004; Batch Reward:   -197.9383279\n",
      "Actor Loss:  -1706.1334229; Critic Loss:   1901.6656494; Batch Reward:   -217.4069525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -1589.1784668; Critic Loss:   1514.4897461; Batch Reward:   -198.2097276\n",
      "Actor Loss:  -1448.5083008; Critic Loss:   1820.1807861; Batch Reward:   -219.4574161\n",
      "Actor Loss:  -1502.1944580; Critic Loss:   3837.5480957; Batch Reward:   -341.6277342\n",
      "Actor Loss:  -1142.9907227; Critic Loss:   2337.3442383; Batch Reward:   -212.0277774\n",
      "Actor Loss:  -1392.3955078; Critic Loss:   1700.3935547; Batch Reward:   -203.7117516\n",
      "Actor Loss:  -1427.1914062; Critic Loss:   2648.6838379; Batch Reward:   -228.6184525\n",
      "Actor Loss:  -1348.6450195; Critic Loss:   1772.9803467; Batch Reward:   -187.5381460\n",
      "Actor Loss:  -1584.7917480; Critic Loss:   4664.4394531; Batch Reward:   -359.0690908\n",
      "Actor Loss:  -1235.7685547; Critic Loss:   1952.6529541; Batch Reward:   -216.3148371\n",
      "Actor Loss:  -1495.8917236; Critic Loss:   2704.0485840; Batch Reward:   -272.0842155\n",
      "Actor Loss:  -1471.7686768; Critic Loss:   3691.5097656; Batch Reward:   -329.4517130\n",
      "Actor Loss:  -1336.4036865; Critic Loss:   1878.9729004; Batch Reward:   -220.7431479\n",
      "Actor Loss:  -1702.0422363; Critic Loss:   2879.9006348; Batch Reward:   -277.8083493\n",
      "Actor Loss:  -1402.5026855; Critic Loss:   1871.0888672; Batch Reward:   -188.6232973\n",
      "Actor Loss:  -1590.9228516; Critic Loss:   1766.5332031; Batch Reward:   -184.8413826\n",
      "Actor Loss:  -1660.1190186; Critic Loss:   1287.7431641; Batch Reward:   -212.9028783\n",
      "Actor Loss:  -1752.6024170; Critic Loss:   1785.5755615; Batch Reward:   -198.4017805\n",
      "Actor Loss:  -1621.1899414; Critic Loss:   2228.4733887; Batch Reward:   -234.1019554\n",
      "Actor Loss:  -1488.8049316; Critic Loss:   1711.2958984; Batch Reward:   -191.4672895\n",
      "Actor Loss:  -2200.1022949; Critic Loss:   5941.5463867; Batch Reward:   -426.1818172\n",
      "Actor Loss:  -1659.8774414; Critic Loss:   3985.1801758; Batch Reward:   -322.2421290\n",
      "Actor Loss:  -1802.2592773; Critic Loss:   1846.4344482; Batch Reward:   -255.8939134\n",
      "Actor Loss:  -1998.9195557; Critic Loss:   2970.5461426; Batch Reward:   -357.4403248\n",
      "Actor Loss:  -1741.8377686; Critic Loss:   1546.5986328; Batch Reward:   -191.9093506\n",
      "Actor Loss:  -2085.6140137; Critic Loss:   2930.9570312; Batch Reward:   -310.7906434\n",
      "Actor Loss:  -1684.6884766; Critic Loss:   2009.7259521; Batch Reward:   -196.9466761\n",
      "Actor Loss:  -1996.0761719; Critic Loss:   2453.5244141; Batch Reward:   -199.8845899\n",
      "Actor Loss:  -2009.3648682; Critic Loss:   1980.6883545; Batch Reward:   -179.0396400\n",
      "Actor Loss:  -1958.7324219; Critic Loss:   2241.4902344; Batch Reward:   -193.7252367\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -1803.9183350; Critic Loss:   1765.8131104; Batch Reward:   -195.6104876\n",
      "Actor Loss:  -1923.2152100; Critic Loss:   2315.8854980; Batch Reward:   -263.4540838\n",
      "Actor Loss:  -1459.3594971; Critic Loss:   3052.7126465; Batch Reward:   -195.2417719\n",
      "Actor Loss:  -1607.0133057; Critic Loss:   2820.3376465; Batch Reward:   -257.6435238\n",
      "Actor Loss:  -1546.4888916; Critic Loss:   1883.0831299; Batch Reward:   -220.3327541\n",
      "Actor Loss:  -1572.7379150; Critic Loss:   1074.0812988; Batch Reward:   -175.3631907\n",
      "Actor Loss:  -1285.3662109; Critic Loss:   2570.0319824; Batch Reward:   -229.0164167\n",
      "Actor Loss:  -1280.6351318; Critic Loss:   2179.4162598; Batch Reward:   -217.8422412\n",
      "Actor Loss:  -1322.0885010; Critic Loss:   1836.2753906; Batch Reward:   -209.2871855\n",
      "Actor Loss:  -1400.7144775; Critic Loss:   1612.1326904; Batch Reward:   -190.0808456\n",
      "Actor Loss:  -1217.5700684; Critic Loss:   1397.4771729; Batch Reward:   -179.9032576\n",
      "Actor Loss:  -1164.1104736; Critic Loss:   3010.9997559; Batch Reward:   -266.3911005\n",
      "Actor Loss:  -1233.3531494; Critic Loss:    840.3226318; Batch Reward:   -170.2275355\n",
      "Actor Loss:  -1142.9991455; Critic Loss:   1911.7460938; Batch Reward:   -205.5600108\n",
      "Actor Loss:  -1172.4259033; Critic Loss:   1660.2480469; Batch Reward:   -217.5073165\n",
      "Actor Loss:  -1214.7250977; Critic Loss:   1445.7690430; Batch Reward:   -199.5052584\n",
      "Actor Loss:  -1198.4249268; Critic Loss:   1622.9902344; Batch Reward:   -227.1949423\n",
      "Actor Loss:  -1285.7818604; Critic Loss:   1292.5836182; Batch Reward:   -171.0312106\n",
      "Actor Loss:  -1206.4296875; Critic Loss:   2387.5007324; Batch Reward:   -258.1582791\n",
      "Actor Loss:  -1287.4438477; Critic Loss:   1604.7927246; Batch Reward:   -201.3228600\n",
      "Actor Loss:  -1274.6003418; Critic Loss:   1651.7265625; Batch Reward:   -207.3450154\n",
      "Actor Loss:  -1311.4875488; Critic Loss:   2437.2077637; Batch Reward:   -237.6833570\n",
      "Actor Loss:  -1352.7342529; Critic Loss:   2534.7561035; Batch Reward:   -204.7162543\n",
      "Actor Loss:  -1334.2285156; Critic Loss:   2911.0446777; Batch Reward:   -267.6939830\n",
      "Actor Loss:  -1480.1304932; Critic Loss:   2356.8950195; Batch Reward:   -217.1619560\n",
      "Actor Loss:  -1446.0555420; Critic Loss:   4827.9267578; Batch Reward:   -365.4283977\n",
      "Actor Loss:  -1612.5648193; Critic Loss:   3756.5349121; Batch Reward:   -269.2144317\n",
      "Actor Loss:  -1653.9819336; Critic Loss:   2058.9367676; Batch Reward:   -275.2038144\n",
      "Actor Loss:  -1651.9863281; Critic Loss:   2782.7814941; Batch Reward:   -235.3790026\n",
      "Actor Loss:  -1811.8769531; Critic Loss:   2023.4677734; Batch Reward:   -231.8326613\n",
      "Actor Loss:  -1827.5889893; Critic Loss:   3919.2138672; Batch Reward:   -288.1749925\n",
      "Actor Loss:  -1962.4183350; Critic Loss:   2873.8913574; Batch Reward:   -289.6798980\n",
      "Actor Loss:  -2062.2524414; Critic Loss:   1826.0488281; Batch Reward:   -203.6884758\n",
      "Actor Loss:  -2636.6452637; Critic Loss:   4319.6367188; Batch Reward:   -441.3878026\n",
      "Actor Loss:  -1966.6174316; Critic Loss:   2720.5004883; Batch Reward:   -241.7970717\n",
      "Actor Loss:  -2092.8820801; Critic Loss:   2762.5385742; Batch Reward:   -225.9548981\n",
      "Actor Loss:  -1975.2886963; Critic Loss:   3404.8525391; Batch Reward:   -196.4220206\n",
      "Actor Loss:  -1920.4753418; Critic Loss:   2049.8259277; Batch Reward:   -207.9915509\n",
      "Actor Loss:  -1948.5013428; Critic Loss:   2393.7656250; Batch Reward:   -221.3661299\n",
      "Actor Loss:  -1744.4067383; Critic Loss:   2171.3437500; Batch Reward:   -205.6391409\n",
      "Actor Loss:  -1742.2550049; Critic Loss:   1361.9769287; Batch Reward:   -194.3457760\n",
      "Actor Loss:  -1464.5666504; Critic Loss:   2357.7355957; Batch Reward:   -221.2305850\n",
      "Actor Loss:  -1571.6201172; Critic Loss:   1513.7583008; Batch Reward:   -198.7431667\n",
      "Actor Loss:  -1438.6979980; Critic Loss:   1493.8455811; Batch Reward:   -211.1248036\n",
      "Actor Loss:  -1340.5148926; Critic Loss:   1871.5513916; Batch Reward:   -209.4160799\n",
      "Actor Loss:  -1364.4383545; Critic Loss:   1862.0805664; Batch Reward:   -218.4227552\n",
      "Actor Loss:  -1166.5310059; Critic Loss:   1969.0296631; Batch Reward:   -206.9885159\n",
      "Actor Loss:  -1212.1599121; Critic Loss:   1511.4580078; Batch Reward:   -215.9649926\n",
      "Actor Loss:  -1106.9543457; Critic Loss:   2019.3792725; Batch Reward:   -220.6202759\n",
      "Actor Loss:  -1148.8422852; Critic Loss:   1725.3179932; Batch Reward:   -195.4542346\n",
      "Actor Loss:  -1312.6179199; Critic Loss:   5095.4775391; Batch Reward:   -318.8585558\n",
      "Actor Loss:  -1172.8409424; Critic Loss:   1837.6348877; Batch Reward:   -201.0764902\n",
      "Actor Loss:  -1109.6198730; Critic Loss:   2754.2673340; Batch Reward:   -230.6222418\n",
      "Actor Loss:  -1234.1281738; Critic Loss:   2563.8195801; Batch Reward:   -261.7678370\n",
      "Actor Loss:  -1181.9541016; Critic Loss:   2381.5722656; Batch Reward:   -229.6893209\n",
      "Actor Loss:  -1352.8205566; Critic Loss:   3114.5410156; Batch Reward:   -274.2103289\n",
      "Actor Loss:  -1311.1192627; Critic Loss:   1429.0770264; Batch Reward:   -205.5344689\n",
      "Actor Loss:  -1445.8266602; Critic Loss:   1574.4755859; Batch Reward:   -223.6532395\n",
      "Actor Loss:  -1513.7563477; Critic Loss:   2388.7258301; Batch Reward:   -264.5385228\n",
      "Actor Loss:  -1504.8291016; Critic Loss:   2140.8808594; Batch Reward:   -247.9954579\n",
      "Actor Loss:  -1535.8151855; Critic Loss:   1522.5631104; Batch Reward:   -193.9170232\n",
      "Actor Loss:  -2342.8266602; Critic Loss:   6334.6552734; Batch Reward:   -434.9323514\n",
      "Actor Loss:  -1713.1135254; Critic Loss:   2577.8405762; Batch Reward:   -236.6082379\n",
      "Actor Loss:  -2033.3433838; Critic Loss:   2013.7269287; Batch Reward:   -283.4715127\n",
      "Actor Loss:  -1797.6546631; Critic Loss:   2189.9472656; Batch Reward:   -206.5927685\n",
      "Actor Loss:  -1992.4067383; Critic Loss:   1958.2265625; Batch Reward:   -190.2019756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2094.4174805; Critic Loss:   3128.7468262; Batch Reward:   -267.1245167\n",
      "Actor Loss:  -2073.0302734; Critic Loss:   1771.2359619; Batch Reward:   -195.3375229\n",
      "Actor Loss:  -2023.1950684; Critic Loss:   2212.9157715; Batch Reward:   -250.3128146\n",
      "Actor Loss:  -2038.4438477; Critic Loss:   2128.4780273; Batch Reward:   -204.1148408\n",
      "Actor Loss:  -1767.5330811; Critic Loss:   2133.3571777; Batch Reward:   -213.3116398\n",
      "Actor Loss:  -1708.4010010; Critic Loss:   1780.8090820; Batch Reward:   -196.2607651\n",
      "Actor Loss:  -1638.1207275; Critic Loss:   2634.3049316; Batch Reward:   -243.2914788\n",
      "Actor Loss:  -1703.0776367; Critic Loss:   1452.0113525; Batch Reward:   -204.1287293\n",
      "Actor Loss:  -1654.8857422; Critic Loss:   2059.1989746; Batch Reward:   -230.9250396\n",
      "Actor Loss:  -1447.1323242; Critic Loss:   1577.9160156; Batch Reward:   -217.9427839\n",
      "Actor Loss:  -1551.0017090; Critic Loss:   2949.7714844; Batch Reward:   -275.9741871\n",
      "Actor Loss:  -1386.2708740; Critic Loss:   2076.0131836; Batch Reward:   -238.1099903\n",
      "Actor Loss:  -1553.5068359; Critic Loss:   3555.6232910; Batch Reward:   -275.7748795\n",
      "Actor Loss:  -1365.0170898; Critic Loss:   1830.6767578; Batch Reward:   -220.4553944\n",
      "Actor Loss:  -1476.9049072; Critic Loss:   3810.8449707; Batch Reward:   -293.5829043\n",
      "Actor Loss:  -1356.4763184; Critic Loss:   2253.0913086; Batch Reward:   -240.8631499\n",
      "Actor Loss:  -1538.2194824; Critic Loss:   1993.0955811; Batch Reward:   -240.2974443\n",
      "Actor Loss:  -1926.4714355; Critic Loss:   5990.1650391; Batch Reward:   -378.5009144\n",
      "Actor Loss:  -1629.2174072; Critic Loss:   1475.7951660; Batch Reward:   -200.1812095\n",
      "Actor Loss:  -2485.3361816; Critic Loss:   6407.5117188; Batch Reward:   -415.4128522\n",
      "Actor Loss:  -1532.2729492; Critic Loss:   4414.2148438; Batch Reward:   -303.2603457\n",
      "Actor Loss:  -2169.2031250; Critic Loss:   2028.3338623; Batch Reward:   -268.6722929\n",
      "Actor Loss:  -2683.2526855; Critic Loss:   4207.6542969; Batch Reward:   -362.3306732\n",
      "Actor Loss:  -2371.0039062; Critic Loss:   2229.3227539; Batch Reward:   -195.7128807\n",
      "Actor Loss:  -3403.0847168; Critic Loss:   4116.0986328; Batch Reward:   -398.7041145\n",
      "Actor Loss:  -2055.2387695; Critic Loss:   2398.6159668; Batch Reward:   -280.4387202\n",
      "Actor Loss:  -3081.2431641; Critic Loss:   2902.4765625; Batch Reward:   -303.4787524\n",
      "Actor Loss:  -2794.9296875; Critic Loss:   3800.9780273; Batch Reward:   -265.2035665\n",
      "Actor Loss:  -2574.0383301; Critic Loss:   3071.5144043; Batch Reward:   -214.8448348\n",
      "Actor Loss:  -2441.9943848; Critic Loss:   3228.1899414; Batch Reward:   -205.1739406\n",
      "Actor Loss:  -2270.5236816; Critic Loss:   2265.4714355; Batch Reward:   -226.5120727\n",
      "Actor Loss:  -2217.4580078; Critic Loss:   2606.5283203; Batch Reward:   -222.6738216\n",
      "Actor Loss:  -1966.2763672; Critic Loss:   1932.9450684; Batch Reward:   -185.7634395\n",
      "Actor Loss:  -1761.0622559; Critic Loss:   2178.4252930; Batch Reward:   -241.2525558\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -1724.9619141; Critic Loss:   1772.4321289; Batch Reward:   -215.4304756\n",
      "Actor Loss:  -1508.1618652; Critic Loss:   3023.1071777; Batch Reward:   -275.4565593\n",
      "Actor Loss:  -1419.4970703; Critic Loss:   1807.7231445; Batch Reward:   -214.1937524\n",
      "Actor Loss:  -1336.8503418; Critic Loss:   1905.4846191; Batch Reward:   -218.3521429\n",
      "Actor Loss:  -1270.5928955; Critic Loss:   3003.2641602; Batch Reward:   -245.9653892\n",
      "Actor Loss:  -1211.1717529; Critic Loss:   4188.4731445; Batch Reward:   -282.0859152\n",
      "Actor Loss:  -1133.6618652; Critic Loss:   3261.0119629; Batch Reward:   -245.9481060\n",
      "Actor Loss:  -1199.9346924; Critic Loss:   4175.1157227; Batch Reward:   -269.4898220\n",
      "Actor Loss:  -1408.1153564; Critic Loss:   7650.2338867; Batch Reward:   -353.6686463\n",
      "Actor Loss:  -1422.6582031; Critic Loss:   2700.2963867; Batch Reward:   -240.4863385\n",
      "Actor Loss:  -1636.3665771; Critic Loss:   6399.8706055; Batch Reward:   -363.9850516\n",
      "Actor Loss:  -1657.4466553; Critic Loss:   1396.5493164; Batch Reward:   -200.7878102\n",
      "Actor Loss:  -2228.1853027; Critic Loss:   7287.2114258; Batch Reward:   -393.1508683\n",
      "Actor Loss:  -1973.8879395; Critic Loss:   1901.3220215; Batch Reward:   -204.0097475\n",
      "Actor Loss:  -2713.1716309; Critic Loss:   4896.6357422; Batch Reward:   -388.8048597\n",
      "Actor Loss:  -2223.0842285; Critic Loss:   2296.4396973; Batch Reward:   -225.9392044\n",
      "Actor Loss:  -2907.3654785; Critic Loss:   3715.7290039; Batch Reward:   -371.8046589\n",
      "Actor Loss:  -2657.4191895; Critic Loss:   2714.7517090; Batch Reward:   -207.8236089\n",
      "Actor Loss:  -2652.0615234; Critic Loss:   3866.4306641; Batch Reward:   -220.3376646\n",
      "Actor Loss:  -2716.1796875; Critic Loss:   5394.9262695; Batch Reward:   -249.8828190\n",
      "Actor Loss:  -2698.5627441; Critic Loss:   3305.3972168; Batch Reward:   -215.1508581\n",
      "Actor Loss:  -2599.6823730; Critic Loss:   3096.2077637; Batch Reward:   -239.0911942\n",
      "Actor Loss:  -2295.6083984; Critic Loss:   4209.5898438; Batch Reward:   -269.2510050\n",
      "Actor Loss:  -2050.7961426; Critic Loss:   1646.6733398; Batch Reward:   -200.6000913\n",
      "Actor Loss:  -2163.3552246; Critic Loss:   3102.3659668; Batch Reward:   -278.2411935\n",
      "Actor Loss:  -2033.5169678; Critic Loss:   3268.8874512; Batch Reward:   -305.7666364\n",
      "Actor Loss:  -1759.4036865; Critic Loss:   1584.1470947; Batch Reward:   -210.4354750\n",
      "Actor Loss:  -1914.2971191; Critic Loss:   3735.8747559; Batch Reward:   -317.4102644\n",
      "Actor Loss:  -1496.4039307; Critic Loss:   2139.4797363; Batch Reward:   -187.1842912\n",
      "Actor Loss:  -1638.0114746; Critic Loss:   3898.9333496; Batch Reward:   -284.9463049\n",
      "Actor Loss:  -1566.9879150; Critic Loss:   3649.9958496; Batch Reward:   -279.4535725\n",
      "Actor Loss:  -1443.2387695; Critic Loss:   2953.5166016; Batch Reward:   -269.8435226\n",
      "Actor Loss:  -1624.6053467; Critic Loss:   4879.2612305; Batch Reward:   -320.2009505\n",
      "Actor Loss:  -1752.1966553; Critic Loss:   5197.2680664; Batch Reward:   -336.1844624\n",
      "Actor Loss:  -1783.3865967; Critic Loss:   2961.3186035; Batch Reward:   -270.0002874\n",
      "Actor Loss:  -2069.5854492; Critic Loss:   3236.9020996; Batch Reward:   -297.1522682\n",
      "Actor Loss:  -2048.0319824; Critic Loss:   2698.6992188; Batch Reward:   -272.7193716\n",
      "Actor Loss:  -2095.7231445; Critic Loss:   2573.7644043; Batch Reward:   -265.1512447\n",
      "Actor Loss:  -2282.8703613; Critic Loss:   2832.0114746; Batch Reward:   -265.7427950\n",
      "Actor Loss:  -2381.7067871; Critic Loss:   2619.4750977; Batch Reward:   -266.5135282\n",
      "Actor Loss:  -2582.3149414; Critic Loss:   3641.5031738; Batch Reward:   -307.1551651\n",
      "Actor Loss:  -2337.3371582; Critic Loss:   1878.0988770; Batch Reward:   -189.4420113\n",
      "Actor Loss:  -3425.6716309; Critic Loss:   5347.8452148; Batch Reward:   -428.7932559\n",
      "Actor Loss:  -2213.1237793; Critic Loss:   1751.8345947; Batch Reward:   -210.1474567\n",
      "Actor Loss:  -3082.4125977; Critic Loss:   3519.4968262; Batch Reward:   -352.7602146\n",
      "Actor Loss:  -2616.0361328; Critic Loss:   3472.7431641; Batch Reward:   -278.3182748\n",
      "Actor Loss:  -2432.5058594; Critic Loss:   2584.6230469; Batch Reward:   -184.8365377\n",
      "Actor Loss:  -2753.7727051; Critic Loss:   3116.0708008; Batch Reward:   -321.3082839\n",
      "Actor Loss:  -2404.7907715; Critic Loss:   3025.0729980; Batch Reward:   -291.0523279\n",
      "Actor Loss:  -2469.4282227; Critic Loss:   2613.7441406; Batch Reward:   -301.9708659\n",
      "Actor Loss:  -2213.3854980; Critic Loss:   1727.8389893; Batch Reward:   -212.3701173\n",
      "Actor Loss:  -2447.5646973; Critic Loss:   3712.2285156; Batch Reward:   -348.3697388\n",
      "Actor Loss:  -2195.6225586; Critic Loss:   2312.6992188; Batch Reward:   -250.1576083\n",
      "Actor Loss:  -2219.9816895; Critic Loss:   3647.7934570; Batch Reward:   -310.5179107\n",
      "Actor Loss:  -1934.7858887; Critic Loss:   2600.5205078; Batch Reward:   -186.8139394\n",
      "Actor Loss:  -1956.8812256; Critic Loss:   2786.0200195; Batch Reward:   -260.2783621\n",
      "Actor Loss:  -1920.5507812; Critic Loss:   3252.9941406; Batch Reward:   -294.8310251\n",
      "Actor Loss:  -1769.5820312; Critic Loss:   2341.0891113; Batch Reward:   -225.3559921\n",
      "Actor Loss:  -2057.4484863; Critic Loss:   4305.3056641; Batch Reward:   -346.3502565\n",
      "Actor Loss:  -2016.4040527; Critic Loss:   3413.4348145; Batch Reward:   -303.2313119\n",
      "Actor Loss:  -2102.1220703; Critic Loss:   4041.4921875; Batch Reward:   -326.8923821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2084.5241699; Critic Loss:   2736.7680664; Batch Reward:   -271.3242226\n",
      "Actor Loss:  -2145.5561523; Critic Loss:   2899.7614746; Batch Reward:   -278.2909208\n",
      "Actor Loss:  -2198.0349121; Critic Loss:   2581.1550293; Batch Reward:   -261.5106560\n",
      "Actor Loss:  -2520.6064453; Critic Loss:   4000.9428711; Batch Reward:   -347.3194463\n",
      "Actor Loss:  -2303.3288574; Critic Loss:   2591.1013184; Batch Reward:   -219.2209409\n",
      "Actor Loss:  -2497.6459961; Critic Loss:   3318.0520020; Batch Reward:   -289.1907139\n",
      "Actor Loss:  -2631.6076660; Critic Loss:   2796.4301758; Batch Reward:   -306.6507422\n",
      "Actor Loss:  -2527.8283691; Critic Loss:   3223.1455078; Batch Reward:   -268.3789497\n",
      "Actor Loss:  -2366.9038086; Critic Loss:   2177.4414062; Batch Reward:   -233.3662863\n",
      "Actor Loss:  -3143.9641113; Critic Loss:   5232.8178711; Batch Reward:   -423.7786430\n",
      "Actor Loss:  -2209.3164062; Critic Loss:   1754.4448242; Batch Reward:   -206.2336140\n",
      "Actor Loss:  -2861.0644531; Critic Loss:   3641.9653320; Batch Reward:   -365.1686635\n",
      "Actor Loss:  -2452.3007812; Critic Loss:   3311.1188965; Batch Reward:   -219.4847659\n",
      "Actor Loss:  -2539.5515137; Critic Loss:   3428.2841797; Batch Reward:   -302.8980236\n",
      "Actor Loss:  -2395.1899414; Critic Loss:   2200.0759277; Batch Reward:   -258.7064548\n",
      "Actor Loss:  -2413.0180664; Critic Loss:   3079.2448730; Batch Reward:   -272.5373919\n",
      "Actor Loss:  -2454.6823730; Critic Loss:   2623.1977539; Batch Reward:   -296.6678499\n",
      "Actor Loss:  -2330.0002441; Critic Loss:   3056.4377441; Batch Reward:   -313.7996133\n",
      "Actor Loss:  -2115.7009277; Critic Loss:   3241.0656738; Batch Reward:   -233.9474387\n",
      "Actor Loss:  -2535.9851074; Critic Loss:   4456.2441406; Batch Reward:   -373.9570230\n",
      "Actor Loss:  -2084.8620605; Critic Loss:   2297.7778320; Batch Reward:   -256.6053504\n",
      "Actor Loss:  -2406.6938477; Critic Loss:   3164.6464844; Batch Reward:   -331.4000229\n",
      "Actor Loss:  -2168.0097656; Critic Loss:   2900.7971191; Batch Reward:   -292.8419193\n",
      "Actor Loss:  -2706.8552246; Critic Loss:   4750.6953125; Batch Reward:   -382.2473761\n",
      "Actor Loss:  -2099.3857422; Critic Loss:   2149.7070312; Batch Reward:   -190.6839166\n",
      "Actor Loss:  -3047.3908691; Critic Loss:   4903.1777344; Batch Reward:   -398.3320302\n",
      "Actor Loss:  -2110.7282715; Critic Loss:   1922.3933105; Batch Reward:   -204.7450792\n",
      "Actor Loss:  -3084.1928711; Critic Loss:   4321.9013672; Batch Reward:   -389.9135897\n",
      "Actor Loss:  -2402.2773438; Critic Loss:   2572.0964355; Batch Reward:   -253.2547675\n",
      "Actor Loss:  -2585.1396484; Critic Loss:   2897.5231934; Batch Reward:   -277.1371547\n",
      "Actor Loss:  -2956.8662109; Critic Loss:   3094.7553711; Batch Reward:   -323.9526470\n",
      "Actor Loss:  -2599.6701660; Critic Loss:   2896.5502930; Batch Reward:   -275.2772195\n",
      "Actor Loss:  -2669.1164551; Critic Loss:   2723.1940918; Batch Reward:   -249.4490500\n",
      "Actor Loss:  -3205.8884277; Critic Loss:   5295.3466797; Batch Reward:   -425.2884027\n",
      "Actor Loss:  -2142.0214844; Critic Loss:   2058.5913086; Batch Reward:   -204.0551501\n",
      "Actor Loss:  -2535.5332031; Critic Loss:   2686.3220215; Batch Reward:   -288.6187726\n",
      "Actor Loss:  -2208.0148926; Critic Loss:   4105.1040039; Batch Reward:   -265.1330365\n",
      "Actor Loss:  -2188.6828613; Critic Loss:   2093.7741699; Batch Reward:   -246.9779014\n",
      "Actor Loss:  -2089.8730469; Critic Loss:   2495.9323730; Batch Reward:   -255.6654944\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2084.0839844; Critic Loss:   2493.2670898; Batch Reward:   -282.9324687\n",
      "Actor Loss:  -2226.3483887; Critic Loss:   3517.3227539; Batch Reward:   -323.8170463\n",
      "Actor Loss:  -2482.7888184; Critic Loss:   6253.1655273; Batch Reward:   -406.6044473\n",
      "Actor Loss:  -2154.0449219; Critic Loss:   2378.7192383; Batch Reward:   -247.7655405\n",
      "Actor Loss:  -2649.6611328; Critic Loss:   5680.1391602; Batch Reward:   -401.9776021\n",
      "Actor Loss:  -2144.6064453; Critic Loss:   1438.1821289; Batch Reward:   -205.1758868\n",
      "Actor Loss:  -3487.1240234; Critic Loss:   7071.9023438; Batch Reward:   -473.2352289\n",
      "Actor Loss:  -2232.0412598; Critic Loss:   1549.2352295; Batch Reward:   -215.6190091\n",
      "Actor Loss:  -3093.4472656; Critic Loss:   3160.0800781; Batch Reward:   -344.1326140\n",
      "Actor Loss:  -2626.3999023; Critic Loss:   2978.3671875; Batch Reward:   -237.5967328\n",
      "Actor Loss:  -3408.9301758; Critic Loss:   3174.8542480; Batch Reward:   -329.9118519\n",
      "Actor Loss:  -2777.2976074; Critic Loss:   3148.9929199; Batch Reward:   -225.1590953\n",
      "Actor Loss:  -3683.3359375; Critic Loss:   3480.6677246; Batch Reward:   -369.3109795\n",
      "Actor Loss:  -2682.9807129; Critic Loss:   3471.9504395; Batch Reward:   -226.2466535\n",
      "Actor Loss:  -3028.9309082; Critic Loss:   2950.3090820; Batch Reward:   -349.1079463\n",
      "Actor Loss:  -2346.8125000; Critic Loss:   2794.4096680; Batch Reward:   -241.7251974\n",
      "Actor Loss:  -2385.6777344; Critic Loss:   2628.3044434; Batch Reward:   -275.2778011\n",
      "Actor Loss:  -2171.6684570; Critic Loss:   2460.0690918; Batch Reward:   -281.9082780\n",
      "Actor Loss:  -2240.4592285; Critic Loss:   3704.6049805; Batch Reward:   -296.8393455\n",
      "Actor Loss:  -2344.9614258; Critic Loss:   4690.1000977; Batch Reward:   -349.6408435\n",
      "Actor Loss:  -1921.0823975; Critic Loss:   2007.6894531; Batch Reward:   -218.1647419\n",
      "Actor Loss:  -2142.0998535; Critic Loss:   3960.2290039; Batch Reward:   -331.5513344\n",
      "Actor Loss:  -1902.3001709; Critic Loss:   2356.7087402; Batch Reward:   -247.8601637\n",
      "Actor Loss:  -2234.4914551; Critic Loss:   4428.8857422; Batch Reward:   -355.9137673\n",
      "Actor Loss:  -1997.0789795; Critic Loss:   2991.9709473; Batch Reward:   -267.8667247\n",
      "Actor Loss:  -2163.5754395; Critic Loss:   3747.6750488; Batch Reward:   -297.7643390\n",
      "Actor Loss:  -2411.3200684; Critic Loss:   3703.9465332; Batch Reward:   -346.7904702\n",
      "Actor Loss:  -2280.7595215; Critic Loss:   2638.9062500; Batch Reward:   -242.5148354\n",
      "Actor Loss:  -2781.6188965; Critic Loss:   5847.7856445; Batch Reward:   -401.9378298\n",
      "Actor Loss:  -2267.3039551; Critic Loss:   2115.2136230; Batch Reward:   -198.2195123\n",
      "Actor Loss:  -3421.5717773; Critic Loss:   4711.1958008; Batch Reward:   -433.0094030\n",
      "Actor Loss:  -2517.7133789; Critic Loss:   2615.2375488; Batch Reward:   -186.0867475\n",
      "Actor Loss:  -3735.1220703; Critic Loss:   3514.6704102; Batch Reward:   -399.3701258\n",
      "Actor Loss:  -2696.3010254; Critic Loss:   3506.5642090; Batch Reward:   -198.5792708\n",
      "Actor Loss:  -2996.9758301; Critic Loss:   3003.5214844; Batch Reward:   -274.1994203\n",
      "Actor Loss:  -2688.2246094; Critic Loss:   3922.7836914; Batch Reward:   -241.4564449\n",
      "Actor Loss:  -2941.7004395; Critic Loss:   3075.4709473; Batch Reward:   -313.6741747\n",
      "Actor Loss:  -2527.6652832; Critic Loss:   2041.5031738; Batch Reward:   -291.5263071\n",
      "Actor Loss:  -2840.4675293; Critic Loss:   3442.5126953; Batch Reward:   -328.1904539\n",
      "Actor Loss:  -2300.6633301; Critic Loss:   2601.6711426; Batch Reward:   -268.1530015\n",
      "Actor Loss:  -2244.0029297; Critic Loss:   2410.3400879; Batch Reward:   -234.8144016\n",
      "Actor Loss:  -2547.1882324; Critic Loss:   4622.0502930; Batch Reward:   -339.8564552\n",
      "Actor Loss:  -2360.6667480; Critic Loss:   3295.3950195; Batch Reward:   -321.5956626\n",
      "Actor Loss:  -2233.0107422; Critic Loss:   3767.8820801; Batch Reward:   -292.3595193\n",
      "Actor Loss:  -1948.0434570; Critic Loss:   2067.7509766; Batch Reward:   -227.1928729\n",
      "Actor Loss:  -2378.1613770; Critic Loss:   3895.2927246; Batch Reward:   -336.1399377\n",
      "Actor Loss:  -1965.6359863; Critic Loss:   2509.9685059; Batch Reward:   -256.2184075\n",
      "Actor Loss:  -2275.1508789; Critic Loss:   2943.6931152; Batch Reward:   -299.6505869\n",
      "Actor Loss:  -2034.2733154; Critic Loss:   1555.4403076; Batch Reward:   -199.6140029\n",
      "Actor Loss:  -3094.6066895; Critic Loss:   9203.8583984; Batch Reward:   -477.4508901\n",
      "Actor Loss:  -2164.1677246; Critic Loss:   1658.4949951; Batch Reward:   -199.5121997\n",
      "Actor Loss:  -3340.1535645; Critic Loss:   6248.4951172; Batch Reward:   -430.9170806\n",
      "Actor Loss:  -2483.6188965; Critic Loss:   3029.9145508; Batch Reward:   -201.3816907\n",
      "Actor Loss:  -3667.2939453; Critic Loss:   3873.8627930; Batch Reward:   -397.8222764\n",
      "Actor Loss:  -3011.0131836; Critic Loss:   4003.2683105; Batch Reward:   -273.4643365\n",
      "Actor Loss:  -2827.6169434; Critic Loss:   3093.7668457; Batch Reward:   -241.2204492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2795.4121094; Critic Loss:   3735.9770508; Batch Reward:   -264.9322461\n",
      "Actor Loss:  -2757.1435547; Critic Loss:   3512.6162109; Batch Reward:   -283.1818087\n",
      "Actor Loss:  -2786.3781738; Critic Loss:   3862.1923828; Batch Reward:   -307.7442401\n",
      "Actor Loss:  -2536.6723633; Critic Loss:   2513.7832031; Batch Reward:   -247.7796758\n",
      "Actor Loss:  -3016.5690918; Critic Loss:   4399.2539062; Batch Reward:   -372.1301502\n",
      "Actor Loss:  -2227.0373535; Critic Loss:   2328.9892578; Batch Reward:   -228.6633323\n",
      "Actor Loss:  -2381.5773926; Critic Loss:   3264.9001465; Batch Reward:   -328.4603473\n",
      "Actor Loss:  -2289.1555176; Critic Loss:   3699.7104492; Batch Reward:   -298.3476951\n",
      "Actor Loss:  -1969.0769043; Critic Loss:   2015.1667480; Batch Reward:   -213.3406958\n",
      "Actor Loss:  -2735.7224121; Critic Loss:   6934.0708008; Batch Reward:   -416.5890184\n",
      "Actor Loss:  -1865.9675293; Critic Loss:   1862.4725342; Batch Reward:   -218.3374652\n",
      "Actor Loss:  -2697.1311035; Critic Loss:   5074.1562500; Batch Reward:   -376.5190270\n",
      "Actor Loss:  -2174.4726562; Critic Loss:   3244.5263672; Batch Reward:   -274.3675802\n",
      "Actor Loss:  -2430.1762695; Critic Loss:   3175.1281738; Batch Reward:   -279.6727727\n",
      "Actor Loss:  -2968.5251465; Critic Loss:   3230.2497559; Batch Reward:   -357.7528096\n",
      "Actor Loss:  -2497.3798828; Critic Loss:   2770.7932129; Batch Reward:   -222.2462233\n",
      "Actor Loss:  -3068.3691406; Critic Loss:   3251.4160156; Batch Reward:   -327.6263218\n",
      "Actor Loss:  -2532.2006836; Critic Loss:   3183.3264160; Batch Reward:   -215.7031001\n",
      "Actor Loss:  -3226.4838867; Critic Loss:   3768.1833496; Batch Reward:   -398.0101207\n",
      "Actor Loss:  -2246.9912109; Critic Loss:   2459.8830566; Batch Reward:   -201.2049557\n",
      "Actor Loss:  -3174.3137207; Critic Loss:   3177.3395996; Batch Reward:   -369.8861289\n",
      "Actor Loss:  -2317.5219727; Critic Loss:   2262.1423340; Batch Reward:   -192.2047713\n",
      "Actor Loss:  -2883.1369629; Critic Loss:   2859.2543945; Batch Reward:   -320.2052374\n",
      "Actor Loss:  -2562.7243652; Critic Loss:   2997.1738281; Batch Reward:   -269.8250967\n",
      "Actor Loss:  -2423.7290039; Critic Loss:   2436.7023926; Batch Reward:   -237.9678004\n",
      "Actor Loss:  -2823.7893066; Critic Loss:   4012.5546875; Batch Reward:   -371.2629366\n",
      "Actor Loss:  -2293.8154297; Critic Loss:   1910.7569580; Batch Reward:   -194.4006642\n",
      "Actor Loss:  -2897.6374512; Critic Loss:   3768.0329590; Batch Reward:   -342.2725102\n",
      "Actor Loss:  -2073.8439941; Critic Loss:   1579.2386475; Batch Reward:   -194.8044287\n",
      "Actor Loss:  -2388.4497070; Critic Loss:   2838.3735352; Batch Reward:   -301.6372219\n",
      "Actor Loss:  -2426.2050781; Critic Loss:   2791.6804199; Batch Reward:   -311.3184719\n",
      "Actor Loss:  -2303.1528320; Critic Loss:   2957.0195312; Batch Reward:   -260.4067764\n",
      "Actor Loss:  -2897.2790527; Critic Loss:   4418.2226562; Batch Reward:   -379.2401994\n",
      "Actor Loss:  -2192.3115234; Critic Loss:   3102.3771973; Batch Reward:   -260.3513833\n",
      "Actor Loss:  -2098.3063965; Critic Loss:   1951.0970459; Batch Reward:   -219.1285104\n",
      "Actor Loss:  -3318.0996094; Critic Loss:   5873.6372070; Batch Reward:   -420.5311387\n",
      "Actor Loss:  -2080.2934570; Critic Loss:   1571.8071289; Batch Reward:   -212.1022344\n",
      "Actor Loss:  -3053.1584473; Critic Loss:   3288.5041504; Batch Reward:   -349.6350160\n",
      "Actor Loss:  -2398.2282715; Critic Loss:   2703.4145508; Batch Reward:   -221.0637428\n",
      "Actor Loss:  -2856.1281738; Critic Loss:   3145.8737793; Batch Reward:   -295.0456210\n",
      "Actor Loss:  -2907.4150391; Critic Loss:   2761.5512695; Batch Reward:   -333.6325263\n",
      "Actor Loss:  -2528.3415527; Critic Loss:   2351.7619629; Batch Reward:   -224.3668920\n",
      "Actor Loss:  -2987.8637695; Critic Loss:   3292.1425781; Batch Reward:   -308.1216330\n",
      "Actor Loss:  -2424.5122070; Critic Loss:   2293.4179688; Batch Reward:   -222.4761107\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -3143.9248047; Critic Loss:   5718.9970703; Batch Reward:   -397.0240039\n",
      "Actor Loss:  -2251.5207520; Critic Loss:   1430.9809570; Batch Reward:   -187.1776505\n",
      "Actor Loss:  -2800.8356934; Critic Loss:   3216.7644043; Batch Reward:   -343.9739581\n",
      "Actor Loss:  -2136.6958008; Critic Loss:   1788.7889404; Batch Reward:   -197.8022439\n",
      "Actor Loss:  -2445.1582031; Critic Loss:   2692.3056641; Batch Reward:   -312.2847073\n",
      "Actor Loss:  -2098.3205566; Critic Loss:   2130.8920898; Batch Reward:   -205.7943193\n",
      "Actor Loss:  -2395.2121582; Critic Loss:   2424.6894531; Batch Reward:   -313.9276046\n",
      "Actor Loss:  -2140.7077637; Critic Loss:   2708.6679688; Batch Reward:   -277.5607715\n",
      "Actor Loss:  -2169.2590332; Critic Loss:   2971.4821777; Batch Reward:   -286.3061119\n",
      "Actor Loss:  -2132.1430664; Critic Loss:   2829.6293945; Batch Reward:   -258.3544728\n",
      "Actor Loss:  -2145.1762695; Critic Loss:   1954.5844727; Batch Reward:   -232.2858387\n",
      "Actor Loss:  -2855.6250000; Critic Loss:   4965.3603516; Batch Reward:   -387.0985419\n",
      "Actor Loss:  -1842.8038330; Critic Loss:   2134.7324219; Batch Reward:   -226.0494497\n",
      "Actor Loss:  -2124.9707031; Critic Loss:   3853.9858398; Batch Reward:   -253.1746848\n",
      "Actor Loss:  -2158.1237793; Critic Loss:   2487.4130859; Batch Reward:   -189.5178117\n",
      "Actor Loss:  -2489.2915039; Critic Loss:   2874.4938965; Batch Reward:   -329.5852891\n",
      "Actor Loss:  -2057.6860352; Critic Loss:   2284.7419434; Batch Reward:   -214.3260955\n",
      "Actor Loss:  -2623.6611328; Critic Loss:   3382.4011230; Batch Reward:   -340.7664698\n",
      "Actor Loss:  -2230.0800781; Critic Loss:   2583.6484375; Batch Reward:   -201.4296518\n",
      "Actor Loss:  -2586.3989258; Critic Loss:   2880.2763672; Batch Reward:   -329.9867805\n",
      "Actor Loss:  -2166.2910156; Critic Loss:   1849.1848145; Batch Reward:   -208.4100213\n",
      "Actor Loss:  -3134.6445312; Critic Loss:   5276.7470703; Batch Reward:   -409.2901177\n",
      "Actor Loss:  -2096.8554688; Critic Loss:   1793.5522461; Batch Reward:   -211.6899991\n",
      "Actor Loss:  -3033.3405762; Critic Loss:   3835.8056641; Batch Reward:   -352.3258005\n",
      "Actor Loss:  -2321.0910645; Critic Loss:   1894.8027344; Batch Reward:   -191.0344940\n",
      "Actor Loss:  -2764.1899414; Critic Loss:   3385.1762695; Batch Reward:   -310.8223812\n",
      "Actor Loss:  -2468.3273926; Critic Loss:   1777.9757080; Batch Reward:   -199.0495625\n",
      "Actor Loss:  -2990.2788086; Critic Loss:   3171.2106934; Batch Reward:   -336.7816626\n",
      "Actor Loss:  -2225.1945801; Critic Loss:   2256.0031738; Batch Reward:   -205.3692878\n",
      "Actor Loss:  -2358.9887695; Critic Loss:   2844.8237305; Batch Reward:   -279.0670197\n",
      "Actor Loss:  -2391.1074219; Critic Loss:   2013.5750732; Batch Reward:   -223.1887553\n",
      "Actor Loss:  -2409.0551758; Critic Loss:   2469.3112793; Batch Reward:   -284.7712358\n",
      "Actor Loss:  -2067.1767578; Critic Loss:   1670.6043701; Batch Reward:   -194.8103136\n",
      "Actor Loss:  -2212.0163574; Critic Loss:   3040.8688965; Batch Reward:   -271.9947974\n",
      "Actor Loss:  -2173.9836426; Critic Loss:   2956.8090820; Batch Reward:   -314.6545556\n",
      "Actor Loss:  -2050.4770508; Critic Loss:   1340.0090332; Batch Reward:   -188.3821218\n",
      "Actor Loss:  -2364.5869141; Critic Loss:   3177.5969238; Batch Reward:   -325.4414325\n",
      "Actor Loss:  -2068.3291016; Critic Loss:   2384.6479492; Batch Reward:   -261.1682459\n",
      "Actor Loss:  -2151.2377930; Critic Loss:   2520.3911133; Batch Reward:   -256.4929430\n",
      "Actor Loss:  -2224.9497070; Critic Loss:   2860.2456055; Batch Reward:   -295.9994388\n",
      "Actor Loss:  -2357.5668945; Critic Loss:   3609.9345703; Batch Reward:   -319.7491715\n",
      "Actor Loss:  -2042.8662109; Critic Loss:   1437.2215576; Batch Reward:   -199.8121627\n",
      "Actor Loss:  -2356.3400879; Critic Loss:   3080.3811035; Batch Reward:   -310.7329260\n",
      "Actor Loss:  -2260.9045410; Critic Loss:   1538.9909668; Batch Reward:   -188.3621027\n",
      "Actor Loss:  -2534.0849609; Critic Loss:   3360.7031250; Batch Reward:   -320.5072903\n",
      "Actor Loss:  -2242.8095703; Critic Loss:   1376.1810303; Batch Reward:   -203.3939017\n",
      "Actor Loss:  -2704.7646484; Critic Loss:   3136.3415527; Batch Reward:   -339.3600397\n",
      "Actor Loss:  -2181.7473145; Critic Loss:   1722.9818115; Batch Reward:   -188.5965875\n",
      "Actor Loss:  -2596.6960449; Critic Loss:   3525.2568359; Batch Reward:   -296.4644158\n",
      "Actor Loss:  -2230.6682129; Critic Loss:   3125.4682617; Batch Reward:   -202.3210031\n",
      "Actor Loss:  -2345.2136230; Critic Loss:   3872.5104980; Batch Reward:   -251.3508685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2124.1904297; Critic Loss:   2044.5101318; Batch Reward:   -208.3320737\n",
      "Actor Loss:  -2429.0322266; Critic Loss:   3249.2749023; Batch Reward:   -293.4996837\n",
      "Actor Loss:  -2052.9819336; Critic Loss:   2888.8806152; Batch Reward:   -247.0036197\n",
      "Actor Loss:  -2061.4003906; Critic Loss:   1452.9227295; Batch Reward:   -201.0230806\n",
      "Actor Loss:  -1970.6909180; Critic Loss:   2708.6054688; Batch Reward:   -258.9483678\n",
      "Actor Loss:  -2032.0249023; Critic Loss:   2798.7451172; Batch Reward:   -291.5850562\n",
      "Actor Loss:  -1838.0849609; Critic Loss:   2519.3222656; Batch Reward:   -228.2981461\n",
      "Actor Loss:  -1877.0322266; Critic Loss:   1652.8181152; Batch Reward:   -184.9241306\n",
      "Actor Loss:  -2277.9916992; Critic Loss:   6200.6708984; Batch Reward:   -369.9570436\n",
      "Actor Loss:  -1763.1456299; Critic Loss:   1564.7484131; Batch Reward:   -206.1135542\n",
      "Actor Loss:  -2229.2802734; Critic Loss:   6073.1625977; Batch Reward:   -379.2193339\n",
      "Actor Loss:  -1704.6336670; Critic Loss:   2647.0368652; Batch Reward:   -255.0053274\n",
      "Actor Loss:  -2171.9631348; Critic Loss:   2160.6022949; Batch Reward:   -242.5521121\n",
      "Actor Loss:  -2358.0786133; Critic Loss:   2301.9223633; Batch Reward:   -217.9899984\n",
      "Actor Loss:  -2451.5114746; Critic Loss:   2311.9812012; Batch Reward:   -235.6508772\n",
      "Actor Loss:  -2272.3591309; Critic Loss:   1771.5501709; Batch Reward:   -197.4204109\n",
      "Actor Loss:  -2271.7509766; Critic Loss:   1863.1160889; Batch Reward:   -208.8615089\n",
      "Actor Loss:  -2375.2912598; Critic Loss:   2369.5251465; Batch Reward:   -250.8635556\n",
      "Actor Loss:  -2325.4270020; Critic Loss:   1997.1260986; Batch Reward:   -196.8807480\n",
      "Actor Loss:  -2228.7011719; Critic Loss:   2229.8283691; Batch Reward:   -238.4013091\n",
      "Actor Loss:  -2069.0837402; Critic Loss:   1165.7158203; Batch Reward:   -192.7661650\n",
      "Actor Loss:  -2155.5107422; Critic Loss:   2533.1943359; Batch Reward:   -251.4820110\n",
      "Actor Loss:  -1854.2387695; Critic Loss:   1416.7073975; Batch Reward:   -211.8477848\n",
      "Actor Loss:  -2081.0832520; Critic Loss:   4253.1225586; Batch Reward:   -324.8344580\n",
      "Actor Loss:  -1765.8000488; Critic Loss:   1396.7083740; Batch Reward:   -201.1041729\n",
      "Actor Loss:  -1898.3205566; Critic Loss:   2220.3852539; Batch Reward:   -219.3451647\n",
      "Actor Loss:  -1878.6721191; Critic Loss:   2301.4436035; Batch Reward:   -271.3032728\n",
      "Actor Loss:  -1847.9197998; Critic Loss:   1190.9233398; Batch Reward:   -197.6844257\n",
      "Actor Loss:  -2093.5009766; Critic Loss:   5538.7905273; Batch Reward:   -351.6897300\n",
      "Actor Loss:  -1838.7526855; Critic Loss:   2015.4598389; Batch Reward:   -248.4268803\n",
      "Actor Loss:  -2122.1638184; Critic Loss:   3092.3295898; Batch Reward:   -279.2894729\n",
      "Actor Loss:  -2196.2770996; Critic Loss:   1530.8482666; Batch Reward:   -194.7551716\n",
      "Actor Loss:  -2210.8720703; Critic Loss:   2514.0415039; Batch Reward:   -246.2213852\n",
      "Actor Loss:  -2180.9213867; Critic Loss:   1897.1209717; Batch Reward:   -185.1621582\n",
      "Actor Loss:  -2271.0883789; Critic Loss:   1374.4841309; Batch Reward:   -194.0025767\n",
      "Actor Loss:  -2194.3908691; Critic Loss:   2174.0942383; Batch Reward:   -257.5980299\n",
      "Actor Loss:  -2033.9219971; Critic Loss:   1964.7817383; Batch Reward:   -203.8663898\n",
      "Actor Loss:  -2308.5690918; Critic Loss:   2840.9370117; Batch Reward:   -289.4993442\n",
      "Actor Loss:  -2216.0598145; Critic Loss:   2127.5764160; Batch Reward:   -225.0789659\n",
      "Actor Loss:  -2252.8090820; Critic Loss:   3304.4616699; Batch Reward:   -288.6070300\n",
      "Actor Loss:  -2200.5500488; Critic Loss:   1502.4429932; Batch Reward:   -196.1283932\n",
      "Actor Loss:  -2212.9345703; Critic Loss:   1708.8967285; Batch Reward:   -226.3295634\n",
      "Actor Loss:  -2169.2819824; Critic Loss:   1250.6540527; Batch Reward:   -202.4696516\n",
      "Actor Loss:  -2263.6596680; Critic Loss:   2806.8874512; Batch Reward:   -268.4789733\n",
      "Actor Loss:  -2037.0576172; Critic Loss:   1256.4035645; Batch Reward:   -202.8725392\n",
      "Actor Loss:  -2047.2464600; Critic Loss:   3888.2521973; Batch Reward:   -271.6450537\n",
      "Actor Loss:  -2053.3139648; Critic Loss:   1296.1529541; Batch Reward:   -213.6057715\n",
      "Actor Loss:  -2012.9858398; Critic Loss:   3217.2719727; Batch Reward:   -278.2755922\n",
      "Actor Loss:  -2042.2833252; Critic Loss:   1254.1839600; Batch Reward:   -212.3907103\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2078.9472656; Critic Loss:   2522.3706055; Batch Reward:   -271.6825775\n",
      "Actor Loss:  -2016.4754639; Critic Loss:   1589.1008301; Batch Reward:   -205.5625167\n",
      "Actor Loss:  -2049.0463867; Critic Loss:   1203.1550293; Batch Reward:   -209.6111085\n",
      "Actor Loss:  -2045.4183350; Critic Loss:   1082.1569824; Batch Reward:   -201.1899489\n",
      "Actor Loss:  -2091.8176270; Critic Loss:   2211.1845703; Batch Reward:   -244.5842194\n",
      "Actor Loss:  -1973.4078369; Critic Loss:   2069.6965332; Batch Reward:   -226.4969173\n",
      "Actor Loss:  -2245.6826172; Critic Loss:   4609.6508789; Batch Reward:   -349.7657266\n",
      "Actor Loss:  -1943.7357178; Critic Loss:   1812.0943604; Batch Reward:   -234.6653536\n",
      "Actor Loss:  -2183.5869141; Critic Loss:   2300.3864746; Batch Reward:   -212.5459273\n",
      "Actor Loss:  -2217.1499023; Critic Loss:   1563.6743164; Batch Reward:   -218.1772532\n",
      "Actor Loss:  -2280.8256836; Critic Loss:   1281.6015625; Batch Reward:   -200.6187282\n",
      "Actor Loss:  -2238.6035156; Critic Loss:   1496.7738037; Batch Reward:   -189.2585502\n",
      "Actor Loss:  -2331.9951172; Critic Loss:   1102.1313477; Batch Reward:   -189.1502610\n",
      "Actor Loss:  -2170.7988281; Critic Loss:   2064.3740234; Batch Reward:   -235.0190270\n",
      "Actor Loss:  -2113.6477051; Critic Loss:   1131.2229004; Batch Reward:   -190.7902291\n",
      "Actor Loss:  -2024.1832275; Critic Loss:   1402.5798340; Batch Reward:   -194.9808870\n",
      "Actor Loss:  -2049.3073730; Critic Loss:   1303.7618408; Batch Reward:   -175.7498307\n",
      "Actor Loss:  -1790.5109863; Critic Loss:   2109.0471191; Batch Reward:   -246.2366291\n",
      "Actor Loss:  -1752.1285400; Critic Loss:   2242.4375000; Batch Reward:   -232.8928000\n",
      "Actor Loss:  -1882.1208496; Critic Loss:   3399.0788574; Batch Reward:   -302.9382465\n",
      "Actor Loss:  -1866.5357666; Critic Loss:   1965.4260254; Batch Reward:   -220.6792082\n",
      "Actor Loss:  -1817.9318848; Critic Loss:   3460.3520508; Batch Reward:   -286.3291856\n",
      "Actor Loss:  -1817.2702637; Critic Loss:   1484.1400146; Batch Reward:   -214.1509942\n",
      "Actor Loss:  -1853.4086914; Critic Loss:   2380.2238770; Batch Reward:   -253.3972223\n",
      "Actor Loss:  -1756.2309570; Critic Loss:   2977.9602051; Batch Reward:   -261.5029267\n",
      "Actor Loss:  -2008.1434326; Critic Loss:   1406.6716309; Batch Reward:   -222.1606655\n",
      "Actor Loss:  -2082.1389160; Critic Loss:   1238.9124756; Batch Reward:   -180.8489187\n",
      "Actor Loss:  -2093.4458008; Critic Loss:   1603.5394287; Batch Reward:   -190.0631209\n",
      "Actor Loss:  -2160.6352539; Critic Loss:   1195.8203125; Batch Reward:   -203.1144786\n",
      "Actor Loss:  -2117.6896973; Critic Loss:   1974.9521484; Batch Reward:   -190.0041229\n",
      "Actor Loss:  -2103.4792480; Critic Loss:   1458.4351807; Batch Reward:   -214.0784011\n",
      "Actor Loss:  -2045.6461182; Critic Loss:   1345.2407227; Batch Reward:   -187.8268232\n",
      "Actor Loss:  -2020.7962646; Critic Loss:   1314.0223389; Batch Reward:   -207.9773435\n",
      "Actor Loss:  -2017.1657715; Critic Loss:    870.3327026; Batch Reward:   -196.5269288\n",
      "Actor Loss:  -1966.9277344; Critic Loss:   1236.9262695; Batch Reward:   -202.7506755\n",
      "Actor Loss:  -1913.9639893; Critic Loss:   1814.5076904; Batch Reward:   -206.7902060\n",
      "Actor Loss:  -1868.7581787; Critic Loss:   3648.8164062; Batch Reward:   -301.2898672\n",
      "Actor Loss:  -1710.3181152; Critic Loss:   2478.1782227; Batch Reward:   -222.0144638\n",
      "Actor Loss:  -1824.1406250; Critic Loss:   2111.3605957; Batch Reward:   -253.9694301\n",
      "Actor Loss:  -1719.2928467; Critic Loss:   3069.1513672; Batch Reward:   -268.6254629\n",
      "Actor Loss:  -1862.9871826; Critic Loss:   2078.0166016; Batch Reward:   -205.7716041\n",
      "Actor Loss:  -1822.4438477; Critic Loss:   2839.4448242; Batch Reward:   -256.2146734\n",
      "Actor Loss:  -1962.5937500; Critic Loss:   1694.0085449; Batch Reward:   -221.3237813\n",
      "Actor Loss:  -1976.2515869; Critic Loss:   1474.4830322; Batch Reward:   -224.8810966\n",
      "Actor Loss:  -2042.5787354; Critic Loss:   1589.6013184; Batch Reward:   -202.5781945\n",
      "Actor Loss:  -2107.4611816; Critic Loss:   1229.4562988; Batch Reward:   -196.3946148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -1973.1182861; Critic Loss:   1595.4129639; Batch Reward:   -203.4670624\n",
      "Actor Loss:  -2069.3674316; Critic Loss:   1561.4425049; Batch Reward:   -215.7016820\n",
      "Actor Loss:  -2041.1887207; Critic Loss:   3439.7685547; Batch Reward:   -285.5167854\n",
      "Actor Loss:  -2052.1652832; Critic Loss:   4436.3422852; Batch Reward:   -294.1473578\n",
      "Actor Loss:  -1910.0872803; Critic Loss:   2520.2226562; Batch Reward:   -247.1445230\n",
      "Actor Loss:  -2067.6667480; Critic Loss:   2914.5292969; Batch Reward:   -284.8146316\n",
      "Actor Loss:  -2119.0302734; Critic Loss:   1760.4749756; Batch Reward:   -243.8358833\n",
      "Actor Loss:  -2214.9299316; Critic Loss:   2208.8872070; Batch Reward:   -245.3070822\n",
      "Actor Loss:  -2205.9082031; Critic Loss:   1549.6560059; Batch Reward:   -212.1680405\n",
      "Actor Loss:  -2246.2734375; Critic Loss:   2283.1716309; Batch Reward:   -251.5683724\n",
      "Actor Loss:  -2056.0935059; Critic Loss:   1910.9770508; Batch Reward:   -240.0192961\n",
      "Actor Loss:  -2290.2011719; Critic Loss:   2276.0773926; Batch Reward:   -212.8828753\n",
      "Actor Loss:  -2099.0087891; Critic Loss:   2528.9672852; Batch Reward:   -210.7830066\n",
      "Actor Loss:  -2229.8203125; Critic Loss:   1614.6491699; Batch Reward:   -184.9962524\n",
      "Actor Loss:  -2158.4145508; Critic Loss:   1345.6257324; Batch Reward:   -193.2320152\n",
      "Actor Loss:  -2009.3339844; Critic Loss:   2023.2290039; Batch Reward:   -231.5651075\n",
      "Actor Loss:  -1996.9746094; Critic Loss:    945.6820068; Batch Reward:   -191.3909192\n",
      "Actor Loss:  -1857.5380859; Critic Loss:   2411.5393066; Batch Reward:   -243.5436472\n",
      "Actor Loss:  -1823.4497070; Critic Loss:    727.3156128; Batch Reward:   -198.9225219\n",
      "Actor Loss:  -1663.7980957; Critic Loss:   1409.5014648; Batch Reward:   -196.3942862\n",
      "Actor Loss:  -1771.6185303; Critic Loss:   1879.4997559; Batch Reward:   -223.1885704\n",
      "Actor Loss:  -1674.4664307; Critic Loss:   2663.1896973; Batch Reward:   -243.1085311\n",
      "Actor Loss:  -1624.8978271; Critic Loss:   3409.0354004; Batch Reward:   -251.2016293\n",
      "Actor Loss:  -1695.4625244; Critic Loss:   1526.8099365; Batch Reward:   -210.3214142\n",
      "Actor Loss:  -1777.1826172; Critic Loss:   2929.3530273; Batch Reward:   -260.0565894\n",
      "Actor Loss:  -1716.2468262; Critic Loss:   2813.9743652; Batch Reward:   -261.7426814\n",
      "Actor Loss:  -1801.5283203; Critic Loss:   1732.1298828; Batch Reward:   -233.9506775\n",
      "Actor Loss:  -1970.8376465; Critic Loss:   1267.4704590; Batch Reward:   -203.0111085\n",
      "Actor Loss:  -1890.9096680; Critic Loss:   2360.6267090; Batch Reward:   -248.9286145\n",
      "Actor Loss:  -2059.6767578; Critic Loss:   1920.1474609; Batch Reward:   -194.4856565\n",
      "Actor Loss:  -2034.7215576; Critic Loss:   1929.3443604; Batch Reward:   -204.9993178\n",
      "Actor Loss:  -2187.7722168; Critic Loss:   1271.8416748; Batch Reward:   -192.4338943\n",
      "Actor Loss:  -2050.4748535; Critic Loss:   2193.6337891; Batch Reward:   -240.0384076\n",
      "Actor Loss:  -2032.1639404; Critic Loss:   1662.3500977; Batch Reward:   -232.2662281\n",
      "Actor Loss:  -1982.1970215; Critic Loss:   2042.4262695; Batch Reward:   -259.8287669\n",
      "Actor Loss:  -2067.8952637; Critic Loss:   2455.8752441; Batch Reward:   -264.3987674\n",
      "Actor Loss:  -2159.8762207; Critic Loss:   2283.9213867; Batch Reward:   -285.8895079\n",
      "Actor Loss:  -1947.2244873; Critic Loss:   1811.8269043; Batch Reward:   -238.6107840\n",
      "Actor Loss:  -2274.8225098; Critic Loss:   3164.3234863; Batch Reward:   -301.1668040\n",
      "Actor Loss:  -2028.9462891; Critic Loss:   2052.9025879; Batch Reward:   -241.7252651\n",
      "Actor Loss:  -2246.3203125; Critic Loss:   2414.1955566; Batch Reward:   -235.3853783\n",
      "Actor Loss:  -2277.8703613; Critic Loss:   1794.3974609; Batch Reward:   -206.5666215\n",
      "Actor Loss:  -2180.9934082; Critic Loss:   2258.4631348; Batch Reward:   -194.2437546\n",
      "Actor Loss:  -2168.6579590; Critic Loss:   1481.1246338; Batch Reward:   -201.5496793\n",
      "Actor Loss:  -2086.8562012; Critic Loss:   1776.5789795; Batch Reward:   -219.5086885\n",
      "Actor Loss:  -1928.8631592; Critic Loss:   1858.9396973; Batch Reward:   -191.2824760\n",
      "Actor Loss:  -1858.0546875; Critic Loss:   1397.5798340; Batch Reward:   -187.8183497\n",
      "Actor Loss:  -1773.0538330; Critic Loss:    846.4617920; Batch Reward:   -203.2194010\n",
      "Actor Loss:  -1633.7658691; Critic Loss:   1767.8116455; Batch Reward:   -219.9935495\n",
      "Actor Loss:  -1526.4445801; Critic Loss:   1646.0588379; Batch Reward:   -214.0750015\n",
      "Actor Loss:  -1390.1413574; Critic Loss:   2114.2272949; Batch Reward:   -226.1640445\n",
      "Actor Loss:  -1546.6461182; Critic Loss:   1620.1987305; Batch Reward:   -206.6429726\n",
      "Actor Loss:  -1470.0418701; Critic Loss:   1447.8742676; Batch Reward:   -208.1712680\n",
      "Actor Loss:  -1429.9573975; Critic Loss:   2084.7204590; Batch Reward:   -233.7077015\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -1448.6068115; Critic Loss:   1335.7468262; Batch Reward:   -189.2995244\n",
      "Actor Loss:  -1381.9252930; Critic Loss:   2523.4973145; Batch Reward:   -229.3802800\n",
      "Actor Loss:  -1565.2386475; Critic Loss:   1565.7298584; Batch Reward:   -199.7584560\n",
      "Actor Loss:  -1590.5003662; Critic Loss:   1216.6872559; Batch Reward:   -194.8989860\n",
      "Actor Loss:  -1586.7647705; Critic Loss:   2463.7844238; Batch Reward:   -226.3908947\n",
      "Actor Loss:  -1649.2801514; Critic Loss:   1531.3712158; Batch Reward:   -223.5203135\n",
      "Actor Loss:  -1750.6799316; Critic Loss:   4186.0625000; Batch Reward:   -304.3086728\n",
      "Actor Loss:  -1746.6861572; Critic Loss:   3189.5402832; Batch Reward:   -288.0028007\n",
      "Actor Loss:  -1950.4020996; Critic Loss:   3720.3198242; Batch Reward:   -288.0199196\n",
      "Actor Loss:  -1934.7500000; Critic Loss:   2129.5175781; Batch Reward:   -260.7495528\n",
      "Actor Loss:  -2367.9902344; Critic Loss:   2365.8154297; Batch Reward:   -293.5774651\n",
      "Actor Loss:  -2250.3046875; Critic Loss:   2096.6877441; Batch Reward:   -223.5439815\n",
      "Actor Loss:  -2684.4208984; Critic Loss:   3262.3552246; Batch Reward:   -311.8522995\n",
      "Actor Loss:  -2521.8591309; Critic Loss:   2307.4541016; Batch Reward:   -207.7155625\n",
      "Actor Loss:  -2779.2824707; Critic Loss:   2635.9020996; Batch Reward:   -275.2535357\n",
      "Actor Loss:  -2672.3435059; Critic Loss:   3010.5759277; Batch Reward:   -209.9594596\n",
      "Actor Loss:  -2640.6572266; Critic Loss:   2796.7363281; Batch Reward:   -220.1273603\n",
      "Actor Loss:  -2395.7153320; Critic Loss:   2903.8386230; Batch Reward:   -221.8358909\n",
      "Actor Loss:  -2119.7006836; Critic Loss:   1920.7071533; Batch Reward:   -209.7738243\n",
      "Actor Loss:  -2069.9594727; Critic Loss:   2299.1772461; Batch Reward:   -245.1070982\n",
      "Actor Loss:  -1973.1694336; Critic Loss:   1095.4482422; Batch Reward:   -201.0797048\n",
      "Actor Loss:  -1675.4807129; Critic Loss:   4437.5278320; Batch Reward:   -310.4895701\n",
      "Actor Loss:  -1596.0544434; Critic Loss:   1374.0306396; Batch Reward:   -210.3107396\n",
      "Actor Loss:  -1678.5844727; Critic Loss:   1226.6550293; Batch Reward:   -195.1135790\n",
      "Actor Loss:  -1469.3333740; Critic Loss:   3785.2441406; Batch Reward:   -253.2552922\n",
      "Actor Loss:  -1552.5710449; Critic Loss:   2023.5439453; Batch Reward:   -222.9141777\n",
      "Actor Loss:  -1526.5712891; Critic Loss:   1986.5384521; Batch Reward:   -235.0094065\n",
      "Actor Loss:  -1451.4129639; Critic Loss:   2479.2507324; Batch Reward:   -249.7346846\n",
      "Actor Loss:  -1617.4268799; Critic Loss:   1046.1481934; Batch Reward:   -195.7220568\n",
      "Actor Loss:  -1684.6437988; Critic Loss:   1465.6845703; Batch Reward:   -210.4914319\n",
      "Actor Loss:  -1643.1763916; Critic Loss:   1920.8531494; Batch Reward:   -238.3819878\n",
      "Actor Loss:  -1783.5783691; Critic Loss:    982.1306763; Batch Reward:   -189.2444383\n",
      "Actor Loss:  -1878.2770996; Critic Loss:   3194.4316406; Batch Reward:   -278.9396059\n",
      "Actor Loss:  -1849.1020508; Critic Loss:   1389.5445557; Batch Reward:   -174.0373573\n",
      "Actor Loss:  -2022.8024902; Critic Loss:   5279.6464844; Batch Reward:   -339.3658547\n",
      "Actor Loss:  -1918.9987793; Critic Loss:   1780.9915771; Batch Reward:   -229.6414876\n",
      "Actor Loss:  -2470.0915527; Critic Loss:   5116.4194336; Batch Reward:   -346.7431108\n",
      "Actor Loss:  -2165.1015625; Critic Loss:   1882.3205566; Batch Reward:   -216.8629502\n",
      "Actor Loss:  -2811.0393066; Critic Loss:   3801.7568359; Batch Reward:   -339.5428299\n",
      "Actor Loss:  -2619.0273438; Critic Loss:   1959.1293945; Batch Reward:   -204.9399395\n",
      "Actor Loss:  -2928.2338867; Critic Loss:   3008.9724121; Batch Reward:   -294.9003934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2550.5205078; Critic Loss:   2882.6899414; Batch Reward:   -201.0869511\n",
      "Actor Loss:  -2830.6516113; Critic Loss:   3025.1291504; Batch Reward:   -270.9509120\n",
      "Actor Loss:  -2518.1730957; Critic Loss:   2496.9975586; Batch Reward:   -220.0819904\n",
      "Actor Loss:  -2302.2426758; Critic Loss:   2399.6901855; Batch Reward:   -218.8518335\n",
      "Actor Loss:  -2382.1435547; Critic Loss:   2544.4145508; Batch Reward:   -273.5994010\n",
      "Actor Loss:  -2019.9420166; Critic Loss:   1661.2149658; Batch Reward:   -181.8505976\n",
      "Actor Loss:  -1951.5200195; Critic Loss:   1633.2729492; Batch Reward:   -230.9905925\n",
      "Actor Loss:  -1731.2535400; Critic Loss:   1518.4052734; Batch Reward:   -220.8764807\n",
      "Actor Loss:  -1639.8549805; Critic Loss:   3489.7636719; Batch Reward:   -275.8553817\n",
      "Actor Loss:  -1533.3803711; Critic Loss:   1447.6541748; Batch Reward:   -187.1719603\n",
      "Actor Loss:  -1430.1086426; Critic Loss:   1976.3601074; Batch Reward:   -213.4888476\n",
      "Actor Loss:  -1420.6682129; Critic Loss:   1552.6473389; Batch Reward:   -214.9892991\n",
      "Actor Loss:  -1430.5076904; Critic Loss:   2592.1943359; Batch Reward:   -249.5709839\n",
      "Actor Loss:  -1420.4715576; Critic Loss:   1434.8221436; Batch Reward:   -191.0167189\n",
      "Actor Loss:  -1388.5112305; Critic Loss:   4385.2324219; Batch Reward:   -293.2784422\n",
      "Actor Loss:  -1451.0898438; Critic Loss:   1324.5817871; Batch Reward:   -195.8869787\n",
      "Actor Loss:  -1498.4539795; Critic Loss:   3268.8022461; Batch Reward:   -248.6518043\n",
      "Actor Loss:  -1625.6541748; Critic Loss:   1138.7534180; Batch Reward:   -192.4052296\n",
      "Actor Loss:  -1645.6212158; Critic Loss:   2982.5612793; Batch Reward:   -267.7126890\n",
      "Actor Loss:  -1720.4720459; Critic Loss:   1126.1257324; Batch Reward:   -197.8463845\n",
      "Actor Loss:  -1983.8787842; Critic Loss:   5414.3183594; Batch Reward:   -339.6026799\n",
      "Actor Loss:  -1773.0965576; Critic Loss:   2046.6069336; Batch Reward:   -209.2102894\n",
      "Actor Loss:  -2287.7419434; Critic Loss:   4136.7719727; Batch Reward:   -344.8786347\n",
      "Actor Loss:  -1909.8538818; Critic Loss:   1742.7987061; Batch Reward:   -202.3385897\n",
      "Actor Loss:  -2603.8002930; Critic Loss:   3508.3686523; Batch Reward:   -328.7843153\n",
      "Actor Loss:  -2305.4951172; Critic Loss:   1927.8410645; Batch Reward:   -184.6087971\n",
      "Actor Loss:  -2813.6118164; Critic Loss:   2755.2346191; Batch Reward:   -305.7988626\n",
      "Actor Loss:  -2413.0771484; Critic Loss:   2387.8481445; Batch Reward:   -198.7104675\n",
      "Actor Loss:  -2463.1159668; Critic Loss:   2274.3098145; Batch Reward:   -236.9824398\n",
      "Actor Loss:  -2355.7568359; Critic Loss:   1902.2054443; Batch Reward:   -198.9425099\n",
      "Actor Loss:  -2620.9011230; Critic Loss:   3346.1135254; Batch Reward:   -323.4262606\n",
      "Actor Loss:  -2125.4814453; Critic Loss:   1880.5541992; Batch Reward:   -198.4006932\n",
      "Actor Loss:  -2423.1425781; Critic Loss:   3391.6826172; Batch Reward:   -304.5867097\n",
      "Actor Loss:  -1948.0861816; Critic Loss:   1891.2885742; Batch Reward:   -196.0906940\n",
      "Actor Loss:  -2089.6735840; Critic Loss:   3711.4509277; Batch Reward:   -302.3262414\n",
      "Actor Loss:  -1717.8338623; Critic Loss:   1138.7689209; Batch Reward:   -216.3383300\n",
      "Actor Loss:  -1885.2987061; Critic Loss:   3396.0913086; Batch Reward:   -300.8764336\n",
      "Actor Loss:  -1665.1096191; Critic Loss:   1501.4870605; Batch Reward:   -208.5259210\n",
      "Actor Loss:  -1768.5196533; Critic Loss:   2528.5563965; Batch Reward:   -252.2735463\n",
      "Actor Loss:  -1736.1677246; Critic Loss:   2263.4877930; Batch Reward:   -233.4801341\n",
      "Actor Loss:  -1791.6583252; Critic Loss:   2130.4287109; Batch Reward:   -258.4227286\n",
      "Actor Loss:  -1810.6427002; Critic Loss:   1653.9907227; Batch Reward:   -212.5289239\n",
      "Actor Loss:  -1867.9182129; Critic Loss:   2951.1513672; Batch Reward:   -274.6466559\n",
      "Actor Loss:  -1780.6141357; Critic Loss:   1859.9505615; Batch Reward:   -230.7283124\n",
      "Actor Loss:  -1852.4544678; Critic Loss:   2741.6958008; Batch Reward:   -261.4305426\n",
      "Actor Loss:  -1815.8391113; Critic Loss:   1243.8142090; Batch Reward:   -207.7979127\n",
      "Actor Loss:  -1969.6199951; Critic Loss:   3253.2714844; Batch Reward:   -283.6580289\n",
      "Actor Loss:  -1795.6259766; Critic Loss:   1424.5093994; Batch Reward:   -203.1289410\n",
      "Actor Loss:  -2166.7998047; Critic Loss:   4056.2670898; Batch Reward:   -336.6641677\n",
      "Actor Loss:  -1889.1333008; Critic Loss:   1383.8435059; Batch Reward:   -198.2985188\n",
      "Actor Loss:  -2356.1606445; Critic Loss:   4068.2177734; Batch Reward:   -337.2108248\n",
      "Actor Loss:  -2033.4176025; Critic Loss:   1424.7430420; Batch Reward:   -197.6289701\n",
      "Actor Loss:  -2593.4948730; Critic Loss:   3696.3378906; Batch Reward:   -355.5066952\n",
      "Actor Loss:  -2115.2158203; Critic Loss:   1783.9537354; Batch Reward:   -196.8561799\n",
      "Actor Loss:  -2483.3415527; Critic Loss:   3045.7426758; Batch Reward:   -278.5127496\n",
      "Actor Loss:  -2257.5246582; Critic Loss:   2137.6113281; Batch Reward:   -229.7984472\n",
      "Actor Loss:  -2543.9472656; Critic Loss:   2528.4182129; Batch Reward:   -307.5728769\n",
      "Actor Loss:  -2176.6896973; Critic Loss:   1916.2442627; Batch Reward:   -191.6999800\n",
      "Actor Loss:  -2308.3254395; Critic Loss:   2997.8532715; Batch Reward:   -287.8316412\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -1968.7265625; Critic Loss:   1843.5775146; Batch Reward:   -198.3556938\n",
      "Actor Loss:  -2121.7485352; Critic Loss:   3255.5192871; Batch Reward:   -314.6088477\n",
      "Actor Loss:  -1862.6397705; Critic Loss:   1861.4759521; Batch Reward:   -218.4570736\n",
      "Actor Loss:  -1957.3580322; Critic Loss:   3053.9821777; Batch Reward:   -294.4791116\n",
      "Actor Loss:  -1648.8901367; Critic Loss:   1503.1420898; Batch Reward:   -201.2525417\n",
      "Actor Loss:  -1786.6401367; Critic Loss:   3298.1982422; Batch Reward:   -301.5910638\n",
      "Actor Loss:  -1654.3389893; Critic Loss:   1362.8479004; Batch Reward:   -197.8687299\n",
      "Actor Loss:  -1817.9012451; Critic Loss:   3290.4638672; Batch Reward:   -291.3368289\n",
      "Actor Loss:  -1613.5849609; Critic Loss:   2117.5510254; Batch Reward:   -227.4748799\n",
      "Actor Loss:  -1692.0245361; Critic Loss:   2242.7170410; Batch Reward:   -262.2079244\n",
      "Actor Loss:  -1809.6339111; Critic Loss:   2200.3315430; Batch Reward:   -241.4788861\n",
      "Actor Loss:  -1978.7990723; Critic Loss:   3401.4475098; Batch Reward:   -294.2064748\n",
      "Actor Loss:  -1809.8358154; Critic Loss:   1545.8730469; Batch Reward:   -181.1115494\n",
      "Actor Loss:  -2312.5278320; Critic Loss:   4342.7817383; Batch Reward:   -336.4146257\n",
      "Actor Loss:  -1813.4005127; Critic Loss:   1294.0889893; Batch Reward:   -198.8050268\n",
      "Actor Loss:  -2385.4926758; Critic Loss:   3899.6286621; Batch Reward:   -340.2636214\n",
      "Actor Loss:  -1999.8682861; Critic Loss:   1761.3499756; Batch Reward:   -187.7742056\n",
      "Actor Loss:  -2636.0131836; Critic Loss:   3413.7231445; Batch Reward:   -313.5939152\n",
      "Actor Loss:  -2092.3818359; Critic Loss:   2494.6315918; Batch Reward:   -210.0446218\n",
      "Actor Loss:  -2640.6965332; Critic Loss:   3258.8876953; Batch Reward:   -297.3046741\n",
      "Actor Loss:  -2026.7442627; Critic Loss:   2085.0576172; Batch Reward:   -205.8610685\n",
      "Actor Loss:  -2476.1640625; Critic Loss:   2466.9733887; Batch Reward:   -292.9958185\n",
      "Actor Loss:  -1923.5883789; Critic Loss:   3081.1389160; Batch Reward:   -179.0563191\n",
      "Actor Loss:  -2243.1135254; Critic Loss:   3390.8386230; Batch Reward:   -305.2361633\n",
      "Actor Loss:  -1698.2075195; Critic Loss:   1399.9063721; Batch Reward:   -213.7698278\n",
      "Actor Loss:  -2042.4135742; Critic Loss:   3611.8237305; Batch Reward:   -308.0867704\n",
      "Actor Loss:  -1614.1549072; Critic Loss:   1546.3425293; Batch Reward:   -210.5431697\n",
      "Actor Loss:  -1795.6674805; Critic Loss:   2090.1538086; Batch Reward:   -260.5389738\n",
      "Actor Loss:  -1768.1634521; Critic Loss:   2673.8969727; Batch Reward:   -283.9476117\n",
      "Actor Loss:  -1703.1424561; Critic Loss:   2655.4733887; Batch Reward:   -248.4544503\n",
      "Actor Loss:  -1809.1735840; Critic Loss:   3157.1582031; Batch Reward:   -280.6803495\n",
      "Actor Loss:  -1659.3575439; Critic Loss:   1525.8056641; Batch Reward:   -206.1142995\n",
      "Actor Loss:  -1921.1336670; Critic Loss:   2942.8544922; Batch Reward:   -287.9040256\n",
      "Actor Loss:  -1730.5585938; Critic Loss:   1764.2509766; Batch Reward:   -242.9248426\n",
      "Actor Loss:  -2076.7827148; Critic Loss:   3588.8730469; Batch Reward:   -323.4320923\n",
      "Actor Loss:  -1713.7548828; Critic Loss:   1672.7160645; Batch Reward:   -192.7771282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2184.2021484; Critic Loss:   3181.9611816; Batch Reward:   -314.5716767\n",
      "Actor Loss:  -1874.1457520; Critic Loss:   2232.5524902; Batch Reward:   -229.3510713\n",
      "Actor Loss:  -2393.8771973; Critic Loss:   3064.8977051; Batch Reward:   -324.7242336\n",
      "Actor Loss:  -1960.5672607; Critic Loss:   2111.5537109; Batch Reward:   -215.1568016\n",
      "Actor Loss:  -2621.2658691; Critic Loss:   3770.1003418; Batch Reward:   -343.7480147\n",
      "Actor Loss:  -2001.4631348; Critic Loss:   1578.4790039; Batch Reward:   -192.8270344\n",
      "Actor Loss:  -2620.1306152; Critic Loss:   3458.7668457; Batch Reward:   -343.8039708\n",
      "Actor Loss:  -1991.5057373; Critic Loss:   2237.0371094; Batch Reward:   -221.9880216\n",
      "Actor Loss:  -2321.6364746; Critic Loss:   2870.5187988; Batch Reward:   -300.7433924\n",
      "Actor Loss:  -2133.7324219; Critic Loss:   2590.8405762; Batch Reward:   -262.3260396\n",
      "Actor Loss:  -2218.9672852; Critic Loss:   2834.9677734; Batch Reward:   -300.8204205\n",
      "Actor Loss:  -1972.6784668; Critic Loss:   1742.4853516; Batch Reward:   -241.7169239\n",
      "Actor Loss:  -1943.3460693; Critic Loss:   2230.6220703; Batch Reward:   -260.5665559\n",
      "Actor Loss:  -2032.1131592; Critic Loss:   2597.2937012; Batch Reward:   -295.2938721\n",
      "Actor Loss:  -1931.5610352; Critic Loss:   2947.0463867; Batch Reward:   -279.4332735\n",
      "Actor Loss:  -1925.7624512; Critic Loss:   2731.6599121; Batch Reward:   -289.7318876\n",
      "Actor Loss:  -1778.5313721; Critic Loss:   2283.5686035; Batch Reward:   -256.6495746\n",
      "Actor Loss:  -2110.7534180; Critic Loss:   4502.9843750; Batch Reward:   -349.6462500\n",
      "Actor Loss:  -1885.5458984; Critic Loss:   1616.1434326; Batch Reward:   -195.4205937\n",
      "Actor Loss:  -2469.9216309; Critic Loss:   5328.5927734; Batch Reward:   -373.3548264\n",
      "Actor Loss:  -1981.4215088; Critic Loss:   1748.6478271; Batch Reward:   -191.6256921\n",
      "Actor Loss:  -2648.6767578; Critic Loss:   3553.8315430; Batch Reward:   -349.1895602\n",
      "Actor Loss:  -2095.3889160; Critic Loss:   1992.1135254; Batch Reward:   -209.5710181\n",
      "Actor Loss:  -2817.1750488; Critic Loss:   3149.4479980; Batch Reward:   -330.7039977\n",
      "Actor Loss:  -2193.4396973; Critic Loss:   2111.7541504; Batch Reward:   -214.0480386\n",
      "Actor Loss:  -2853.8566895; Critic Loss:   3937.3964844; Batch Reward:   -338.2165371\n",
      "Actor Loss:  -2257.4687500; Critic Loss:   1832.5847168; Batch Reward:   -217.7623786\n",
      "Actor Loss:  -2490.9111328; Critic Loss:   2294.1394043; Batch Reward:   -285.0785502\n",
      "Actor Loss:  -2295.1223145; Critic Loss:   2311.4741211; Batch Reward:   -243.2649610\n",
      "Actor Loss:  -2221.5170898; Critic Loss:   3499.5322266; Batch Reward:   -293.5328202\n",
      "Actor Loss:  -2049.6186523; Critic Loss:   2682.8713379; Batch Reward:   -271.0026865\n",
      "Actor Loss:  -1891.8223877; Critic Loss:   2912.7770996; Batch Reward:   -266.3765227\n",
      "Actor Loss:  -1914.3289795; Critic Loss:   2137.1301270; Batch Reward:   -254.6137801\n",
      "Actor Loss:  -1885.0148926; Critic Loss:   2784.0881348; Batch Reward:   -272.2242118\n",
      "Actor Loss:  -1938.9953613; Critic Loss:   2924.6401367; Batch Reward:   -274.9119972\n",
      "Actor Loss:  -1728.5372314; Critic Loss:   1885.0817871; Batch Reward:   -233.4603194\n",
      "Actor Loss:  -1936.4000244; Critic Loss:   3796.3452148; Batch Reward:   -325.0343840\n",
      "Actor Loss:  -1864.3020020; Critic Loss:   1753.6634521; Batch Reward:   -233.7937607\n",
      "Actor Loss:  -2072.4206543; Critic Loss:   3621.3386230; Batch Reward:   -306.6853854\n",
      "Actor Loss:  -2007.7722168; Critic Loss:   2073.2819824; Batch Reward:   -237.8101125\n",
      "Actor Loss:  -2314.6286621; Critic Loss:   3874.1184082; Batch Reward:   -349.5977213\n",
      "Actor Loss:  -1991.7347412; Critic Loss:   1805.1108398; Batch Reward:   -190.9837151\n",
      "Actor Loss:  -2514.3977051; Critic Loss:   3763.5407715; Batch Reward:   -348.8913499\n",
      "Actor Loss:  -2186.9514160; Critic Loss:   2300.1303711; Batch Reward:   -213.2577236\n",
      "Actor Loss:  -2658.8073730; Critic Loss:   3286.0610352; Batch Reward:   -319.6673887\n",
      "Actor Loss:  -2147.4677734; Critic Loss:   2378.5563965; Batch Reward:   -186.7298024\n",
      "Actor Loss:  -2542.6904297; Critic Loss:   3238.6748047; Batch Reward:   -308.2979288\n",
      "Actor Loss:  -2247.9223633; Critic Loss:   2591.6574707; Batch Reward:   -251.7878070\n",
      "Actor Loss:  -2558.5566406; Critic Loss:   3151.3046875; Batch Reward:   -332.8587024\n",
      "Actor Loss:  -2046.6416016; Critic Loss:   2004.0537109; Batch Reward:   -212.1833886\n",
      "Actor Loss:  -2330.7148438; Critic Loss:   2732.3034668; Batch Reward:   -310.9123378\n",
      "Actor Loss:  -1903.1870117; Critic Loss:   1644.7922363; Batch Reward:   -197.6472719\n",
      "Actor Loss:  -2247.9592285; Critic Loss:   3286.5393066; Batch Reward:   -309.9270381\n",
      "Actor Loss:  -1852.8652344; Critic Loss:   1886.3853760; Batch Reward:   -220.5944095\n",
      "Actor Loss:  -2120.8986816; Critic Loss:   3644.5993652; Batch Reward:   -290.7101562\n",
      "Actor Loss:  -1865.1875000; Critic Loss:   2051.2888184; Batch Reward:   -223.9648410\n",
      "Actor Loss:  -1938.9667969; Critic Loss:   3141.8256836; Batch Reward:   -297.3454197\n",
      "Actor Loss:  -1801.9012451; Critic Loss:   1918.2340088; Batch Reward:   -237.5972181\n",
      "Actor Loss:  -2027.4111328; Critic Loss:   3696.3283691; Batch Reward:   -319.9127768\n",
      "Actor Loss:  -1865.5532227; Critic Loss:   1964.4197998; Batch Reward:   -227.8798220\n",
      "Actor Loss:  -2074.5537109; Critic Loss:   3080.7563477; Batch Reward:   -307.0737230\n",
      "Actor Loss:  -1865.7271729; Critic Loss:   2080.8393555; Batch Reward:   -208.5101467\n",
      "Actor Loss:  -2313.8854980; Critic Loss:   3831.0004883; Batch Reward:   -317.6659791\n",
      "Actor Loss:  -1960.4112549; Critic Loss:   2109.1572266; Batch Reward:   -211.2822273\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2411.5734863; Critic Loss:   2857.9995117; Batch Reward:   -312.0310315\n",
      "Actor Loss:  -2012.8616943; Critic Loss:   1978.5396729; Batch Reward:   -199.7111734\n",
      "Actor Loss:  -2511.5122070; Critic Loss:   4192.8764648; Batch Reward:   -358.4515690\n",
      "Actor Loss:  -2060.4833984; Critic Loss:   1725.4193115; Batch Reward:   -187.3400771\n",
      "Actor Loss:  -2676.5329590; Critic Loss:   4376.3837891; Batch Reward:   -346.7644416\n",
      "Actor Loss:  -2021.3541260; Critic Loss:   2143.4833984; Batch Reward:   -201.4622435\n",
      "Actor Loss:  -2592.7929688; Critic Loss:   3305.9121094; Batch Reward:   -330.4012710\n",
      "Actor Loss:  -2145.5969238; Critic Loss:   2264.1564941; Batch Reward:   -216.8829180\n",
      "Actor Loss:  -2422.8098145; Critic Loss:   3001.6166992; Batch Reward:   -313.6086815\n",
      "Actor Loss:  -2146.9814453; Critic Loss:   2196.6894531; Batch Reward:   -250.4642222\n",
      "Actor Loss:  -2208.0849609; Critic Loss:   2612.3881836; Batch Reward:   -277.6574945\n",
      "Actor Loss:  -2161.1850586; Critic Loss:   2713.0002441; Batch Reward:   -269.1683661\n",
      "Actor Loss:  -2126.1430664; Critic Loss:   3552.7258301; Batch Reward:   -277.2264198\n",
      "Actor Loss:  -1979.6867676; Critic Loss:   2418.4108887; Batch Reward:   -255.6071012\n",
      "Actor Loss:  -2077.6225586; Critic Loss:   3619.0356445; Batch Reward:   -306.7278667\n",
      "Actor Loss:  -2058.3134766; Critic Loss:   3140.3896484; Batch Reward:   -287.9612922\n",
      "Actor Loss:  -1986.2947998; Critic Loss:   2077.6105957; Batch Reward:   -250.4620824\n",
      "Actor Loss:  -2128.7770996; Critic Loss:   2956.4580078; Batch Reward:   -298.1783986\n",
      "Actor Loss:  -2028.9196777; Critic Loss:   2106.5014648; Batch Reward:   -267.1101938\n",
      "Actor Loss:  -2063.3869629; Critic Loss:   2616.5322266; Batch Reward:   -286.3682045\n",
      "Actor Loss:  -2115.9387207; Critic Loss:   2165.9853516; Batch Reward:   -244.7557096\n",
      "Actor Loss:  -2172.2824707; Critic Loss:   2804.1110840; Batch Reward:   -299.2387140\n",
      "Actor Loss:  -1922.7886963; Critic Loss:   1858.6201172; Batch Reward:   -212.4792880\n",
      "Actor Loss:  -2184.9953613; Critic Loss:   3023.2473145; Batch Reward:   -300.1565273\n",
      "Actor Loss:  -1903.3946533; Critic Loss:   1912.2572021; Batch Reward:   -223.9036540\n",
      "Actor Loss:  -2179.5839844; Critic Loss:   4013.9880371; Batch Reward:   -335.0944590\n",
      "Actor Loss:  -1914.4860840; Critic Loss:   1815.6008301; Batch Reward:   -207.1967745\n",
      "Actor Loss:  -2211.8522949; Critic Loss:   2972.6638184; Batch Reward:   -324.2670303\n",
      "Actor Loss:  -2014.5446777; Critic Loss:   2303.2067871; Batch Reward:   -222.8924736\n",
      "Actor Loss:  -2239.6047363; Critic Loss:   3102.8652344; Batch Reward:   -304.6543079\n",
      "Actor Loss:  -2039.4829102; Critic Loss:   1842.6987305; Batch Reward:   -242.6374282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2318.6491699; Critic Loss:   3944.9396973; Batch Reward:   -331.8769629\n",
      "Actor Loss:  -2012.1745605; Critic Loss:   1742.5347900; Batch Reward:   -194.6369970\n",
      "Actor Loss:  -2486.2175293; Critic Loss:   5051.3139648; Batch Reward:   -390.9909011\n",
      "Actor Loss:  -2150.6647949; Critic Loss:   1464.2624512; Batch Reward:   -199.2789583\n",
      "Actor Loss:  -2512.8955078; Critic Loss:   3354.5568848; Batch Reward:   -322.8959498\n",
      "Actor Loss:  -2457.3085938; Critic Loss:   1994.5610352; Batch Reward:   -282.0453680\n",
      "Actor Loss:  -2601.4150391; Critic Loss:   3647.8459473; Batch Reward:   -321.9550424\n",
      "Actor Loss:  -2457.9748535; Critic Loss:   2877.0249023; Batch Reward:   -248.8600146\n",
      "Actor Loss:  -2488.9536133; Critic Loss:   2811.0925293; Batch Reward:   -256.2830507\n",
      "Actor Loss:  -2651.6791992; Critic Loss:   3246.7795410; Batch Reward:   -321.7211010\n",
      "Actor Loss:  -2292.0842285; Critic Loss:   2489.4060059; Batch Reward:   -255.6392466\n",
      "Actor Loss:  -2585.0566406; Critic Loss:   3639.2648926; Batch Reward:   -313.7305985\n",
      "Actor Loss:  -2025.1334229; Critic Loss:   1819.0336914; Batch Reward:   -221.4067263\n",
      "Actor Loss:  -2471.3464355; Critic Loss:   4467.3125000; Batch Reward:   -372.8913131\n",
      "Actor Loss:  -2038.6713867; Critic Loss:   1278.5286865; Batch Reward:   -201.6859063\n",
      "Actor Loss:  -2379.9724121; Critic Loss:   3714.5747070; Batch Reward:   -335.1597416\n",
      "Actor Loss:  -2097.0678711; Critic Loss:   1503.9047852; Batch Reward:   -216.7889282\n",
      "Actor Loss:  -2418.5900879; Critic Loss:   3651.8381348; Batch Reward:   -338.4164061\n",
      "Actor Loss:  -2099.1528320; Critic Loss:   2280.6892090; Batch Reward:   -218.2123602\n",
      "Actor Loss:  -2421.1093750; Critic Loss:   2916.8996582; Batch Reward:   -331.8569045\n",
      "Actor Loss:  -2126.5019531; Critic Loss:   2668.4384766; Batch Reward:   -218.7455476\n",
      "Actor Loss:  -2399.7155762; Critic Loss:   3695.9953613; Batch Reward:   -335.0571417\n",
      "Actor Loss:  -2216.3579102; Critic Loss:   2483.0075684; Batch Reward:   -242.4239553\n",
      "Actor Loss:  -2502.4558105; Critic Loss:   4010.7548828; Batch Reward:   -336.3424672\n",
      "Actor Loss:  -2102.3005371; Critic Loss:   2100.6679688; Batch Reward:   -213.2403840\n",
      "Actor Loss:  -2640.3789062; Critic Loss:   3675.3981934; Batch Reward:   -347.7669946\n",
      "Actor Loss:  -2115.4489746; Critic Loss:   1959.9515381; Batch Reward:   -230.1744617\n",
      "Actor Loss:  -2416.7355957; Critic Loss:   3028.2624512; Batch Reward:   -306.5407221\n",
      "Actor Loss:  -1978.2766113; Critic Loss:   2214.4624023; Batch Reward:   -234.6702101\n",
      "Actor Loss:  -2302.2429199; Critic Loss:   3499.2573242; Batch Reward:   -328.2285441\n",
      "Actor Loss:  -2093.1208496; Critic Loss:   2055.2783203; Batch Reward:   -241.0961467\n",
      "Actor Loss:  -2339.0270996; Critic Loss:   3788.8845215; Batch Reward:   -347.2193984\n",
      "Actor Loss:  -2078.7287598; Critic Loss:   2633.8068848; Batch Reward:   -200.7495350\n",
      "Actor Loss:  -2462.9528809; Critic Loss:   3843.3791504; Batch Reward:   -336.3681842\n",
      "Actor Loss:  -2144.5620117; Critic Loss:   1943.3978271; Batch Reward:   -219.2758003\n",
      "Actor Loss:  -2202.4804688; Critic Loss:   2804.1726074; Batch Reward:   -303.6581439\n",
      "Actor Loss:  -2267.4179688; Critic Loss:   3228.3735352; Batch Reward:   -308.0487047\n",
      "Actor Loss:  -2223.1381836; Critic Loss:   2773.6059570; Batch Reward:   -281.9184131\n",
      "Actor Loss:  -2358.2753906; Critic Loss:   2403.5981445; Batch Reward:   -293.5822421\n",
      "Actor Loss:  -2109.5922852; Critic Loss:   2710.7170410; Batch Reward:   -252.6127062\n",
      "Actor Loss:  -2283.1679688; Critic Loss:   2924.0698242; Batch Reward:   -296.4114659\n",
      "Actor Loss:  -2228.5864258; Critic Loss:   2280.3923340; Batch Reward:   -252.9986095\n",
      "Actor Loss:  -2295.2368164; Critic Loss:   3311.3352051; Batch Reward:   -318.2785546\n",
      "Actor Loss:  -2097.4089355; Critic Loss:   2022.8804932; Batch Reward:   -234.4771154\n",
      "Actor Loss:  -2421.5693359; Critic Loss:   4483.8544922; Batch Reward:   -385.8818743\n",
      "Actor Loss:  -2186.1193848; Critic Loss:   2159.7204590; Batch Reward:   -197.8433212\n",
      "Actor Loss:  -2484.6342773; Critic Loss:   4831.9575195; Batch Reward:   -366.8665690\n",
      "Actor Loss:  -2330.5842285; Critic Loss:   2572.7846680; Batch Reward:   -231.3879223\n",
      "Actor Loss:  -2624.2541504; Critic Loss:   3131.4477539; Batch Reward:   -320.7804069\n",
      "Actor Loss:  -2375.4951172; Critic Loss:   2693.1298828; Batch Reward:   -266.2911400\n",
      "Actor Loss:  -2518.7211914; Critic Loss:   3507.6755371; Batch Reward:   -338.6916176\n",
      "Actor Loss:  -2370.4375000; Critic Loss:   2627.0541992; Batch Reward:   -248.4563714\n",
      "Actor Loss:  -2492.1469727; Critic Loss:   3946.0075684; Batch Reward:   -347.7956907\n",
      "Actor Loss:  -2328.8564453; Critic Loss:   2420.9941406; Batch Reward:   -253.9174659\n",
      "Actor Loss:  -2584.4243164; Critic Loss:   4830.4863281; Batch Reward:   -388.7882987\n",
      "Actor Loss:  -2268.5747070; Critic Loss:   2430.1193848; Batch Reward:   -223.0721387\n",
      "Actor Loss:  -2796.6293945; Critic Loss:   4276.7719727; Batch Reward:   -392.4329447\n",
      "Actor Loss:  -2221.2741699; Critic Loss:   2656.7231445; Batch Reward:   -211.1676676\n",
      "Actor Loss:  -2688.0544434; Critic Loss:   3657.4665527; Batch Reward:   -321.8040606\n",
      "Actor Loss:  -2307.2224121; Critic Loss:   3060.1342773; Batch Reward:   -260.0372503\n",
      "Actor Loss:  -2541.9284668; Critic Loss:   3467.7019043; Batch Reward:   -326.5801207\n",
      "Actor Loss:  -2473.3334961; Critic Loss:   3226.0014648; Batch Reward:   -298.9385320\n",
      "Actor Loss:  -2420.8046875; Critic Loss:   2920.1672363; Batch Reward:   -321.2829618\n",
      "Actor Loss:  -2408.3173828; Critic Loss:   2580.8776855; Batch Reward:   -310.6919260\n",
      "Actor Loss:  -2394.6176758; Critic Loss:   3645.6669922; Batch Reward:   -324.3085945\n",
      "Actor Loss:  -2317.9020996; Critic Loss:   2632.7250977; Batch Reward:   -279.4899250\n",
      "Actor Loss:  -2407.5415039; Critic Loss:   2828.1350098; Batch Reward:   -298.8448100\n",
      "Actor Loss:  -2310.3535156; Critic Loss:   2555.9267578; Batch Reward:   -270.0184033\n",
      "Actor Loss:  -2473.8247070; Critic Loss:   3863.3952637; Batch Reward:   -340.3796957\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2247.7380371; Critic Loss:   1999.6942139; Batch Reward:   -237.1047472\n",
      "Actor Loss:  -2539.4379883; Critic Loss:   4867.4199219; Batch Reward:   -379.0411940\n",
      "Actor Loss:  -2286.0541992; Critic Loss:   2301.4667969; Batch Reward:   -198.4550136\n",
      "Actor Loss:  -2618.0461426; Critic Loss:   4432.5029297; Batch Reward:   -365.2047947\n",
      "Actor Loss:  -2299.3791504; Critic Loss:   3225.7990723; Batch Reward:   -221.6334804\n",
      "Actor Loss:  -2559.7470703; Critic Loss:   3639.7089844; Batch Reward:   -353.4054703\n",
      "Actor Loss:  -2451.9833984; Critic Loss:   2626.2851562; Batch Reward:   -290.3672231\n",
      "Actor Loss:  -2436.8249512; Critic Loss:   2735.6564941; Batch Reward:   -282.4008775\n",
      "Actor Loss:  -2386.7900391; Critic Loss:   2580.7360840; Batch Reward:   -263.8876292\n",
      "Actor Loss:  -2483.7595215; Critic Loss:   4208.2622070; Batch Reward:   -377.9813537\n",
      "Actor Loss:  -2446.1835938; Critic Loss:   2087.9772949; Batch Reward:   -249.7962831\n",
      "Actor Loss:  -2631.5661621; Critic Loss:   3712.4399414; Batch Reward:   -357.2413128\n",
      "Actor Loss:  -2378.0639648; Critic Loss:   2519.5385742; Batch Reward:   -245.7509067\n",
      "Actor Loss:  -2848.4116211; Critic Loss:   4003.5024414; Batch Reward:   -375.4261710\n",
      "Actor Loss:  -2424.9367676; Critic Loss:   2260.4523926; Batch Reward:   -237.6894104\n",
      "Actor Loss:  -2650.0258789; Critic Loss:   3019.2641602; Batch Reward:   -342.6605097\n",
      "Actor Loss:  -2504.6059570; Critic Loss:   2840.7255859; Batch Reward:   -250.8335892\n",
      "Actor Loss:  -2644.6086426; Critic Loss:   3944.0354004; Batch Reward:   -356.8580628\n",
      "Actor Loss:  -2632.0473633; Critic Loss:   2419.4697266; Batch Reward:   -279.5979220\n",
      "Actor Loss:  -2713.4782715; Critic Loss:   2947.3408203; Batch Reward:   -316.9008585\n",
      "Actor Loss:  -2392.6665039; Critic Loss:   2337.9831543; Batch Reward:   -251.1663915\n",
      "Actor Loss:  -2605.2839355; Critic Loss:   3715.2138672; Batch Reward:   -346.5275177\n",
      "Actor Loss:  -2270.8640137; Critic Loss:   2528.0749512; Batch Reward:   -229.1978111\n",
      "Actor Loss:  -2521.7224121; Critic Loss:   3274.0056152; Batch Reward:   -342.5467071\n",
      "Actor Loss:  -2243.4423828; Critic Loss:   2311.7749023; Batch Reward:   -233.1669749\n",
      "Actor Loss:  -2435.4631348; Critic Loss:   4384.3842773; Batch Reward:   -359.7341135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2211.9575195; Critic Loss:   2011.1906738; Batch Reward:   -257.8600433\n",
      "Actor Loss:  -2342.9453125; Critic Loss:   3323.8615723; Batch Reward:   -307.1455922\n",
      "Actor Loss:  -2321.8503418; Critic Loss:   3046.5942383; Batch Reward:   -299.3985623\n",
      "Actor Loss:  -2364.0593262; Critic Loss:   2682.8293457; Batch Reward:   -313.3304455\n",
      "Actor Loss:  -2286.3044434; Critic Loss:   3015.5336914; Batch Reward:   -309.9009666\n",
      "Actor Loss:  -2501.9528809; Critic Loss:   2978.8969727; Batch Reward:   -306.9757330\n",
      "Actor Loss:  -2577.5910645; Critic Loss:   2539.5183105; Batch Reward:   -313.0790535\n",
      "Actor Loss:  -2510.5187988; Critic Loss:   2747.1589355; Batch Reward:   -317.6315198\n",
      "Actor Loss:  -2727.8303223; Critic Loss:   2943.1691895; Batch Reward:   -306.4366027\n",
      "Actor Loss:  -2590.8417969; Critic Loss:   2616.3981934; Batch Reward:   -285.9577052\n",
      "Actor Loss:  -2780.1069336; Critic Loss:   3295.5241699; Batch Reward:   -314.5458011\n",
      "Actor Loss:  -2526.6828613; Critic Loss:   3003.6494141; Batch Reward:   -288.7119446\n",
      "Actor Loss:  -2619.9963379; Critic Loss:   2999.0720215; Batch Reward:   -354.8168323\n",
      "Actor Loss:  -2390.5327148; Critic Loss:   2867.2446289; Batch Reward:   -246.2607285\n",
      "Actor Loss:  -2614.6425781; Critic Loss:   5351.3945312; Batch Reward:   -411.8331864\n",
      "Actor Loss:  -2445.9597168; Critic Loss:   2961.1513672; Batch Reward:   -194.2316964\n",
      "Actor Loss:  -2522.9614258; Critic Loss:   4249.3286133; Batch Reward:   -373.2933408\n",
      "Actor Loss:  -2399.8164062; Critic Loss:   2722.0617676; Batch Reward:   -225.5879360\n",
      "Actor Loss:  -2578.2619629; Critic Loss:   4046.1535645; Batch Reward:   -352.8964026\n",
      "Actor Loss:  -2482.5046387; Critic Loss:   2482.5061035; Batch Reward:   -258.3622115\n",
      "Actor Loss:  -2475.2009277; Critic Loss:   3720.4130859; Batch Reward:   -339.2976724\n",
      "Actor Loss:  -2364.7485352; Critic Loss:   2658.3818359; Batch Reward:   -255.0447400\n",
      "Actor Loss:  -2578.7189941; Critic Loss:   4034.0283203; Batch Reward:   -353.6198580\n",
      "Actor Loss:  -2390.6625977; Critic Loss:   2534.0190430; Batch Reward:   -276.5305477\n",
      "Actor Loss:  -2639.5097656; Critic Loss:   4064.1552734; Batch Reward:   -370.0088840\n",
      "Actor Loss:  -2313.7199707; Critic Loss:   1976.0439453; Batch Reward:   -230.3214251\n",
      "Actor Loss:  -2687.9211426; Critic Loss:   4016.4138184; Batch Reward:   -378.6291034\n",
      "Actor Loss:  -2519.4926758; Critic Loss:   2224.8544922; Batch Reward:   -237.7309224\n",
      "Actor Loss:  -2856.3752441; Critic Loss:   3538.2111816; Batch Reward:   -349.2616221\n",
      "Actor Loss:  -2529.8874512; Critic Loss:   2499.7023926; Batch Reward:   -276.4692248\n",
      "Actor Loss:  -2961.3046875; Critic Loss:   3966.9633789; Batch Reward:   -376.1107525\n",
      "Actor Loss:  -2565.7021484; Critic Loss:   2422.5783691; Batch Reward:   -240.9828997\n",
      "Actor Loss:  -2806.1540527; Critic Loss:   3102.7075195; Batch Reward:   -358.2548790\n",
      "Actor Loss:  -2452.5380859; Critic Loss:   2321.9570312; Batch Reward:   -246.0303255\n",
      "Actor Loss:  -2751.3735352; Critic Loss:   2996.5122070; Batch Reward:   -340.5115273\n",
      "Actor Loss:  -2570.7897949; Critic Loss:   2447.7236328; Batch Reward:   -266.2416583\n",
      "Actor Loss:  -2385.6960449; Critic Loss:   2880.3164062; Batch Reward:   -310.0652692\n",
      "Actor Loss:  -2431.0617676; Critic Loss:   3106.4624023; Batch Reward:   -296.3561441\n",
      "Actor Loss:  -2514.9863281; Critic Loss:   2951.3129883; Batch Reward:   -329.5675592\n",
      "Actor Loss:  -2284.6845703; Critic Loss:   2067.5559082; Batch Reward:   -276.0927538\n",
      "Actor Loss:  -2436.7761230; Critic Loss:   3423.3684082; Batch Reward:   -317.4592723\n",
      "Actor Loss:  -2340.8300781; Critic Loss:   3132.9377441; Batch Reward:   -328.3920037\n",
      "Actor Loss:  -2489.6098633; Critic Loss:   2883.7961426; Batch Reward:   -319.9116291\n",
      "Actor Loss:  -2332.3159180; Critic Loss:   2191.3649902; Batch Reward:   -258.9029706\n",
      "Actor Loss:  -2509.0324707; Critic Loss:   3921.3041992; Batch Reward:   -355.1570656\n",
      "Actor Loss:  -2489.3918457; Critic Loss:   2462.2604980; Batch Reward:   -222.5945811\n",
      "Actor Loss:  -2689.5986328; Critic Loss:   3476.8144531; Batch Reward:   -357.4380603\n",
      "Actor Loss:  -2458.7109375; Critic Loss:   2889.6972656; Batch Reward:   -222.1821432\n",
      "Actor Loss:  -2682.7910156; Critic Loss:   4135.9370117; Batch Reward:   -395.4216755\n",
      "Actor Loss:  -2428.7773438; Critic Loss:   2689.4294434; Batch Reward:   -224.2610500\n",
      "Actor Loss:  -2748.0930176; Critic Loss:   3936.6032715; Batch Reward:   -363.1917864\n",
      "Actor Loss:  -2390.0620117; Critic Loss:   2395.6577148; Batch Reward:   -243.2381563\n",
      "Actor Loss:  -2702.4216309; Critic Loss:   4325.0800781; Batch Reward:   -354.6980834\n",
      "Actor Loss:  -2436.8183594; Critic Loss:   2278.6665039; Batch Reward:   -236.5078385\n",
      "Actor Loss:  -2593.2045898; Critic Loss:   3896.0407715; Batch Reward:   -361.3653202\n",
      "Actor Loss:  -2386.3049316; Critic Loss:   2398.4453125; Batch Reward:   -264.6536739\n",
      "Actor Loss:  -2691.3442383; Critic Loss:   3522.9108887; Batch Reward:   -371.4536595\n",
      "Actor Loss:  -2397.6271973; Critic Loss:   2275.8159180; Batch Reward:   -257.4072490\n",
      "Actor Loss:  -2759.9301758; Critic Loss:   3909.3125000; Batch Reward:   -371.9747634\n",
      "Actor Loss:  -2408.7683105; Critic Loss:   2825.6306152; Batch Reward:   -231.4880777\n",
      "Actor Loss:  -2821.4514160; Critic Loss:   3945.9077148; Batch Reward:   -361.5381431\n",
      "Actor Loss:  -2622.6025391; Critic Loss:   2643.1975098; Batch Reward:   -261.7276893\n",
      "Actor Loss:  -2783.7297363; Critic Loss:   3341.3833008; Batch Reward:   -359.1369441\n",
      "Actor Loss:  -2491.4531250; Critic Loss:   2387.6723633; Batch Reward:   -263.6669163\n",
      "Actor Loss:  -2799.8212891; Critic Loss:   3944.8383789; Batch Reward:   -368.6529922\n",
      "Actor Loss:  -2379.6943359; Critic Loss:   2108.2937012; Batch Reward:   -229.8151935\n",
      "Actor Loss:  -2751.0642090; Critic Loss:   4429.2309570; Batch Reward:   -374.0358090\n",
      "Actor Loss:  -2429.7707520; Critic Loss:   2579.5410156; Batch Reward:   -281.9411257\n",
      "Actor Loss:  -2849.4072266; Critic Loss:   4184.6044922; Batch Reward:   -375.1455086\n",
      "Actor Loss:  -2305.0053711; Critic Loss:   2714.1052246; Batch Reward:   -241.3755326\n",
      "Actor Loss:  -2728.2416992; Critic Loss:   4808.9985352; Batch Reward:   -378.2959035\n",
      "Actor Loss:  -2377.5930176; Critic Loss:   2367.3718262; Batch Reward:   -239.9879949\n",
      "Actor Loss:  -2773.0004883; Critic Loss:   4258.1269531; Batch Reward:   -389.3866236\n",
      "Actor Loss:  -2473.3540039; Critic Loss:   2152.1140137; Batch Reward:   -257.0493600\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2879.3991699; Critic Loss:   3986.1723633; Batch Reward:   -370.1631409\n",
      "Actor Loss:  -2475.6027832; Critic Loss:   3454.0913086; Batch Reward:   -251.8220214\n",
      "Actor Loss:  -2795.6408691; Critic Loss:   3688.0148926; Batch Reward:   -363.3348708\n",
      "Actor Loss:  -2383.2175293; Critic Loss:   4970.3232422; Batch Reward:   -275.5058962\n",
      "Actor Loss:  -2743.6123047; Critic Loss:   3517.3847656; Batch Reward:   -361.8597815\n",
      "Actor Loss:  -2480.7814941; Critic Loss:   2377.2109375; Batch Reward:   -283.4436014\n",
      "Actor Loss:  -2549.3867188; Critic Loss:   3082.9311523; Batch Reward:   -334.4852095\n",
      "Actor Loss:  -2400.0500488; Critic Loss:   2729.1621094; Batch Reward:   -278.0191388\n",
      "Actor Loss:  -2489.5612793; Critic Loss:   3934.4416504; Batch Reward:   -375.2431147\n",
      "Actor Loss:  -2338.7802734; Critic Loss:   3027.3027344; Batch Reward:   -277.9005262\n",
      "Actor Loss:  -2638.0266113; Critic Loss:   3867.3037109; Batch Reward:   -354.9011150\n",
      "Actor Loss:  -2417.9904785; Critic Loss:   2773.2663574; Batch Reward:   -239.9746064\n",
      "Actor Loss:  -2823.1108398; Critic Loss:   5307.1318359; Batch Reward:   -436.7938002\n",
      "Actor Loss:  -2556.5791016; Critic Loss:   2708.0043945; Batch Reward:   -232.5418292\n",
      "Actor Loss:  -3135.2558594; Critic Loss:   3908.0908203; Batch Reward:   -390.9950764\n",
      "Actor Loss:  -2631.9772949; Critic Loss:   3160.0920410; Batch Reward:   -271.4952747\n",
      "Actor Loss:  -3299.5617676; Critic Loss:   3133.8840332; Batch Reward:   -374.8916053\n",
      "Actor Loss:  -2563.4323730; Critic Loss:   3221.9289551; Batch Reward:   -224.4649815\n",
      "Actor Loss:  -2929.4826660; Critic Loss:   3962.7414551; Batch Reward:   -380.3659643\n",
      "Actor Loss:  -2457.5402832; Critic Loss:   2917.0437012; Batch Reward:   -254.3512689\n",
      "Actor Loss:  -2861.6914062; Critic Loss:   4076.4960938; Batch Reward:   -354.8445140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -2336.1391602; Critic Loss:   2645.4729004; Batch Reward:   -261.9895067\n",
      "Actor Loss:  -2538.1237793; Critic Loss:   4514.9458008; Batch Reward:   -368.6345387\n",
      "Actor Loss:  -2232.5812988; Critic Loss:   2733.5639648; Batch Reward:   -244.5436446\n",
      "Actor Loss:  -2497.2185059; Critic Loss:   4487.9018555; Batch Reward:   -381.8271038\n",
      "Actor Loss:  -2242.1684570; Critic Loss:   2467.2675781; Batch Reward:   -269.0936591\n",
      "Actor Loss:  -2448.7067871; Critic Loss:   3116.1845703; Batch Reward:   -350.1247984\n",
      "Actor Loss:  -2426.1501465; Critic Loss:   2898.1462402; Batch Reward:   -340.6944306\n",
      "Actor Loss:  -2419.6313477; Critic Loss:   2568.9465332; Batch Reward:   -275.8582972\n",
      "Actor Loss:  -2759.0993652; Critic Loss:   3536.9443359; Batch Reward:   -363.0963281\n",
      "Actor Loss:  -2512.6240234; Critic Loss:   2651.8093262; Batch Reward:   -253.2647993\n",
      "Actor Loss:  -2844.7834473; Critic Loss:   3868.8549805; Batch Reward:   -362.0323600\n",
      "Actor Loss:  -2569.1457520; Critic Loss:   3011.7998047; Batch Reward:   -253.1027989\n",
      "Actor Loss:  -2864.5114746; Critic Loss:   3036.7966309; Batch Reward:   -365.7472029\n",
      "Actor Loss:  -2484.0434570; Critic Loss:   3045.3923340; Batch Reward:   -257.8778679\n",
      "Actor Loss:  -2782.9128418; Critic Loss:   4379.9672852; Batch Reward:   -386.9762351\n",
      "Actor Loss:  -2289.5534668; Critic Loss:   2672.3088379; Batch Reward:   -231.2325987\n",
      "Actor Loss:  -2588.3867188; Critic Loss:   3860.6469727; Batch Reward:   -380.4586834\n",
      "Actor Loss:  -2313.0571289; Critic Loss:   2643.9079590; Batch Reward:   -246.9295096\n",
      "Actor Loss:  -2423.4680176; Critic Loss:   2918.2758789; Batch Reward:   -333.3296435\n",
      "Actor Loss:  -2247.4580078; Critic Loss:   2503.0449219; Batch Reward:   -298.3394170\n",
      "Actor Loss:  -2601.2846680; Critic Loss:   3853.0539551; Batch Reward:   -355.7784890\n",
      "Actor Loss:  -2298.8964844; Critic Loss:   2554.7900391; Batch Reward:   -278.0098306\n",
      "Actor Loss:  -2438.8825684; Critic Loss:   3395.3710938; Batch Reward:   -349.0897883\n",
      "Actor Loss:  -2276.2639160; Critic Loss:   2711.0312500; Batch Reward:   -278.1590113\n",
      "Actor Loss:  -2454.4633789; Critic Loss:   3384.4499512; Batch Reward:   -317.3136982\n",
      "Actor Loss:  -2548.7277832; Critic Loss:   3343.6735840; Batch Reward:   -314.4305348\n",
      "Actor Loss:  -2495.8825684; Critic Loss:   3137.9807129; Batch Reward:   -289.5407352\n",
      "Actor Loss:  -2533.4140625; Critic Loss:   3173.8281250; Batch Reward:   -346.5420983\n",
      "Actor Loss:  -2448.7419434; Critic Loss:   2692.6774902; Batch Reward:   -311.3600285\n",
      "Actor Loss:  -2597.9960938; Critic Loss:   3174.3288574; Batch Reward:   -343.0976590\n",
      "Actor Loss:  -2591.7893066; Critic Loss:   2573.5971680; Batch Reward:   -314.3751256\n",
      "Actor Loss:  -2760.3322754; Critic Loss:   4087.6562500; Batch Reward:   -405.7344985\n",
      "Actor Loss:  -2531.6652832; Critic Loss:   2796.5732422; Batch Reward:   -249.0954303\n",
      "Actor Loss:  -3133.0988770; Critic Loss:   4161.7250977; Batch Reward:   -413.8002263\n",
      "Actor Loss:  -2629.3127441; Critic Loss:   3706.4528809; Batch Reward:   -192.7311324\n",
      "Actor Loss:  -3240.8247070; Critic Loss:   4469.8666992; Batch Reward:   -424.1782786\n",
      "Actor Loss:  -2599.8964844; Critic Loss:   3476.0996094; Batch Reward:   -239.9077999\n",
      "Actor Loss:  -3093.9206543; Critic Loss:   3121.6918945; Batch Reward:   -360.3255661\n",
      "Actor Loss:  -2579.8913574; Critic Loss:   3195.1059570; Batch Reward:   -303.3623951\n",
      "Actor Loss:  -2685.7866211; Critic Loss:   3699.5317383; Batch Reward:   -349.5777987\n",
      "Actor Loss:  -2569.4482422; Critic Loss:   2901.9987793; Batch Reward:   -293.2307431\n",
      "Actor Loss:  -2665.1015625; Critic Loss:   4435.8520508; Batch Reward:   -385.4467320\n",
      "Actor Loss:  -2352.6704102; Critic Loss:   3637.3862305; Batch Reward:   -283.4218916\n",
      "Actor Loss:  -2701.3049316; Critic Loss:   4259.5556641; Batch Reward:   -371.7994082\n",
      "Actor Loss:  -2552.4099121; Critic Loss:   4269.0942383; Batch Reward:   -292.9631582\n",
      "Actor Loss:  -2746.6940918; Critic Loss:   4202.8227539; Batch Reward:   -404.2308765\n",
      "Actor Loss:  -2437.2509766; Critic Loss:   3593.2873535; Batch Reward:   -258.6938643\n",
      "Actor Loss:  -2909.6650391; Critic Loss:   4617.4335938; Batch Reward:   -393.1349048\n",
      "Actor Loss:  -2608.8027344; Critic Loss:   2826.6608887; Batch Reward:   -267.1760291\n",
      "Actor Loss:  -2883.9077148; Critic Loss:   4162.0107422; Batch Reward:   -379.6642055\n",
      "Actor Loss:  -2665.5444336; Critic Loss:   4386.7539062; Batch Reward:   -248.0857653\n",
      "Actor Loss:  -3000.0886230; Critic Loss:   3834.0356445; Batch Reward:   -384.5032716\n",
      "Actor Loss:  -2665.4458008; Critic Loss:   2866.0715332; Batch Reward:   -285.2866834\n",
      "Actor Loss:  -2939.3981934; Critic Loss:   3206.3767090; Batch Reward:   -366.1224408\n",
      "Actor Loss:  -2515.3354492; Critic Loss:   2836.5078125; Batch Reward:   -277.7646820\n",
      "Actor Loss:  -2652.1098633; Critic Loss:   3691.4624023; Batch Reward:   -373.7441546\n",
      "Actor Loss:  -2399.7941895; Critic Loss:   2513.9660645; Batch Reward:   -249.5229015\n",
      "Actor Loss:  -2599.5725098; Critic Loss:   4667.7275391; Batch Reward:   -407.8326980\n",
      "Actor Loss:  -2242.8300781; Critic Loss:   2883.0964355; Batch Reward:   -228.3116074\n",
      "Actor Loss:  -2632.7905273; Critic Loss:   4161.9296875; Batch Reward:   -359.5939780\n",
      "Actor Loss:  -2362.4411621; Critic Loss:   3057.5524902; Batch Reward:   -258.0982672\n",
      "Actor Loss:  -2665.1962891; Critic Loss:   3641.5605469; Batch Reward:   -353.6027104\n",
      "Actor Loss:  -2502.2634277; Critic Loss:   3106.9221191; Batch Reward:   -305.9444016\n",
      "Actor Loss:  -2630.3310547; Critic Loss:   3818.1176758; Batch Reward:   -355.3609219\n",
      "Actor Loss:  -2485.8171387; Critic Loss:   3108.1630859; Batch Reward:   -301.6971981\n",
      "Actor Loss:  -2665.9443359; Critic Loss:   3424.5883789; Batch Reward:   -333.1436511\n",
      "Actor Loss:  -2475.7373047; Critic Loss:   2964.9284668; Batch Reward:   -330.9297289\n",
      "Actor Loss:  -2644.6494141; Critic Loss:   2940.7768555; Batch Reward:   -328.7630028\n",
      "Actor Loss:  -2808.3264160; Critic Loss:   3092.8203125; Batch Reward:   -327.5296190\n",
      "Actor Loss:  -2815.7568359; Critic Loss:   3329.1340332; Batch Reward:   -353.9155385\n",
      "Actor Loss:  -2808.4177246; Critic Loss:   3377.5893555; Batch Reward:   -314.9978439\n",
      "Actor Loss:  -2738.6027832; Critic Loss:   3456.5083008; Batch Reward:   -346.0140819\n",
      "Actor Loss:  -2800.5541992; Critic Loss:   2876.3833008; Batch Reward:   -340.0127636\n",
      "Actor Loss:  -2854.2929688; Critic Loss:   3927.7150879; Batch Reward:   -374.5785304\n",
      "Actor Loss:  -2541.1413574; Critic Loss:   3518.2380371; Batch Reward:   -247.4103468\n",
      "Actor Loss:  -2770.3928223; Critic Loss:   5853.7182617; Batch Reward:   -443.0826928\n",
      "Actor Loss:  -2730.3469238; Critic Loss:   3051.8459473; Batch Reward:   -223.3725374\n",
      "Actor Loss:  -2791.7526855; Critic Loss:   3729.9836426; Batch Reward:   -379.5858581\n",
      "Actor Loss:  -2753.2592773; Critic Loss:   3026.1320801; Batch Reward:   -297.1157822\n",
      "Completed 100 Training Iterations\n",
      "\n",
      "Actor Loss:  -2777.6037598; Critic Loss:   2803.9624023; Batch Reward:   -341.5967089\n",
      "Actor Loss:  -2767.6181641; Critic Loss:   3550.1088867; Batch Reward:   -317.6491985\n",
      "Actor Loss:  -2680.8398438; Critic Loss:   3818.3232422; Batch Reward:   -339.6603035\n",
      "Actor Loss:  -2516.5490723; Critic Loss:   3697.2373047; Batch Reward:   -295.5902194\n",
      "Actor Loss:  -2709.5615234; Critic Loss:   3286.5927734; Batch Reward:   -361.3672056\n",
      "Actor Loss:  -2667.8403320; Critic Loss:   2442.8532715; Batch Reward:   -285.8002887\n",
      "Actor Loss:  -2629.9370117; Critic Loss:   4083.1457520; Batch Reward:   -370.3145079\n",
      "Actor Loss:  -2593.2656250; Critic Loss:   3123.3833008; Batch Reward:   -280.4882999\n",
      "Actor Loss:  -2808.3955078; Critic Loss:   5116.3520508; Batch Reward:   -410.2319868\n",
      "Actor Loss:  -2586.2419434; Critic Loss:   3115.8105469; Batch Reward:   -236.8669415\n",
      "Actor Loss:  -2781.0979004; Critic Loss:   4885.3969727; Batch Reward:   -402.7770116\n",
      "Actor Loss:  -2730.8256836; Critic Loss:   3049.9804688; Batch Reward:   -255.2083302\n",
      "Actor Loss:  -3004.4531250; Critic Loss:   4515.4077148; Batch Reward:   -404.1865410\n",
      "Actor Loss:  -2698.2543945; Critic Loss:   2905.7783203; Batch Reward:   -274.9133365\n",
      "Actor Loss:  -3063.7570801; Critic Loss:   4206.7246094; Batch Reward:   -383.1825045\n",
      "Actor Loss:  -2841.2170410; Critic Loss:   2831.1608887; Batch Reward:   -270.2591720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor Loss:  -3256.1208496; Critic Loss:   4891.6206055; Batch Reward:   -426.3851060\n",
      "Actor Loss:  -2679.6530762; Critic Loss:   3083.7536621; Batch Reward:   -249.8881587\n",
      "Actor Loss:  -3157.9362793; Critic Loss:   4415.2744141; Batch Reward:   -384.6000101\n",
      "Actor Loss:  -2898.5368652; Critic Loss:   3245.9897461; Batch Reward:   -320.0187747\n",
      "Actor Loss:  -2592.5515137; Critic Loss:   3210.8525391; Batch Reward:   -341.3499625\n",
      "Actor Loss:  -2677.5722656; Critic Loss:   2978.8103027; Batch Reward:   -313.9854044\n",
      "Actor Loss:  -2539.4543457; Critic Loss:   4397.3427734; Batch Reward:   -369.0603134\n",
      "Actor Loss:  -2426.0788574; Critic Loss:   2702.8454590; Batch Reward:   -280.4964736\n",
      "Actor Loss:  -2647.3310547; Critic Loss:   3392.3691406; Batch Reward:   -369.8015013\n",
      "Actor Loss:  -2429.7531738; Critic Loss:   2659.8249512; Batch Reward:   -269.6050127\n",
      "Actor Loss:  -2493.1557617; Critic Loss:   3577.6528320; Batch Reward:   -364.4627450\n",
      "Actor Loss:  -2503.5668945; Critic Loss:   2442.7683105; Batch Reward:   -329.3818605\n",
      "Actor Loss:  -2664.3908691; Critic Loss:   3435.2758789; Batch Reward:   -337.2113852\n",
      "Actor Loss:  -2648.8994141; Critic Loss:   3305.5676270; Batch Reward:   -321.5227589\n",
      "Actor Loss:  -2565.0793457; Critic Loss:   3280.4768066; Batch Reward:   -325.1552840\n",
      "Actor Loss:  -2688.5283203; Critic Loss:   3915.4584961; Batch Reward:   -331.5535230\n",
      "Actor Loss:  -2650.2053223; Critic Loss:   3281.2946777; Batch Reward:   -346.4108898\n",
      "Actor Loss:  -2724.5791016; Critic Loss:   3264.4780273; Batch Reward:   -327.2939622\n",
      "Actor Loss:  -2761.2209473; Critic Loss:   3400.5317383; Batch Reward:   -342.7415254\n",
      "Actor Loss:  -2603.8222656; Critic Loss:   3375.1611328; Batch Reward:   -315.8653919\n",
      "Actor Loss:  -2696.3854980; Critic Loss:   3491.7341309; Batch Reward:   -364.2223808\n",
      "Actor Loss:  -2643.4033203; Critic Loss:   2913.8703613; Batch Reward:   -326.5063227\n",
      "Actor Loss:  -2708.8361816; Critic Loss:   4498.0620117; Batch Reward:   -416.1688361\n",
      "Actor Loss:  -2733.1782227; Critic Loss:   4074.8395996; Batch Reward:   -211.5518512\n",
      "Actor Loss:  -2895.2355957; Critic Loss:   4443.4960938; Batch Reward:   -424.8979478\n",
      "Actor Loss:  -2798.6379395; Critic Loss:   3597.9519043; Batch Reward:   -291.7816637\n",
      "Actor Loss:  -2986.9443359; Critic Loss:   3700.0527344; Batch Reward:   -385.0957864\n",
      "Actor Loss:  -2804.6545410; Critic Loss:   2649.4106445; Batch Reward:   -300.5041944\n",
      "Actor Loss:  -2945.7932129; Critic Loss:   3766.4807129; Batch Reward:   -381.3119679\n",
      "Actor Loss:  -2749.8483887; Critic Loss:   2664.8786621; Batch Reward:   -294.1870041\n",
      "Actor Loss:  -2891.3083496; Critic Loss:   4638.8227539; Batch Reward:   -393.3722406\n",
      "Actor Loss:  -2614.9301758; Critic Loss:   2991.5427246; Batch Reward:   -267.1800830\n",
      "Actor Loss:  -2854.5378418; Critic Loss:   4281.4233398; Batch Reward:   -418.9758609\n",
      "Actor Loss:  -2577.6494141; Critic Loss:   3156.2341309; Batch Reward:   -271.3593107\n",
      "Actor Loss:  -2901.1286621; Critic Loss:   2831.4206543; Batch Reward:   -344.4499541\n",
      "Actor Loss:  -2631.9611816; Critic Loss:   2680.9475098; Batch Reward:   -303.6336338\n",
      "Actor Loss:  -2651.5207520; Critic Loss:   4556.3359375; Batch Reward:   -392.2566730\n",
      "Actor Loss:  -2657.3728027; Critic Loss:   2174.6574707; Batch Reward:   -292.0359353\n",
      "Actor Loss:  -2489.8349609; Critic Loss:   4394.6933594; Batch Reward:   -373.2483099\n",
      "Actor Loss:  -2603.7639160; Critic Loss:   2735.1967773; Batch Reward:   -333.4314753\n",
      "Actor Loss:  -2845.5456543; Critic Loss:   3147.9633789; Batch Reward:   -369.1767655\n",
      "Actor Loss:  -2795.7878418; Critic Loss:   3586.8630371; Batch Reward:   -349.4014725\n",
      "Actor Loss:  -2772.4807129; Critic Loss:   3455.7080078; Batch Reward:   -323.3007287\n",
      "Actor Loss:  -3120.0727539; Critic Loss:   3291.7045898; Batch Reward:   -369.4543895\n",
      "Actor Loss:  -2690.5612793; Critic Loss:   4610.9072266; Batch Reward:   -266.2866659\n",
      "Actor Loss:  -2892.9941406; Critic Loss:   4421.3471680; Batch Reward:   -421.0056829\n",
      "Actor Loss:  -2783.1931152; Critic Loss:   4626.8496094; Batch Reward:   -218.9162141\n",
      "Actor Loss:  -2897.8503418; Critic Loss:   5485.2714844; Batch Reward:   -439.9046388\n",
      "Actor Loss:  -2531.2119141; Critic Loss:   3024.2365723; Batch Reward:   -270.9237636\n",
      "Actor Loss:  -2500.2033691; Critic Loss:   3398.1650391; Batch Reward:   -339.8561805\n",
      "Actor Loss:  -2789.3071289; Critic Loss:   3160.3972168; Batch Reward:   -342.4722833\n",
      "Actor Loss:  -2519.7958984; Critic Loss:   3185.9995117; Batch Reward:   -325.4070210\n",
      "Actor Loss:  -2489.2133789; Critic Loss:   3338.7568359; Batch Reward:   -352.3662765\n",
      "Actor Loss:  -2469.8122559; Critic Loss:   3065.0891113; Batch Reward:   -318.0847513\n",
      "Actor Loss:  -2760.1318359; Critic Loss:   3084.8688965; Batch Reward:   -375.6457267\n",
      "Actor Loss:  -2615.8955078; Critic Loss:   3108.0588379; Batch Reward:   -320.5990340\n",
      "Actor Loss:  -2954.1772461; Critic Loss:   3106.5976562; Batch Reward:   -370.1856798\n",
      "Actor Loss:  -2641.8105469; Critic Loss:   3193.2609863; Batch Reward:   -284.1702266\n",
      "Actor Loss:  -2968.5278320; Critic Loss:   3231.7785645; Batch Reward:   -374.6697876\n",
      "Actor Loss:  -2644.4536133; Critic Loss:   2808.6437988; Batch Reward:   -276.5369665\n",
      "Actor Loss:  -3057.0747070; Critic Loss:   3898.2580566; Batch Reward:   -378.8970321\n",
      "Actor Loss:  -2838.9470215; Critic Loss:   3468.1257324; Batch Reward:   -303.7047887\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-a08885fb812c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.012\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Completed 100 Training Iterations\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-ba00aadf59fb>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, train_func, rollout, a_rate, c_rate, decay, render, e_encr, e_dscr, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_encr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.007\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_dscr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0;34m'invalid train_func name specified'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_encr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_dscr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Close the display window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-154-ba00aadf59fb>\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(self, batch, a_rate, c_rate, e_encr, e_dscr, verbose)\u001b[0m\n\u001b[1;32m    107\u001b[0m         c_loss = self.critic.update(batch['obs'],\n\u001b[1;32m    108\u001b[0m                            \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'td_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                            c_rate)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-153-09a0d49ce00e>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, obs, target, l_rate)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m       \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         })\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    for _ in range(100):\n",
    "        handler.run('train_all', rollout=100, a_rate=0.001, c_rate=0.012, decay=0.98, render=False, verbose=True)\n",
    "        handler.play()\n",
    "    print('Completed 100 Training Iterations\\n')\n",
    "    handler.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.run_constant_training(1000, render=False, decay=0.99, a_rate=0.002, c_rate=0.01, e_encr=0.008, e_dscr=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .models/l1.cpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .models/l1.cpt\n"
     ]
    }
   ],
   "source": [
    "handler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.unwrapped.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.1062035e-06 2.1275442e-05 5.6120130e-05 9.9991453e-01]] [[-4.670416  -3.7054915 -2.7355506  7.0523796]] [0.00095868]\n",
      "[[7.8590192e-06 2.0009598e-05 5.2955500e-05 9.9991918e-01]] [[-4.675467  -3.7409163 -2.767677   7.078301 ]] [0.00091109]\n",
      "[[7.6236875e-06 1.8806415e-05 4.9962448e-05 9.9992359e-01]] [[-4.679423  -3.7764852 -2.7994115  7.1047506]] [0.00086573]\n",
      "[[7.5754178e-06 1.7795739e-05 4.7487902e-05 9.9992716e-01]] [[-4.666027  -3.811976  -2.8304603  7.1245027]] [0.00082952]\n",
      "[[7.5232933e-06 1.6968739e-05 4.5331431e-05 9.9993014e-01]] [[-4.6527047 -3.8393364 -2.8567085  7.144732 ]] [0.00079838]\n",
      "[[7.3798687e-06 1.5923879e-05 4.2898635e-05 9.9993384e-01]] [[-4.6407466 -3.8716817 -2.8806615  7.1759424]] [0.0007607]\n",
      "[[7.19089394e-06 1.49880525e-05 4.06964318e-05 9.99937177e-01]] [[-4.6342506 -3.899813  -2.9009259  7.208381 ]] [0.00072589]\n",
      "[[6.9537482e-06 1.4069132e-05 3.8550577e-05 9.9994040e-01]] [[-4.6333547 -3.9286523 -2.9206645  7.2428155]] [0.00069117]\n",
      "[[6.7149381e-06 1.3205517e-05 3.6575726e-05 9.9994349e-01]] [[-4.634421 -3.95812  -2.93937   7.276699]] [0.00065851]\n",
      "[[6.5589893e-06 1.2442538e-05 3.5127247e-05 9.9994588e-01]] [[-4.6305156 -3.9902306 -2.952375   7.304105 ]] [0.00063321]\n",
      "[[6.3114389e-06 1.1754583e-05 3.3883287e-05 9.9994802e-01]] [[-4.6403937 -4.0185137 -2.959835   7.3327017]] [0.00060972]\n",
      "[[6.1757537e-06 1.1180201e-05 3.3112734e-05 9.9994957e-01]] [[-4.6415005 -4.0479865 -2.9622128  7.353329 ]] [0.00059355]\n",
      "[[6.0981388e-06 1.0709877e-05 3.2381457e-05 9.9995077e-01]] [[-4.6362405 -4.0730577 -2.966638   7.3712373]] [0.00057978]\n",
      "[[6.0615421e-06 1.0223718e-05 3.1765780e-05 9.9995196e-01]] [[-4.6230493 -4.1003027 -2.9666235  7.3904495]] [0.00056734]\n",
      "[[5.8758960e-06 9.7851735e-06 3.1119882e-05 9.9995327e-01]] [[-4.6256833 -4.115674  -2.9586947  7.418922 ]] [0.00055332]\n",
      "[[5.6757776e-06 9.2283572e-06 3.0102445e-05 9.9995494e-01]] [[-4.6193056 -4.1332326 -2.950907   7.459952 ]] [0.000534]\n",
      "[[5.5747923e-06 8.7743701e-06 2.9229526e-05 9.9995637e-01]] [[-4.604537 -4.150957 -2.947613  7.492675]] [0.0005184]\n",
      "[[5.4750508e-06 8.3259465e-06 2.8447796e-05 9.9995780e-01]] [[-4.5899777 -4.170803  -2.9421086  7.5252886]] [0.00050369]\n",
      "[[5.3871458e-06 8.0162354e-06 2.7942588e-05 9.9995863e-01]] [[-4.5812473 -4.183794  -2.9351106  7.550206 ]] [0.00049377]\n",
      "[[5.3497411e-06 7.6293009e-06 2.7429269e-05 9.9995959e-01]] [[-4.5592427 -4.204295  -2.9246807  7.579179 ]] [0.00048336]\n",
      "[[5.2712335e-06 7.2940029e-06 2.6772570e-05 9.9996066e-01]] [[-4.544442  -4.2196536 -2.9193292  7.6087646]] [0.00047154]\n",
      "[[5.1225179e-06 6.9260354e-06 2.5880741e-05 9.9996209e-01]] [[-4.5360136 -4.234372  -2.916161   7.645813 ]] [0.00045595]\n",
      "[[4.9601940e-06 6.5163786e-06 2.4933470e-05 9.9996364e-01]] [[-4.5264845 -4.2536106 -2.9117184  7.687545 ]] [0.00043903]\n",
      "[[4.9411465e-06 6.2919971e-06 2.4472338e-05 9.9996424e-01]] [[-4.506107  -4.2644258 -2.906161   7.7117705]] [0.00043133]\n",
      "[[4.8073930e-06 5.9383879e-06 2.3529488e-05 9.9996567e-01]] [[-4.4924345 -4.2811522 -2.9043348  7.752887 ]] [0.00041542]\n",
      "[[4.7347748e-06 5.7457664e-06 2.3071390e-05 9.9996650e-01]] [[-4.4811726 -4.2876434 -2.8975134  7.7793703]] [0.00040721]\n",
      "[[4.7190597e-06 5.5409946e-06 2.2451432e-05 9.9996734e-01]] [[-4.461937  -4.3013725 -2.9021924  7.8019314]] [0.00039793]\n",
      "[[4.7224084e-06 5.3160170e-06 2.1774207e-05 9.9996817e-01]] [[-4.4364815 -4.3180766 -2.9080744  7.8266783]] [0.00038804]\n",
      "[[4.7816065e-06 5.1363331e-06 2.1150056e-05 9.9996889e-01]] [[-4.402131  -4.330569  -2.9152653  7.848572 ]] [0.0003799]\n",
      "[[4.9312380e-06 5.0817544e-06 2.0803383e-05 9.9996912e-01]] [[-4.360141  -4.330074  -2.9206154  7.859749 ]] [0.00037735]\n",
      "[[4.8674333e-06 4.9386463e-06 1.9940628e-05 9.9997020e-01]] [[-4.339555  -4.325031  -2.9293625  7.893359 ]] [0.0003655]\n",
      "[[4.7017370e-06 4.9713976e-06 1.9305380e-05 9.9997103e-01]] [[-4.340581  -4.284812  -2.9281297  7.926968 ]] [0.00035692]\n",
      "[[4.4092458e-06 4.9390110e-06 1.8061794e-05 9.9997258e-01]] [[-4.3456173 -4.2321553 -2.935522   7.9861627]] [0.0003394]\n",
      "[[4.1391327e-06 4.8511129e-06 1.6718992e-05 9.9997425e-01]] [[-4.3508854 -4.1921635 -2.9548264  8.044113 ]] [0.0003203]\n",
      "[[3.6858858e-06 4.5230327e-06 1.4706414e-05 9.9997711e-01]] [[-4.37826   -4.1735883 -2.994487   8.132717 ]] [0.00028831]\n",
      "[[3.3985841e-06 4.2987213e-06 1.3340428e-05 9.9997902e-01]] [[-4.3949723 -4.1600137 -3.0275323  8.197158 ]] [0.00026664]\n",
      "[[3.1214065e-06 3.9050674e-06 1.1877870e-05 9.9998105e-01]] [[-4.4105706 -4.1865788 -3.0741773  8.266638 ]] [0.00024186]\n",
      "[[2.8052657e-06 3.4918055e-06 1.0421366e-05 9.9998331e-01]] [[-4.434784  -4.2158628 -3.1224244  8.349212 ]] [0.00021598]\n",
      "[[2.5844047e-06 3.2227022e-06 9.4185152e-06 9.9998474e-01]] [[-4.449481  -4.2287555 -3.1562989  8.416519 ]] [0.00019826]\n",
      "[[2.2688753e-06 2.8708664e-06 8.1932794e-06 9.9998665e-01]] [[-4.4816647 -4.2463346 -3.1976345  8.514548 ]] [0.00017543]\n",
      "[[2.0178691e-06 2.6092755e-06 7.2047560e-06 9.9998820e-01]] [[-4.5078874 -4.250858  -3.2351885  8.605569 ]] [0.00015712]\n",
      "[[1.6529525e-06 2.2246916e-06 5.8764776e-06 9.9999022e-01]] [[-4.563592  -4.2665367 -3.2951972  8.749346 ]] [0.00013152]\n",
      "[[1.3901698e-06 1.9464817e-06 4.9048867e-06 9.9999177e-01]] [[-4.608768  -4.272171  -3.3479624  8.877308 ]] [0.00011253]\n",
      "[[1.1130733e-06 1.6774368e-06 3.9849970e-06 9.9999321e-01]] [[-4.6810265 -4.2708845 -3.405615   9.027352 ]] [9.390567e-05]\n",
      "[[8.9503254e-07 1.4711303e-06 3.2845069e-06 9.9999440e-01]] [[-4.753664  -4.2567377 -3.453552   9.172736 ]] [7.9295074e-05]\n",
      "[[7.3978566e-07 1.3314365e-06 2.7856745e-06 9.9999511e-01]] [[-4.8163376 -4.228684  -3.490453   9.300563 ]] [6.8976005e-05]\n",
      "[[5.7706620e-07 1.1396604e-06 2.2345707e-06 9.9999607e-01]] [[-4.900384 -4.219856 -3.546537  9.464921]] [5.6894663e-05]\n",
      "[[4.5689794e-07 9.9520264e-07 1.8247669e-06 9.9999678e-01]] [[-4.9789376 -4.2004504 -3.5941894  9.619865 ]] [4.7755402e-05]\n",
      "[[3.7368295e-07 8.9459718e-07 1.5335662e-06 9.9999714e-01]] [[-5.042961  -4.169996  -3.6310174  9.756894 ]] [4.1381685e-05]\n",
      "[[3.0933867e-07 7.8372290e-07 1.2804795e-06 9.9999762e-01]] [[-5.0979943 -4.168376  -3.6774418  9.890832 ]] [3.541323e-05]\n",
      "[[2.4114755e-07 6.5745468e-07 1.0151335e-06 9.9999809e-01]] [[-5.1759243 -4.172957  -3.7385576 10.061931 ]] [2.8950055e-05]\n",
      "[[1.8426324e-07 5.4165002e-07 7.8947727e-07 9.9999845e-01]] [[-5.2613974 -4.1831427 -3.8063917 10.2455015]] [2.3315997e-05]\n",
      "[[1.4227946e-07 4.5767777e-07 6.2883839e-07 9.9999881e-01]] [[-5.345813  -4.17744   -3.8597314 10.419659 ]] [1.9095394e-05]\n",
      "[[1.1043677e-07 3.9439664e-07 5.0830619e-07 9.9999905e-01]] [[-5.431846  -4.1589317 -3.9052045 10.586976 ]] [1.5904943e-05]\n",
      "[[8.2963126e-08 3.3018603e-07 3.9820137e-07 9.9999917e-01]] [[-5.5317726 -4.150513  -3.9632113 10.773096 ]] [1.2982753e-05]\n",
      "[[6.0723885e-08 2.6665791e-07 3.0160564e-07 9.9999940e-01]] [[-5.640484 -4.160854 -4.0377   10.976444]] [1.01699225e-05]\n",
      "[[4.5095192e-08 2.1906715e-07 2.3232826e-07 9.9999952e-01]] [[-5.7452464 -4.164644  -4.1058707 11.169244 ]] [8.147591e-06]\n",
      "[[3.4695393e-08 1.8759209e-07 1.8588619e-07 9.9999964e-01]] [[-5.8399134 -4.1522503 -4.161386  11.336745 ]] [6.7400806e-06]\n",
      "[[2.6305601e-08 1.5850894e-07 1.4668001e-07 9.9999964e-01]] [[-5.9402966 -4.144268  -4.221825  11.513186 ]] [5.60661e-06]\n",
      "[[1.9894346e-08 1.3381083e-07 1.1550560e-07 9.9999976e-01]] [[-6.041756 -4.135764 -4.282872 11.691074]] [4.554084e-06]\n",
      "[[1.5044160e-08 1.1312524e-07 9.0987669e-08 9.9999976e-01]] [[-6.143527  -4.126022  -4.3437934 11.868748 ]] [3.7939517e-06]\n",
      "[[3.9381288e-05 9.5274605e-05 2.4025216e-04 9.9962509e-01]] [[-4.051812  -3.1683397 -2.2434137  6.0900326]] [0.0036586]\n",
      "[[3.9147184e-05 8.9522691e-05 2.3387502e-04 9.9963748e-01]] [[-4.0306444 -3.2034807 -2.2431858  6.117175 ]] [0.00354953]\n",
      "[[3.9121955e-05 8.4352687e-05 2.2850765e-04 9.9964797e-01]] [[-4.005049  -3.236726  -2.2401628  6.1434255]] [0.00345607]\n",
      "[[3.8874710e-05 7.8698577e-05 2.2288077e-04 9.9965954e-01]] [[-3.9761996 -3.2709184 -2.229906   6.1786265]] [0.00335305]\n",
      "[[3.7595208e-05 7.3119416e-05 2.1542827e-04 9.9967384e-01]] [[-3.9705334 -3.305316  -2.2247822  6.2177744]] [0.00322433]\n",
      "[[3.5432178e-05 6.6159038e-05 2.0330763e-04 9.9969518e-01]] [[-3.970457  -3.3460157 -2.223357   6.277128 ]] [0.00303283]\n",
      "[[3.3582284e-05 5.9573871e-05 1.9108341e-04 9.9971575e-01]] [[-3.9610481 -3.38783   -2.2223375  6.340179 ]] [0.00284592]\n",
      "[[3.1765681e-05 5.4119821e-05 1.7991112e-04 9.9973422e-01]] [[-3.9561157 -3.4233017 -2.2220397  6.4007425]] [0.00267782]\n",
      "[[3.0760537e-05 4.9482464e-05 1.7101310e-04 9.9974877e-01]] [[-3.9367487 -3.4613633 -2.221241   6.452278 ]] [0.00254467]\n",
      "[[3.0460298e-05 4.6431927e-05 1.6388755e-04 9.9975926e-01]] [[-3.9085836 -3.48702   -2.2258263  6.4902625]] [0.00244925]\n",
      "[[2.9757179e-05 4.3499487e-05 1.5711880e-04 9.9976963e-01]] [[-3.8898208 -3.5101418 -2.2258885  6.532389 ]] [0.00235347]\n",
      "[[2.8631115e-05 4.0230439e-05 1.5131726e-04 9.9977988e-01]] [[-3.8810766 -3.5409465 -2.2161925  6.5797195]] [0.00225778]\n",
      "[[2.7701644e-05 3.7976526e-05 1.4816943e-04 9.9978620e-01]] [[-3.878916  -3.5634398 -2.2020514  6.6148887]] [0.00219746]\n",
      "[[2.7230230e-05 3.6152302e-05 1.4645536e-04 9.9979013e-01]] [[-3.8689556 -3.5855422 -2.1865618  6.642018 ]] [0.00215885]\n",
      "[[2.7205657e-05 3.4641904e-05 1.4575568e-04 9.9979240e-01]] [[-3.850499  -3.6088595 -2.171992   6.661379 ]] [0.0021369]\n",
      "[[2.7236896e-05 3.3600216e-05 1.4645883e-04 9.9979275e-01]] [[-3.8346057 -3.6246457 -2.1524339  6.676125 ]] [0.00213267]\n",
      "[[2.7245424e-05 3.3023887e-05 1.4870342e-04 9.9979109e-01]] [[-3.8231158 -3.6307702 -2.1260478  6.6873   ]] [0.00214661]\n",
      "[[2.7393162e-05 3.2656601e-05 1.5217139e-04 9.9978775e-01]] [[-3.8092675 -3.6335146 -2.0945544  6.695737 ]] [0.00217499]\n",
      "[[2.7536949e-05 3.2263695e-05 1.5567230e-04 9.9978453e-01]] [[-3.7949946 -3.6365805 -2.0627697  6.704772 ]] [0.00220314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.7771599e-05 3.1256684e-05 1.5614994e-04 9.9978489e-01]] [[-3.76889   -3.6506708 -2.0420866  6.7223916]] [0.0021993]\n",
      "[[2.6898926e-05 2.8600434e-05 1.4679669e-04 9.9979776e-01]] [[-3.7522483 -3.6909125 -2.0552855  6.770974 ]] [0.0020802]\n",
      "[[2.6026477e-05 2.6602622e-05 1.3686056e-04 9.9981052e-01]] [[-3.7363014 -3.7144065 -2.076453   6.8199053]] [0.00196204]\n",
      "[[2.5450310e-05 2.5209209e-05 1.2822710e-04 9.9982113e-01]] [[-3.7165165 -3.7260349 -2.099441   6.8620877]] [0.00186415]\n",
      "[[2.43509985e-05 2.41933176e-05 1.19729695e-04 9.99831676e-01]] [[-3.7162144 -3.7227106 -2.123551   6.906555 ]] [0.00176534]\n",
      "[[2.2989590e-05 2.3535133e-05 1.1315743e-04 9.9984026e-01]] [[-3.7236786 -3.7002258 -2.12994    6.95663  ]] [0.00168431]\n",
      "[[2.1036951e-05 2.2223687e-05 1.0187664e-04 9.9985480e-01]] [[-3.741583  -3.6867042 -2.1641002  7.027502 ]] [0.00154627]\n",
      "[[1.9382080e-05 2.0805819e-05 9.2010370e-05 9.9986780e-01]] [[-3.7593172 -3.6884334 -2.201765   7.091712 ]] [0.00142191]\n",
      "[[1.8229504e-05 1.9780391e-05 8.5293308e-05 9.9987674e-01]] [[-3.7688775 -3.6872287 -2.2258236  7.143468 ]] [0.00133557]\n",
      "[[1.6784212e-05 1.8622528e-05 7.7548735e-05 9.9988699e-01]] [[-3.7848754 -3.680942  -2.254408   7.210083 ]] [0.00123434]\n",
      "[[1.4639788e-05 1.6549549e-05 6.6355016e-05 9.9990249e-01]] [[-3.8180187 -3.6954021 -2.3067427  7.3136516]] [0.00108104]\n",
      "[[1.2900782e-05 1.4884537e-05 5.8018461e-05 9.9991417e-01]] [[-3.8487682 -3.7057333 -2.3452954  7.4093685]] [0.00096247]\n",
      "[[1.11958725e-05 1.32207269e-05 5.01204122e-05 9.99925494e-01]] [[-3.884297  -3.7180564 -2.385414   7.5155935]] [0.0008469]\n",
      "[[9.6545418e-06 1.1491225e-05 4.2451353e-05 9.9993634e-01]] [[-3.91976   -3.7456048 -2.4388294  7.6282587]] [0.00073321]\n",
      "[[8.2374809e-06 9.8487399e-06 3.5501362e-05 9.9994636e-01]] [[-3.957715  -3.7790656 -2.496838   7.7490478]] [0.00062736]\n",
      "[[6.946554e-06 8.450582e-06 2.935246e-05 9.999553e-01]] [[-4.0003734 -3.8043833 -2.5592427  7.876847 ]] [0.00053225]\n",
      "[[6.0347566e-06 7.4590962e-06 2.4926119e-05 9.9996161e-01]] [[-4.0320263 -3.820127  -2.613646   7.9859104]] [0.00046318]\n",
      "[[5.1141519e-06 6.4245505e-06 2.0497482e-05 9.9996793e-01]] [[-4.0696793 -3.8415644 -2.681389   8.113788 ]] [0.00039246]\n",
      "[[4.2863585e-06 5.5336086e-06 1.6780108e-05 9.9997342e-01]] [[-4.1088796 -3.8534765 -2.7441227  8.251167 ]] [0.00033105]\n",
      "[[3.5454734e-06 4.7130525e-06 1.3592342e-05 9.9997818e-01]] [[-4.15254   -3.8678758 -2.808705   8.397277 ]] [0.00027643]\n",
      "[[3.0748311e-06 4.2321003e-06 1.1600064e-05 9.9998105e-01]] [[-4.1798906 -3.8604417 -2.8521297  8.512351 ]] [0.00024217]\n",
      "[[2.5764177e-06 3.6732863e-06 9.5433124e-06 9.9998426e-01]] [[-4.2190003 -3.864314  -2.90956    8.650094 ]] [0.00020518]\n",
      "[[2.1998135e-06 3.3208244e-06 8.1257422e-06 9.9998641e-01]] [[-4.2577825 -3.845943  -2.9511182  8.769341 ]] [0.00017938]\n",
      "[[1.7817698e-06 2.8704455e-06 6.5677209e-06 9.9998879e-01]] [[-4.3200045 -3.8431442 -3.0154445  8.917888 ]] [0.0001498]\n",
      "[[1.4556091e-06 2.5006286e-06 5.3872259e-06 9.9999070e-01]] [[-4.383988  -3.8428705 -3.0753822  9.056088 ]] [0.00012647]\n",
      "[[1.1453875e-06 2.0921905e-06 4.2284814e-06 9.9999249e-01]] [[-4.459547 -3.857078 -3.153447  9.220213]] [0.00010286]\n",
      "[[9.2688521e-07 1.8115870e-06 3.4402249e-06 9.9999380e-01]] [[-4.5277452 -3.8576167 -3.216283   9.363685 ]] [8.630412e-05]\n",
      "[[6.9122785e-07 1.4578358e-06 2.6112552e-06 9.9999523e-01]] [[-4.6256075 -3.8793683 -3.2964904  9.559184 ]] [6.7733956e-05]\n",
      "[[5.0556417e-07 1.1632928e-06 1.9639003e-06 9.9999642e-01]] [[-4.733196  -3.8998604 -3.3761823  9.764392 ]] [5.2608055e-05]\n",
      "[[3.6930481e-07 9.3245006e-07 1.4824070e-06 9.9999726e-01]] [[-4.843894  -3.9177008 -3.4540937  9.967747 ]] [4.1055948e-05]\n",
      "[[2.7048739e-07 7.5133522e-07 1.1322157e-06 9.9999785e-01]] [[-4.96418   -3.942554  -3.5324736 10.158858 ]] [3.2332788e-05]\n",
      "[[1.9621790e-07 5.9912946e-07 8.5436869e-07 9.9999833e-01]] [[-5.08697   -3.9707181 -3.6158333 10.357068 ]] [2.5221538e-05]\n",
      "[[1.4315994e-07 4.8662793e-07 6.5715483e-07 9.9999869e-01]] [[-5.212436  -3.988899  -3.6884797 10.546865 ]] [1.999574e-05]\n",
      "[[1.0328098e-07 3.9217963e-07 5.0068775e-07 9.9999905e-01]] [[-5.342319 -4.008053 -3.76379  10.743492]] [1.5663907e-05]\n",
      "[[7.5083008e-08 3.1997266e-07 3.8621513e-07 9.9999917e-01]] [[-5.47147   -4.0218277 -3.8336682 10.933202 ]] [1.2554568e-05]\n",
      "[[5.3736748e-08 2.5645735e-07 2.9179367e-07 9.9999940e-01]] [[-5.6042533 -4.0413876 -3.9123032 11.134915 ]] [9.778313e-06]\n",
      "[[3.8438444e-08 2.0561386e-07 2.2051007e-07 9.9999952e-01]] [[-5.737544  -4.060601  -3.9906573 11.336664 ]] [7.678863e-06]\n",
      "[[2.7884219e-08 1.6767846e-07 1.6986579e-07 9.9999964e-01]] [[-5.8679805 -4.073993  -4.0610337 11.527224 ]] [6.1065793e-06]\n",
      "[[2.9513697e-06 9.2286309e-06 2.8980263e-05 9.9995887e-01]] [[-5.1604614 -4.0204206 -2.8761153  7.5727386]] [0.00048851]\n",
      "[[3.0003353e-06 8.9488767e-06 2.8210996e-05 9.9995983e-01]] [[-5.131614  -4.0388103 -2.8906267  7.585132 ]] [0.00047788]\n",
      "[[3.0433591e-06 8.5896882e-06 2.7158143e-05 9.9996126e-01]] [[-5.09839   -4.0607896 -2.9096751  7.60412  ]] [0.00046314]\n",
      "[[2.9728569e-06 8.0829905e-06 2.5816749e-05 9.9996316e-01]] [[-5.088911  -4.088673  -2.9274113  7.637039 ]] [0.00044219]\n",
      "[[3.0431738e-06 7.7137347e-06 2.4964676e-05 9.9996424e-01]] [[-5.054049  -4.1239476 -2.9494886  7.6485248]] [0.00042981]\n",
      "[[3.0527769e-06 7.2860385e-06 2.3874216e-05 9.9996579e-01]] [[-5.030631  -4.1607227 -2.9738834  7.6687937]] [0.00041326]\n",
      "[[2.8899099e-06 6.7449873e-06 2.2222030e-05 9.9996817e-01]] [[-5.038311  -4.1907372 -2.998453   7.715942 ]] [0.00038709]\n",
      "[[2.8106283e-06 6.3827952e-06 2.1180289e-05 9.9996960e-01]] [[-5.0324564 -4.2122574 -3.0127926  7.749616 ]] [0.00037063]\n",
      "[[2.6853334e-06 6.0243369e-06 2.0162699e-05 9.9997115e-01]] [[-5.0394692 -4.231467  -3.0234392  7.788208 ]] [0.0003537]\n",
      "[[2.6096723e-06 5.6882427e-06 1.9289968e-05 9.9997246e-01]] [[-5.0322075 -4.253031  -3.031847   7.8240504]] [0.0003392]\n",
      "[[2.5695942e-06 5.2849855e-06 1.8148410e-05 9.9997401e-01]] [[-5.001144  -4.2800217 -3.0463085  7.870593 ]] [0.0003214]\n",
      "[[2.5268569e-06 4.9385208e-06 1.7163513e-05 9.9997532e-01]] [[-4.972974  -4.302884  -3.0571635  7.9155364]] [0.00030592]\n",
      "[[2.5107699e-06 4.6507453e-06 1.6382710e-05 9.9997640e-01]] [[-4.9369354 -4.3204975 -3.0612993  7.9579616]] [0.00029361]\n",
      "[[2.4522833e-06 4.4147919e-06 1.5673217e-05 9.9997747e-01]] [[-4.9125676 -4.324627  -3.0576346  8.0059   ]] [0.00028205]\n",
      "[[2.3966936e-06 4.2338161e-06 1.5190694e-05 9.9997818e-01]] [[-4.8946185 -4.325606  -3.048026   8.04678  ]] [0.00027375]\n",
      "[[2.3411935e-06 4.0431601e-06 1.4871154e-05 9.9997878e-01]] [[-4.879414  -4.3330493 -3.0306525  8.085414 ]] [0.00026709]\n",
      "[[2.3054954e-06 3.8858980e-06 1.4673311e-05 9.9997914e-01]] [[-4.8620934 -4.3400354 -3.0113587  8.1181   ]] [0.0002625]\n",
      "[[2.29797524e-06 3.76568823e-06 1.46256725e-05 9.99979258e-01]] [[-4.838521 -4.344619 -2.987771  8.14494 ]] [0.00026043]\n",
      "[[2.2986223e-06 3.6735662e-06 1.4665942e-05 9.9997938e-01]] [[-4.8152227 -4.3463697 -2.962005   8.167957 ]] [0.00025967]\n",
      "[[2.2721392e-06 3.5837725e-06 1.4743450e-05 9.9997938e-01]] [[-4.8023796 -4.346686  -2.932303   8.192389 ]] [0.0002591]\n",
      "[[2.2633462e-06 3.4526986e-06 1.4696343e-05 9.9997962e-01]] [[-4.778999  -4.356687  -2.9082453  8.219646 ]] [0.00025677]\n",
      "[[2.2984777e-06 3.3854328e-06 1.4826657e-05 9.9997950e-01]] [[-4.750211  -4.3629766 -2.886031   8.233032 ]] [0.00025785]\n",
      "[[2.32464117e-06 3.24093912e-06 1.44749465e-05 9.99979973e-01]] [[-4.7129765 -4.380679  -2.8841226  8.258948 ]] [0.00025244]\n",
      "[[2.3895489e-06 3.1194047e-06 1.3985243e-05 9.9998045e-01]] [[-4.665861  -4.399324  -2.8989632  8.278525 ]] [0.00024635]\n",
      "[[2.4669430e-06 2.9890750e-06 1.3492470e-05 9.9998105e-01]] [[-4.61338   -4.4213963 -2.9142287  8.299131 ]] [0.00024013]\n",
      "[[2.4572648e-06 2.7961889e-06 1.2655860e-05 9.9998212e-01]] [[-4.5755987 -4.4463906 -2.9365268  8.340845 ]] [0.0002281]\n",
      "[[2.3709867e-06 2.6516491e-06 1.1743769e-05 9.9998319e-01]] [[-4.562544  -4.4506683 -2.962527   8.389644 ]] [0.00021488]\n",
      "[[2.3035711e-06 2.5532834e-06 1.0861595e-05 9.9998426e-01]] [[-4.550516  -4.4475965 -2.999743   8.430518 ]] [0.00020267]\n",
      "[[2.2228148e-06 2.4528877e-06 9.8385926e-06 9.9998546e-01]] [[-4.527571  -4.42908   -3.0400336  8.48915  ]] [0.0001886]\n",
      "[[2.1408916e-06 2.4248263e-06 9.0496142e-06 9.9998641e-01]] [[-4.515047  -4.390509  -3.0735476  8.5392275]] [0.00017798]\n",
      "[[2.0864766e-06 2.3809682e-06 8.3968889e-06 9.9998713e-01]] [[-4.5040607 -4.3720303 -3.1116765  8.57596  ]] [0.00016913]\n",
      "[[1.9584065e-06 2.1960407e-06 7.4172522e-06 9.9998844e-01]] [[-4.503421  -4.3888955 -3.1717436  8.639947 ]] [0.00015353]\n",
      "[[1.846844e-06 2.058781e-06 6.828760e-06 9.999893e-01]] [[-4.510763  -4.4021273 -3.2030985  8.691258 ]] [0.00014329]\n",
      "[[1.7403048e-06 1.9534070e-06 6.3049893e-06 9.9998999e-01]] [[-4.5172687 -4.4017544 -3.229988   8.744171 ]] [0.00013427]\n",
      "[[1.5447921e-06 1.7731392e-06 5.5444775e-06 9.9999118e-01]] [[-4.5418587 -4.403996  -3.2639453  8.838754 ]] [0.00012008]\n",
      "[[1.3302167e-06 1.6029143e-06 4.7882254e-06 9.9999225e-01]] [[-4.5797296 -4.393249  -3.298912   8.950431 ]] [0.00010579]\n",
      "[[1.1476717e-06 1.4077133e-06 4.0180148e-06 9.9999344e-01]] [[-4.6053    -4.4010687 -3.3522472  9.072469 ]] [9.114369e-05]\n",
      "[[9.9270619e-07 1.2507487e-06 3.3970841e-06 9.9999440e-01]] [[-4.633004  -4.401942  -3.4027662  9.189821 ]] [7.9102814e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.8093418e-07 1.1538654e-06 2.9454138e-06 9.9999499e-01]] [[-4.6586704 -4.388781  -3.4516487  9.2836075]] [7.057573e-05]\n",
      "[[7.1298257e-07 1.0026361e-06 2.3750929e-06 9.9999595e-01]] [[-4.726253  -4.3853216 -3.5229182  9.427552 ]] [5.8752397e-05]\n",
      "[[5.7114579e-07 8.6207302e-07 1.8933069e-06 9.9999666e-01]] [[-4.7975464 -4.3858514 -3.5991104  9.578072 ]] [4.8534814e-05]\n",
      "[[4.5685110e-07 7.4323037e-07 1.5068232e-06 9.9999726e-01]] [[-4.8708277 -4.3841796 -3.677426   9.728078 ]] [4.0099727e-05]\n",
      "[[3.8818524e-07 6.7981887e-07 1.2674324e-06 9.9999762e-01]] [[-4.923238  -4.362894  -3.7399719  9.838543 ]] [3.4978748e-05]\n",
      "[[3.2835118e-07 6.2261279e-07 1.0716783e-06 9.9999797e-01]] [[-4.977185  -4.3373446 -3.7942872  9.951995 ]] [3.055689e-05]\n",
      "[[2.8507415e-07 5.8842880e-07 9.3380629e-07 9.9999821e-01]] [[-5.0225005 -4.297794  -3.8359804 10.048015 ]] [2.7490803e-05]\n",
      "[[2.3534342e-07 5.3300744e-07 7.7787382e-07 9.9999845e-01]] [[-5.087093  -4.269603  -3.8915734 10.175126 ]] [2.378285e-05]\n",
      "[[1.8872331e-07 4.6817834e-07 6.2599855e-07 9.9999869e-01]] [[-5.1614046 -4.2528367 -3.9623384 10.321578 ]] [1.9998439e-05]\n",
      "[[1.6048331e-07 4.2750759e-07 5.2469017e-07 9.9999893e-01]] [[-5.2137036 -4.2339206 -4.0290847 10.431372 ]] [1.7440441e-05]\n",
      "[[1.3297152e-07 3.8029916e-07 4.2873617e-07 9.9999905e-01]] [[-5.2751184 -4.2242947 -4.104411  10.558012 ]] [1.49670395e-05]\n",
      "[[1.0991416e-07 3.4123954e-07 3.5360944e-07 9.9999917e-01]] [[-5.338735  -4.20585   -4.1702414 10.684831 ]] [1.2929865e-05]\n",
      "[[8.7159812e-08 2.9388426e-07 2.8003240e-07 9.9999928e-01]] [[-5.4171014 -4.2016587 -4.249939  10.838421 ]] [1.0777357e-05]\n",
      "[[9.8570536e-06 2.4311923e-05 6.1612991e-05 9.9990416e-01]] [[-4.541234  -3.6384544 -2.708548   6.9859934]] [0.00106508]\n",
      "[[9.7626398e-06 2.3325872e-05 5.8926413e-05 9.9990797e-01]] [[-4.5375504 -3.66655   -2.7398233  6.9993057]] [0.00102735]\n",
      "[[9.7287921e-06 2.2187576e-05 5.6158533e-05 9.9991190e-01]] [[-4.52448   -3.7000377 -2.7713916  7.0158525]] [0.00098777]\n",
      "[[9.5998739e-06 2.1100446e-05 5.3378400e-05 9.9991596e-01]] [[-4.517616  -3.7300723 -2.8019605  7.0360603]] [0.00094727]\n",
      "[[9.5717478e-06 2.0132273e-05 5.1058305e-05 9.9991918e-01]] [[-4.504212  -3.760704  -2.83006    7.0524015]] [0.00091372]\n",
      "[[9.4964544e-06 1.9236861e-05 4.9085491e-05 9.9992216e-01]] [[-4.4969497 -3.7910404 -2.854305   7.067564 ]] [0.00088357]\n",
      "[[9.2195105e-06 1.8067338e-05 4.6945552e-05 9.9992573e-01]] [[-4.501814  -3.8290303 -2.8741472  7.0923004]] [0.00084636]\n",
      "[[8.7829158e-06 1.6895383e-05 4.4893135e-05 9.9992943e-01]] [[-4.5191307 -3.8648992 -2.887654   7.123501 ]] [0.00080792]\n",
      "[[8.4025287e-06 1.5812091e-05 4.3018463e-05 9.9993277e-01]] [[-4.5342407 -3.9019978 -2.9011433  7.1526704]] [0.00077273]\n",
      "[[8.0423742e-06 1.4796451e-05 4.0918338e-05 9.9993622e-01]] [[-4.5436363 -3.9339733 -2.916782   7.187086 ]] [0.00073611]\n",
      "[[7.8247940e-06 1.3926554e-05 3.9383620e-05 9.9993885e-01]] [[-4.5443926 -3.9678924 -2.9283404  7.2137594]] [0.00070832]\n",
      "[[7.5841535e-06 1.3183237e-05 3.8218255e-05 9.9994099e-01]] [[-4.5516233 -3.9987378 -2.934371   7.2377677]] [0.00068532]\n",
      "[[7.3976921e-06 1.2562339e-05 3.7199192e-05 9.9994278e-01]] [[-4.5549083 -4.025372  -2.939789   7.2593775]] [0.00066578]\n",
      "[[7.3987035e-06 1.2042380e-05 3.6467743e-05 9.9994409e-01]] [[-4.5399857 -4.0528584 -2.9448621  7.274164 ]] [0.00065239]\n",
      "[[7.1858130e-06 1.1542580e-05 3.5641948e-05 9.9994564e-01]] [[-4.542633  -4.0686994 -2.9412184  7.3007145]] [0.00063574]\n",
      "[[6.9434359e-06 1.1036523e-05 3.5024827e-05 9.9994695e-01]] [[-4.5457134 -4.0822997 -2.9274528  7.331948 ]] [0.00062083]\n",
      "[[6.7453539e-06 1.0533968e-05 3.4626224e-05 9.9994814e-01]] [[-4.5433035 -4.097553  -2.9075463  7.363301 ]] [0.00060854]\n",
      "[[6.6482344e-06 1.0125212e-05 3.4277164e-05 9.9994898e-01]] [[-4.534649  -4.113971  -2.8945205  7.3864594]] [0.00059912]\n",
      "[[6.5805234e-06 9.7719521e-06 3.3922919e-05 9.9994969e-01]] [[-4.525883  -4.1304817 -2.8859065  7.4054627]] [0.00059066]\n",
      "[[6.4682254e-06 9.3185363e-06 3.3159959e-05 9.9995100e-01]] [[-4.516901  -4.151798  -2.8824594  7.4316587]] [0.00057624]\n",
      "[[6.3598682e-06 8.9847326e-06 3.2498818e-05 9.9995220e-01]] [[-4.510595  -4.165076  -2.8793983  7.45486  ]] [0.00056416]\n",
      "[[6.2577178e-06 8.6303971e-06 3.1740783e-05 9.9995339e-01]] [[-4.50149   -4.180015  -2.8777034  7.4801583]] [0.00055099]\n",
      "[[5.9743097e-06 8.0070540e-06 3.0061998e-05 9.9995601e-01]] [[-4.4986234 -4.205769  -2.8828309  7.529374 ]] [0.00052282]\n",
      "[[5.7466727e-06 7.4240984e-06 2.8501576e-05 9.9995828e-01]] [[-4.4893775 -4.233268  -2.888039   7.5774703]] [0.00049704]\n",
      "[[5.7184952e-06 7.2312891e-06 2.7952330e-05 9.9995911e-01]] [[-4.475964  -4.241252  -2.8891685  7.5958004]] [0.0004886]\n",
      "[[5.7420843e-06 7.1256550e-06 2.7522079e-05 9.9995959e-01]] [[-4.4582806 -4.2424    -2.8911135  7.609368 ]] [0.00048315]\n",
      "[[5.4361071e-06 6.5077320e-06 2.5547124e-05 9.9996245e-01]] [[-4.4481807 -4.2682524 -2.900719   7.6742296]] [0.00045133]\n",
      "[[5.3735948e-06 6.1177534e-06 2.3978211e-05 9.9996448e-01]] [[-4.416271  -4.286573  -2.9206226  7.7177067]] [0.00042926]\n",
      "[[5.3548802e-06 5.7647385e-06 2.2694381e-05 9.9996614e-01]] [[-4.3810987 -4.3073473 -2.9369898  7.756369 ]] [0.00041107]\n",
      "[[5.4505626e-06 5.6333402e-06 2.2067623e-05 9.9996686e-01]] [[-4.3443723 -4.311389  -2.9459798  7.775386 ]] [0.00040388]\n",
      "[[5.4047564e-06 5.5878313e-06 2.1535707e-05 9.9996746e-01]] [[-4.334912  -4.3016005 -2.9524796  7.7932863]] [0.0003971]\n",
      "[[5.4576185e-06 5.6615222e-06 2.1372802e-05 9.9996746e-01]] [[-4.3196964 -4.2830157 -2.9545894  7.7987695]] [0.00039691]\n",
      "[[5.134502e-06 5.566193e-06 2.025389e-05 9.999690e-01]] [[-4.333429  -4.252701  -2.9610648  7.8460674]] [0.00037976]\n",
      "[[4.6560558e-06 5.4143320e-06 1.8532093e-05 9.9997139e-01]] [[-4.3588533 -4.2079725 -2.9775186  7.9184594]] [0.00035336]\n",
      "[[4.3487876e-06 5.2634737e-06 1.7090906e-05 9.9997330e-01]] [[-4.374766  -4.1838713 -3.0061157  7.9708214]] [0.00033197]\n",
      "[[4.0567988e-06 5.0792023e-06 1.5764472e-05 9.9997509e-01]] [[-4.388362  -4.163602  -3.0309973  8.02673  ]] [0.00031152]\n",
      "[[3.5802154e-06 4.6205673e-06 1.3648495e-05 9.9997818e-01]] [[-4.417017 -4.161922 -3.078811  8.123049]] [0.00027636]\n",
      "[[3.2288906e-06 4.1978747e-06 1.1950492e-05 9.9998057e-01]] [[-4.4392095 -4.1767693 -3.1305752  8.204144 ]] [0.00024768]\n",
      "[[3.0226463e-06 3.9168694e-06 1.0881147e-05 9.9998224e-01]] [[-4.448782  -4.189622  -3.1678827  8.260578 ]] [0.0002293]\n",
      "[[2.7460467e-06 3.5692617e-06 9.7484672e-06 9.9998391e-01]] [[-4.4699655 -4.2077684 -3.2030175  8.335367 ]] [0.00020851]\n",
      "[[2.3722146e-06 3.1649697e-06 8.5045567e-06 9.9998593e-01]] [[-4.5096893 -4.2213693 -3.2329116  8.441983 ]] [0.00018416]\n",
      "[[2.0932321e-06 2.8341203e-06 7.4777304e-06 9.9998760e-01]] [[-4.5384665 -4.235444  -3.2652462  8.538322 ]] [0.00016424]\n",
      "[[1.8493251e-06 2.5534928e-06 6.5933023e-06 9.9998903e-01]] [[-4.565505  -4.2428637 -3.294271   8.635174 ]] [0.00014692]\n",
      "[[1.5289012e-06 2.1839326e-06 5.4863754e-06 9.9999082e-01]] [[-4.6142187 -4.2576413 -3.3364997  8.776733 ]] [0.00012458]\n",
      "[[1.2456883e-06 1.8787819e-06 4.5628435e-06 9.9999237e-01]] [[-4.671981  -4.261046  -3.3737228  8.923834 ]] [0.00010545]\n",
      "[[9.9789270e-07 1.6342660e-06 3.7994889e-06 9.9999356e-01]] [[-4.7424273 -4.249123  -3.4054506  9.075187 ]] [8.942133e-05]\n",
      "[[7.9417731e-07 1.4301205e-06 3.1789093e-06 9.9999464e-01]] [[-4.8168697 -4.228663  -3.4298832  9.229084 ]] [7.6007316e-05]\n",
      "[[6.3097491e-07 1.2555521e-06 2.6557004e-06 9.9999547e-01]] [[-4.892431  -4.2043657 -3.4552324  9.383565 ]] [6.469412e-05]\n",
      "[[4.986806e-07 1.102533e-06 2.203230e-06 9.999962e-01]] [[-4.9706917 -4.177292  -3.484978   9.540605 ]] [5.487399e-05]\n",
      "[[3.8755653e-07 9.4066507e-07 1.7784739e-06 9.9999690e-01]] [[-5.0536075 -4.1668825 -3.529959   9.709793 ]] [4.5420955e-05]\n",
      "[[3.0538826e-07 7.9814680e-07 1.4316064e-06 9.9999750e-01]] [[-5.128352  -4.1676435 -3.5833836  9.873327 ]] [3.7556205e-05]\n",
      "[[2.3751326e-07 6.7037189e-07 1.1392127e-06 9.9999797e-01]] [[-5.2081785 -4.17057   -3.6403096 10.044862 ]] [3.0769304e-05]\n",
      "[[1.8839289e-07 5.7614807e-07 9.2598822e-07 9.9999833e-01]] [[-5.280328  -4.1624923 -3.6879957 10.204407 ]] [2.5727808e-05]\n",
      "[[1.419895e-07 4.713875e-07 7.159867e-07 9.999987e-01]] [[-5.3722973 -4.17237   -3.7543883 10.395214 ]] [2.0548028e-05]\n",
      "[[1.0990847e-07 3.9978573e-07 5.7291021e-07 9.9999893e-01]] [[-5.4555683 -4.1642866 -3.8044868 10.568049 ]] [1.6957965e-05]\n",
      "[[8.3552756e-08 3.3291664e-07 4.4984122e-07 9.9999917e-01]] [[-5.547656  -4.1652427 -3.8642411 10.75013  ]] [1.3735913e-05]\n",
      "[[6.1896280e-08 2.7003696e-07 3.4366875e-07 9.9999928e-01]] [[-5.65068   -4.1775813 -3.9364624 10.9471245]] [1.0941852e-05]\n",
      "[[4.7196654e-08 2.2649317e-07 2.7113086e-07 9.9999940e-01]] [[-5.745833  -4.1774416 -3.9975545 11.123109 ]] [8.957353e-06]\n",
      "[[3.5773940e-08 1.9031232e-07 2.1352156e-07 9.9999952e-01]] [[-5.8454504 -4.1740026 -4.058932  11.300596 ]] [7.314816e-06]\n",
      "[[2.6709969e-08 1.5772241e-07 1.6577000e-07 9.9999964e-01]] [[-5.9510612 -4.1752605 -4.125496  11.487168 ]] [5.8818296e-06]\n",
      "[[2.0160282e-08 1.3243137e-07 1.3015496e-07 9.9999976e-01]] [[-6.0527463 -4.170397  -4.1877356 11.666804 ]] [4.756539e-06]\n",
      "[[1.49446624e-08 1.09234776e-07 1.00378948e-07 9.99999762e-01]] [[-6.1614757 -4.17233   -4.256877  11.857436 ]] [3.876251e-06]\n",
      "[[1.1272113e-08 9.1892318e-08 7.8789533e-08 9.9999976e-01]] [[-6.2638288 -4.1655426 -4.3193803 12.037105 ]] [3.2223275e-06]\n",
      "[[8.3909075e-09 7.6241015e-08 6.0992519e-08 9.9999988e-01]] [[-6.3713446 -4.1645937 -4.3877416 12.224772 ]] [2.5380286e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6533321e-05 1.1254563e-04 2.7016376e-04 9.9957079e-01]] [[-3.856328  -2.9731379 -2.0974681  6.1185846]] [0.00413638]\n",
      "[[4.9053349e-05 1.0918181e-04 2.6740201e-04 9.9957436e-01]] [[-3.8111904 -3.0110848 -2.1153462  6.1109858]] [0.00410814]\n",
      "[[5.06041251e-05 1.06344014e-04 2.63478229e-04 9.99579608e-01]] [[-3.7795432 -3.0368974 -2.1296062  6.1115136]] [0.00406524]\n",
      "[[5.19160822e-05 1.03988685e-04 2.57972599e-04 9.99586165e-01]] [[-3.7485402 -3.053887  -2.1453156  6.116928 ]] [0.00401119]\n",
      "[[5.1797208e-05 1.0096229e-04 2.5128687e-04 9.9959594e-01]] [[-3.7372699 -3.0698593 -2.1580112  6.1305003]] [0.00392695]\n",
      "[[5.1002695e-05 9.5160714e-05 2.4325482e-04 9.9961060e-01]] [[-3.7225618 -3.0988727 -2.1603308  6.160681 ]] [0.00379882]\n",
      "[[4.9593371e-05 9.0847556e-05 2.3689569e-04 9.9962258e-01]] [[-3.7257495 -3.1204233 -2.1619873  6.1855264]] [0.00369193]\n",
      "[[4.8300346e-05 8.6631415e-05 2.3077709e-04 9.9963427e-01]] [[-3.7268317 -3.1426084 -2.1628182  6.210874 ]] [0.00358856]\n",
      "[[4.7231213e-05 8.2177248e-05 2.2502216e-04 9.9964559e-01]] [[-3.7214973 -3.167674  -2.1603534  6.2386036]] [0.00348783]\n",
      "[[4.6246139e-05 7.7730154e-05 2.2071724e-04 9.9965537e-01]] [[-3.7159069 -3.1966417 -2.1530025  6.2652807]] [0.00339982]\n",
      "[[4.5557976e-05 7.2893206e-05 2.1434929e-04 9.9966717e-01]] [[-3.7035668 -3.2335572 -2.1549456  6.292625 ]] [0.00329342]\n",
      "[[4.5525579e-05 7.0677954e-05 2.1177612e-04 9.9967206e-01]] [[-3.691342  -3.2514827 -2.1540864  6.3055663]] [0.00325014]\n",
      "[[4.5767203e-05 6.7990070e-05 2.0901015e-04 9.9967730e-01]] [[-3.671362  -3.275568  -2.1525474  6.320258 ]] [0.00320336]\n",
      "[[4.6311379e-05 6.5125161e-05 2.0643786e-04 9.9968219e-01]] [[-3.644276  -3.3033526 -2.1496644  6.335529 ]] [0.00315944]\n",
      "[[4.5773646e-05 6.2783023e-05 2.0496179e-04 9.9968648e-01]] [[-3.639713  -3.323737  -2.1405978  6.3517756]] [0.00311899]\n",
      "[[4.5128199e-05 6.1273284e-05 2.0435358e-04 9.9968922e-01]] [[-3.6394894 -3.3336525 -2.1291447  6.3662033]] [0.00309276]\n",
      "[[4.3903605e-05 5.9284081e-05 2.0212805e-04 9.9969471e-01]] [[-3.643918  -3.343574  -2.1170125  6.389291 ]] [0.0030422]\n",
      "[[4.3046875e-05 5.7188015e-05 1.9940488e-04 9.9970043e-01]] [[-3.6444948 -3.36044   -2.1114473  6.4084263]] [0.00298993]\n",
      "[[4.1943669e-05 5.4721397e-05 1.9551069e-04 9.9970776e-01]] [[-3.6473975 -3.3814707 -2.1081102  6.4314933]] [0.00292159]\n",
      "[[4.1293064e-05 5.3053009e-05 1.9329590e-04 9.9971229e-01]] [[-3.6458213 -3.3952246 -2.1022935  6.4487066]] [0.00287971]\n",
      "[[4.0555824e-05 5.1524348e-05 1.9025353e-04 9.9971765e-01]] [[-3.645337  -3.4059618 -2.0996592  6.4672117]] [0.0028311]\n",
      "[[3.9338567e-05 4.9384598e-05 1.8520524e-04 9.9972600e-01]] [[-3.6488214 -3.4213877 -2.099562   6.49421  ]] [0.00275434]\n",
      "[[3.8174210e-05 4.7443144e-05 1.7862866e-04 9.9973577e-01]] [[-3.6538765 -3.4365046 -2.1107275  6.51921  ]] [0.0026665]\n",
      "[[3.7346970e-05 4.5883920e-05 1.7303682e-04 9.9974376e-01]] [[-3.656686  -3.4508238 -2.1234338  6.5383162]] [0.00259417]\n",
      "[[3.5453031e-05 4.2829004e-05 1.6366494e-04 9.9975806e-01]] [[-3.6714308 -3.482424  -2.1418183  6.5756288]] [0.00246277]\n",
      "[[3.3279299e-05 3.9327573e-05 1.5293522e-04 9.9977452e-01]] [[-3.686196  -3.5192053 -2.1611176  6.6241536]] [0.00231112]\n",
      "[[3.0817133e-05 3.5488847e-05 1.3964759e-04 9.9979407e-01]] [[-3.7066455 -3.5654979 -2.1955936  6.6805887]] [0.00212922]\n",
      "[[2.8064540e-05 3.2290660e-05 1.2745008e-04 9.9981219e-01]] [[-3.73758   -3.5973089 -2.2243624  6.743236 ]] [0.0019588]\n",
      "[[2.5797803e-05 2.9823919e-05 1.1743463e-04 9.9982697e-01]] [[-3.7648385 -3.6198175 -2.249246   6.8002095]] [0.00181909]\n",
      "[[2.35667376e-05 2.72111938e-05 1.05814186e-04 9.99843359e-01]] [[-3.7922897 -3.648498  -2.2904425  6.8632274]] [0.00166239]\n",
      "[[2.158750e-05 2.520484e-05 9.645716e-05 9.998567e-01]] [[-3.8180044 -3.663083  -2.32102    6.9252486]] [0.00153397]\n",
      "[[1.8735720e-05 2.2784143e-05 8.4640451e-05 9.9987388e-01]] [[-3.8667486 -3.6711164 -2.3587687  7.0182037]] [0.00136729]\n",
      "[[1.6212593e-05 2.0368414e-05 7.4195130e-05 9.9988925e-01]] [[-3.9116716 -3.6834738 -2.3907604  7.1179404]] [0.00121508]\n",
      "[[1.4505757e-05 1.8685183e-05 6.8346584e-05 9.9989843e-01]] [[-3.9422598 -3.689075  -2.3922143  7.198603 ]] [0.00112212]\n",
      "[[1.2819554e-05 1.6985110e-05 6.1901432e-05 9.9990833e-01]] [[-3.9765804 -3.6952143 -2.4020083  7.287867 ]] [0.00102245]\n",
      "[[1.1287556e-05 1.5372347e-05 5.5637451e-05 9.9991775e-01]] [[-4.0104604 -3.7015903 -2.415304   7.3812675]] [0.00092627]\n",
      "[[9.8403289e-06 1.3910492e-05 4.9830734e-05 9.9992645e-01]] [[-4.0476027 -3.7014487 -2.4254608  7.4813447]] [0.00083622]\n",
      "[[8.5181764e-06 1.2593539e-05 4.4575012e-05 9.9993432e-01]] [[-4.0876403 -3.6966584 -2.4326684  7.5856028]] [0.00075377]\n",
      "[[7.2337007e-06 1.1184462e-05 3.9049897e-05 9.9994254e-01]] [[-4.13401   -3.698235  -2.44792    7.7026925]] [0.00066698]\n",
      "[[6.2562126e-06 1.0182736e-05 3.5049274e-05 9.9994850e-01]] [[-4.1741767 -3.6870582 -2.4509969  7.8077073]] [0.00060307]\n",
      "[[5.4334159e-06 9.3305653e-06 3.1641994e-05 9.9995363e-01]] [[-4.21243   -3.6717021 -2.4505124  7.9104667]] [0.00054815]\n",
      "[[4.7081649e-06 8.5538559e-06 2.8539434e-05 9.9995816e-01]] [[-4.251192  -3.6541085 -2.449203   8.014978 ]] [0.00049805]\n",
      "[[3.9293332e-06 7.6582928e-06 2.4882132e-05 9.9996352e-01]] [[-4.3031    -3.6357806 -2.4574199  8.143905 ]] [0.00043938]\n",
      "[[3.2322841e-06 6.7260539e-06 2.1356445e-05 9.9996865e-01]] [[-4.3577704 -3.6249702 -2.469606   8.28452  ]] [0.00038199]\n",
      "[[2.6481948e-06 5.7218631e-06 1.7861299e-05 9.9997377e-01]] [[-4.408728  -3.6383114 -2.4999697  8.4328785]] [0.00032458]\n",
      "[[2.1873902e-06 4.7900903e-06 1.4717768e-05 9.9997830e-01]] [[-4.45568   -3.6718402 -2.5493338  8.5771   ]] [0.00027263]\n",
      "[[1.8151603e-06 4.0932937e-06 1.2431193e-05 9.9998164e-01]] [[-4.5009947 -3.6878188 -2.5769596  8.718324 ]] [0.00023355]\n",
      "[[1.4208374e-06 3.3067925e-06 9.8305354e-06 9.9998546e-01]] [[-4.5672665 -3.7225342 -2.63302    8.896983 ]] [0.00018875]\n",
      "[[1.1161185e-06 2.7817316e-06 7.9362144e-06 9.9998820e-01]] [[-4.6398277 -3.7266114 -2.6782482  9.065814 ]] [0.00015589]\n",
      "[[8.5424807e-07 2.2787424e-06 6.1928108e-06 9.9999070e-01]] [[-4.7221975 -3.7410405 -2.741275   9.250837 ]] [0.0001251]\n",
      "[[6.5837844e-07 1.8858209e-06 4.8746501e-06 9.9999261e-01]] [[-4.8015685 -3.7492294 -2.7995448  9.4319105]] [0.00010124]\n",
      "[[5.1772088e-07 1.5937043e-06 3.9193928e-06 9.9999392e-01]] [[-4.873397  -3.7490165 -2.8491414  9.600427 ]] [8.364291e-05]\n",
      "[[4.0774506e-07 1.3490414e-06 3.1597874e-06 9.9999511e-01]] [[-4.9455643 -3.7490573 -2.897946   9.767055 ]] [6.9139096e-05]\n",
      "[[3.0815048e-07 1.1029800e-06 2.4523995e-06 9.9999619e-01]] [[-5.0340834 -3.7589011 -2.9598496  9.9585905]] [5.5245997e-05]\n",
      "[[2.3054960e-07 8.9201063e-07 1.8935477e-06 9.9999702e-01]] [[-5.127522  -3.7745109 -3.0217805 10.155274 ]] [4.3880576e-05]\n",
      "[[1.7116702e-07 7.1694734e-07 1.4504186e-06 9.9999762e-01]] [[-5.223429  -3.7910662 -3.086461  10.357195 ]] [3.4693567e-05]\n",
      "[[1.2756506e-07 5.7902554e-07 1.1120021e-06 9.9999821e-01]] [[-5.317599  -3.8048778 -3.1523073 10.557039 ]] [2.737393e-05]\n",
      "[[9.1653810e-08 4.5188423e-07 8.2403125e-07 9.9999869e-01]] [[-5.426496  -3.8310878 -3.230306  10.77875  ]] [2.0942432e-05]\n",
      "[[6.4877980e-08 3.4729382e-07 6.0310720e-07 9.9999893e-01]] [[-5.539216  -3.8615534 -3.3096292 11.01154  ]] [1.5949197e-05]\n",
      "[[4.5594039e-08 2.6515917e-07 4.3733289e-07 9.9999928e-01]] [[-5.6539226 -3.8933697 -3.3930056 11.249565 ]] [1.190492e-05]\n",
      "[[3.2333485e-08 2.0397073e-07 3.2017448e-07 9.9999940e-01]] [[-5.76463   -3.9227571 -3.4718673 11.482532 ]] [9.083953e-06]\n",
      "[[2.2807235e-08 1.5577270e-07 2.3053744e-07 9.9999964e-01]] [[-5.8769507 -3.9556303 -3.5636148 11.719237 ]] [6.7239343e-06]\n",
      "[[1.6104048e-08 1.2010062e-07 1.6702013e-07 9.9999964e-01]] [[-5.9931564 -3.983897  -3.6541126 11.951038 ]] [5.166772e-06]\n",
      "[[1.1344887e-08 9.2022987e-08 1.2032615e-07 9.9999976e-01]] [[-6.1119184 -4.0186467 -3.7504795 12.18258  ]] [3.8540165e-06]\n",
      "[[7.9518863e-09 6.9959619e-08 8.5827075e-08 9.9999988e-01]] [[-6.2308617 -4.056353  -3.8519366 12.418994 ]] [2.8166064e-06]\n",
      "[[5.5828053e-09 5.3482676e-08 6.1607516e-08 9.9999988e-01]] [[-6.350441  -4.0907755 -3.9493492 12.653133 ]] [2.1436492e-06]\n",
      "[[3.9328891e-09 4.0868855e-08 4.4162974e-08 9.9999988e-01]] [[-6.4674077 -4.1264143 -4.048896  12.886484 ]] [1.6385403e-06]\n",
      "[[2.7680149e-09 3.0914045e-08 3.1248991e-08 9.9999988e-01]] [[-6.5810575 -4.167978  -4.1572013 13.124077 ]] [1.2483433e-06]\n",
      "[[1.9192432e-09 2.2827875e-08 2.1786041e-08 1.0000000e+00]] [[-6.6983643 -4.222312  -4.2690253 13.372972 ]] [8.2453397e-07]\n",
      "[[1.3230338e-09 1.6714104e-08 1.5096566e-08 1.0000000e+00]] [[-6.816956  -4.2806315 -4.382417  13.626382 ]] [5.982179e-07]\n",
      "[[9.07833919e-10 1.22510615e-08 1.05072475e-08 1.00000000e+00]] [[-6.939306  -4.3369994 -4.490546  13.880654 ]] [4.351174e-07]\n",
      "[[6.218073e-10 8.948821e-09 7.281921e-09 1.000000e+00]] [[-7.061446  -4.3947997 -4.600926  14.136945 ]] [3.1546625e-07]\n",
      "[[4.2523035e-10 6.5140640e-09 5.0260325e-09 1.0000000e+00]] [[-7.1832657 -4.4541783 -4.7135096 14.395124 ]] [2.2800198e-07]\n",
      "[[2.5364991e-10 4.7313558e-09 3.4730743e-09 1.0000000e+00]] [[-7.5768995 -4.6508875 -4.9600587 14.518167 ]] [1.6394935e-07]\n",
      "[[3.1873289e-05 8.1105230e-05 2.0608788e-04 9.9968100e-01]] [[-4.0843716 -3.1503925 -2.2178369  6.2690516]] [0.00316206]\n",
      "[[3.2380151e-05 7.9113073e-05 2.0118999e-04 9.9968731e-01]] [[-4.067662  -3.174329  -2.240958   6.2699904]] [0.00310696]\n",
      "[[3.3621276e-05 7.7082608e-05 1.9660284e-04 9.9969268e-01]] [[-4.0315814 -3.2018626 -2.2655547  6.2684627]] [0.00306148]\n",
      "[[3.5071280e-05 7.4634008e-05 1.9144682e-04 9.9969888e-01]] [[-3.989059  -3.2338457 -2.2918313  6.268768 ]] [0.00300904]\n",
      "[[3.6392186e-05 7.2445429e-05 1.8706502e-04 9.9970406e-01]] [[-3.9520862 -3.2636075 -2.3149846  6.268774 ]] [0.00296424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.7341233e-05 7.1306393e-05 1.8386240e-04 9.9970752e-01]] [[-3.9230227 -3.2761352 -2.328934   6.2720966]] [0.00293548]\n",
      "[[3.7189930e-05 6.8864203e-05 1.8006761e-04 9.9971384e-01]] [[-3.9115493 -3.2954502 -2.334255   6.287637 ]] [0.00287797]\n",
      "[[3.6810001e-05 6.5864937e-05 1.7707565e-04 9.9972028e-01]] [[-3.9007332 -3.318897  -2.3299263  6.3087277]] [0.00281939]\n",
      "[[3.6585436e-05 6.3355430e-05 1.7468956e-04 9.9972540e-01]] [[-3.888399  -3.3392885 -2.325039   6.3271866]] [0.00277226]\n",
      "[[3.6421799e-05 6.1130719e-05 1.7275887e-04 9.9972969e-01]] [[-3.8759747 -3.3581278 -2.319245   6.344098 ]] [0.00273235]\n",
      "[[3.6140722e-05 5.9397335e-05 1.7144642e-04 9.9973303e-01]] [[-3.871272  -3.3744433 -2.3144212  6.356551 ]] [0.00270125]\n",
      "[[3.5994432e-05 5.7454134e-05 1.7074688e-04 9.9973577e-01]] [[-3.8606696 -3.3930469 -2.303851   6.371213 ]] [0.00267479]\n",
      "[[3.6218491e-05 5.5916997e-05 1.7100111e-04 9.9973685e-01]] [[-3.8436868 -3.4093883 -2.2915869  6.3819904]] [0.00266424]\n",
      "[[3.6987174e-05 5.4725675e-05 1.7286814e-04 9.9973541e-01]] [[-3.8159425 -3.4241812 -2.2739847  6.388732 ]] [0.00267659]\n",
      "[[3.7379428e-05 5.3957538e-05 1.7444654e-04 9.9973422e-01]] [[-3.7994466 -3.4323702 -2.258949   6.3946776]] [0.0026867]\n",
      "[[3.7489044e-05 5.2282954e-05 1.7453000e-04 9.9973565e-01]] [[-3.7844868 -3.4518652 -2.246439   6.4067106]] [0.00267211]\n",
      "[[3.7766393e-05 5.0339560e-05 1.7443595e-04 9.9973744e-01]] [[-3.7632356 -3.4758642 -2.233098   6.4205923]] [0.0026549]\n",
      "[[3.7687099e-05 4.7878439e-05 1.7306463e-04 9.9974138e-01]] [[-3.7449818 -3.5056343 -2.2206345  6.440952 ]] [0.00261778]\n",
      "[[3.7512924e-05 4.5663652e-05 1.7104016e-04 9.9974579e-01]] [[-3.732579  -3.5359626 -2.2153661  6.4579916]] [0.00257638]\n",
      "[[3.6896370e-05 4.3657023e-05 1.6832816e-04 9.9975115e-01]] [[-3.7289126 -3.5606618 -2.2111104  6.4782357]] [0.00252642]\n",
      "[[3.6112997e-05 4.1679530e-05 1.6514785e-04 9.9975711e-01]] [[-3.7273552 -3.5839984 -2.207167   6.5012593]] [0.00247083]\n",
      "[[3.5336921e-05 3.9791041e-05 1.6174959e-04 9.9976307e-01]] [[-3.723828  -3.6051147 -2.202707   6.526517 ]] [0.00241427]\n",
      "[[3.3781213e-05 3.7508042e-05 1.5479706e-04 9.9977392e-01]] [[-3.7277567 -3.6231055 -2.2055461  6.567623 ]] [0.00231419]\n",
      "[[3.1687552e-05 3.4478780e-05 1.4359859e-04 9.9979025e-01]] [[-3.735716  -3.651296  -2.2246182  6.6236606]] [0.0021629]\n",
      "[[2.9677934e-05 3.2480057e-05 1.3693732e-04 9.9980098e-01]] [[-3.748144  -3.657922  -2.2190244  6.6767635]] [0.00206227]\n",
      "[[2.7493521e-05 3.0353453e-05 1.2904999e-04 9.9981314e-01]] [[-3.7677126 -3.668753  -2.221463   6.7336607]] [0.00194701]\n",
      "[[2.55634914e-05 2.80085278e-05 1.18771415e-04 9.99827623e-01]] [[-3.7871232 -3.695779  -2.2510874  6.78705  ]] [0.00180979]\n",
      "[[2.4032583e-05 2.6197416e-05 1.1110328e-04 9.9983859e-01]] [[-3.802495  -3.7162445 -2.271445   6.833444 ]] [0.00170499]\n",
      "[[2.2418408e-05 2.4307605e-05 1.0273899e-04 9.9985051e-01]] [[-3.8202486 -3.7393425 -2.2979398  6.8852296]] [0.00159123]\n",
      "[[2.0805670e-05 2.2601405e-05 9.4034316e-05 9.9986255e-01]] [[-3.8382127 -3.7554264 -2.3297782  6.9419346]] [0.00147538]\n",
      "[[1.8594443e-05 2.0654612e-05 8.3738101e-05 9.9987698e-01]] [[-3.87191   -3.7668338 -2.3670785  7.0206146]] [0.00133449]\n",
      "[[1.6243184e-05 1.8640085e-05 7.3246905e-05 9.9989188e-01]] [[-3.9099364 -3.7722952 -2.4037735  7.1177926]] [0.00118767]\n",
      "[[1.4189228e-05 1.6837032e-05 6.4105559e-05 9.9990487e-01]] [[-3.9476125 -3.776515  -2.4395645  7.2153196]] [0.00105753]\n",
      "[[1.2772456e-05 1.5871978e-05 5.7813897e-05 9.9991357e-01]] [[-3.9756932 -3.7584298 -2.4657555  7.2924395]] [0.00096991]\n",
      "[[1.1778649e-05 1.5149073e-05 5.3959484e-05 9.9991906e-01]] [[-3.998107  -3.7464566 -2.4761615  7.351034 ]] [0.00091301]\n",
      "[[1.0759960e-05 1.4216036e-05 4.9870843e-05 9.9992514e-01]] [[-4.0243025 -3.7457643 -2.490698   7.415301 ]] [0.00085064]\n",
      "[[9.8474911e-06 1.3483988e-05 4.6566965e-05 9.9993014e-01]] [[-4.0482593 -3.7339735 -2.4945848  7.4799647]] [0.00079908]\n",
      "[[8.4978783e-06 1.2090424e-05 4.0958719e-05 9.9993849e-01]] [[-4.0915203 -3.738923  -2.5187721  7.584112 ]] [0.00071143]\n",
      "[[7.3612696e-06 1.0935610e-05 3.6366582e-05 9.9994528e-01]] [[-4.1338067 -3.7380137 -2.5363882  7.685417 ]] [0.00063838]\n",
      "[[6.3533798e-06 9.7744332e-06 3.2049014e-05 9.9995184e-01]] [[-4.1735935 -3.7428107 -2.5553143  7.792882 ]] [0.00056859]\n",
      "[[5.4101720e-06 8.6692244e-06 2.7919024e-05 9.9995804e-01]] [[-4.2165804 -3.745082  -2.575553   7.9106073]] [0.00050138]\n",
      "[[4.5440506e-06 7.5441694e-06 2.3796867e-05 9.9996412e-01]] [[-4.2574053 -3.7504494 -2.6016705  8.0442505]] [0.0004341]\n",
      "[[3.7423404e-06 6.4726128e-06 1.9680063e-05 9.9997008e-01]] [[-4.3059893 -3.758121  -2.6460948  8.18978  ]] [0.00036727]\n",
      "[[3.0884839e-06 5.6025206e-06 1.6377251e-05 9.9997497e-01]] [[-4.354254  -3.7587173 -2.6860414  8.333551 ]] [0.00031244]\n",
      "[[2.5771922e-06 4.9179844e-06 1.3807950e-05 9.9997866e-01]] [[-4.398243  -3.7520444 -2.7196987  8.470546 ]] [0.00026913]\n",
      "[[2.1010731e-06 4.2046372e-06 1.1351612e-05 9.9998236e-01]] [[-4.452487  -3.7587469 -2.7655754  8.620558 ]] [0.00022641]\n",
      "[[1.6261461e-06 3.4427944e-06 8.8684837e-06 9.9998605e-01]] [[-4.5331345 -3.7830641 -2.8368437  8.796149 ]] [0.0001821]\n",
      "[[1.2640428e-06 2.8660611e-06 7.0141032e-06 9.9998891e-01]] [[-4.612817  -3.794193  -2.8992095  8.968368 ]] [0.00014807]\n",
      "[[1.0046679e-06 2.4582262e-06 5.7088464e-06 9.9999082e-01]] [[-4.6850705 -3.7902882 -2.9477115  9.125773 ]] [0.00012373]\n",
      "[[8.033408e-07 2.127013e-06 4.686952e-06 9.999924e-01]] [[-4.7565856 -3.782891  -2.9928272  9.277893 ]] [0.0001042]\n",
      "[[6.1643385e-07 1.7559075e-06 3.6648398e-06 9.9999392e-01]] [[-4.8414617 -3.794671  -3.0588725  9.457848 ]] [8.403625e-05]\n",
      "[[4.7720448e-07 1.4592267e-06 2.8887177e-06 9.9999523e-01]] [[-4.9228992 -3.8051822 -3.1222765  9.632417 ]] [6.816746e-05]\n",
      "[[3.5797660e-07 1.1880581e-06 2.2277111e-06 9.9999619e-01]] [[-5.0186105 -3.8190033 -3.1903486  9.824183 ]] [5.4329597e-05]\n",
      "[[2.7378886e-07 9.8890564e-07 1.7587117e-06 9.9999702e-01]] [[-5.108446  -3.824205  -3.2484667 10.00246  ]] [4.409526e-05]\n",
      "[[2.0603588e-07 8.1244343e-07 1.3660148e-06 9.9999762e-01]] [[-5.203972  -3.8319762 -3.312369  10.191241 ]] [3.5395355e-05]\n",
      "[[1.5584882e-07 6.6929493e-07 1.0676511e-06 9.9999809e-01]] [[-5.298017  -3.8406792 -3.3736875 10.37636  ]] [2.8545828e-05]\n",
      "[[1.2108517e-07 5.6673025e-07 8.6048522e-07 9.9999845e-01]] [[-5.3834934 -3.8401043 -3.4224913 10.543277 ]] [2.364705e-05]\n",
      "[[8.7004139e-08 4.4963645e-07 6.4600238e-07 9.9999881e-01]] [[-5.4977818 -3.8552978 -3.492934  10.759527 ]] [1.838503e-05]\n",
      "[[6.2139001e-08 3.5314264e-07 4.8043427e-07 9.9999905e-01]] [[-5.6096754 -3.8721783 -3.5643597 10.984215 ]] [1.4220863e-05]\n",
      "[[4.4517130e-08 2.7844868e-07 3.5864267e-07 9.9999928e-01]] [[-5.7200394 -3.8866794 -3.6335864 11.207352 ]] [1.0994322e-05]\n",
      "[[3.2013286e-08 2.2084912e-07 2.6941555e-07 9.9999952e-01]] [[-5.829042 -3.897713 -3.698937 11.428073]] [8.489433e-06]\n",
      "[[2.3170641e-08 1.7566654e-07 2.0351922e-07 9.9999964e-01]] [[-5.938202  -3.9125009 -3.7653272 11.642178 ]] [6.6331363e-06]\n",
      "[[1.6570368e-08 1.3720724e-07 1.5114546e-07 9.9999964e-01]] [[-6.055725  -3.9418485 -3.845098  11.859924 ]] [5.196357e-06]\n",
      "[[1.18788899e-08 1.07786029e-07 1.11371186e-07 9.99999762e-01]] [[-6.1716166 -3.9662316 -3.9335115 12.076886 ]] [3.9675115e-06]\n",
      "[[8.4016536e-09 8.2844124e-08 7.9592198e-08 9.9999988e-01]] [[-6.2877126 -3.999179  -4.0392246 12.307125 ]] [2.9273601e-06]\n",
      "[[6.0029253e-09 6.4585677e-08 5.7625527e-08 9.9999988e-01]] [[-6.4013615 -4.025615  -4.1396413 12.529658 ]] [2.2626614e-06]\n",
      "[[4.2517132e-09 4.9696968e-08 4.1267242e-08 9.9999988e-01]] [[-6.5171194 -4.058499  -4.2443743 12.758823 ]] [1.7386101e-06]\n",
      "[[1.8345012e-09 2.1958922e-08 2.0269598e-08 1.0000000e+00]] [[-6.985066  -4.502666  -4.5827165 13.131427 ]] [7.8318794e-07]\n",
      "[[1.8652492e-05 4.1413710e-05 1.0455265e-04 9.9983537e-01]] [[-4.1664743 -3.3688426 -2.4427636  6.7228913]] [0.00174399]\n",
      "[[1.8100221e-05 3.9146842e-05 9.8400422e-05 9.9984431e-01]] [[-4.1716285 -3.400233  -2.4785075  6.7478023]] [0.00165848]\n",
      "[[1.7638356e-05 3.6618658e-05 9.2763286e-05 9.9985301e-01]] [[-4.1716304 -3.4411488 -2.5116558  6.773657 ]] [0.00157544]\n",
      "[[1.7204156e-05 3.4735756e-05 8.8026536e-05 9.9986005e-01]] [[-4.1779604 -3.4753416 -2.5454733  6.792259 ]] [0.00150732]\n",
      "[[1.6795455e-05 3.2984786e-05 8.4042484e-05 9.9986613e-01]] [[-4.1859384 -3.5109992 -2.5757241  6.8083305]] [0.00144757]\n",
      "[[1.611561e-05 3.112951e-05 8.004803e-05 9.998727e-01]] [[-4.205644  -3.5472753 -2.6028054  6.8299513]] [0.00138328]\n",
      "[[1.5414993e-05 2.9020939e-05 7.6073047e-05 9.9987948e-01]] [[-4.2213635 -3.5886865 -2.625011   6.8586855]] [0.00131597]\n",
      "[[1.4764121e-05 2.7327331e-05 7.2763854e-05 9.9988508e-01]] [[-4.23892   -3.6232328 -2.643901   6.8842754]] [0.0012596]\n",
      "[[1.4361516e-05 2.5768199e-05 6.9898488e-05 9.9988997e-01]] [[-4.2438526 -3.6592636 -2.6613612  6.9069953]] [0.00121127]\n",
      "[[1.4022211e-05 2.4085626e-05 6.7099667e-05 9.9989474e-01]] [[-4.2426972 -3.7017243 -2.6771607  6.9320655]] [0.00116286]\n",
      "[[1.3505123e-05 2.2427063e-05 6.4170810e-05 9.9989986e-01]] [[-4.248218  -3.741019  -2.689739   6.9641232]] [0.00111115]\n",
      "[[1.2776672e-05 2.1255953e-05 6.1908839e-05 9.9990404e-01]] [[-4.26704   -3.7580245 -2.688998   7.0007534]] [0.0010685]\n",
      "[[1.2370457e-05 2.0534062e-05 6.0401508e-05 9.9990666e-01]] [[-4.2763915 -3.7696183 -2.6906893  7.023714 ]] [0.00104153]\n",
      "[[1.1988875e-05 1.9483356e-05 5.8944494e-05 9.9990952e-01]] [[-4.2768807 -3.7912996 -2.6842635  7.05456  ]] [0.0010117]\n",
      "[[1.1685166e-05 1.8610443e-05 5.7720870e-05 9.9991202e-01]] [[-4.275323  -3.80992   -2.678024   7.0817795]] [0.00098673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1422811e-05 1.7828173e-05 5.6732537e-05 9.9991405e-01]] [[-4.271473  -3.8263044 -2.6687365  7.10834  ]] [0.00096557]\n",
      "[[1.1099445e-05 1.6985625e-05 5.5209999e-05 9.9991667e-01]] [[-4.269976  -3.8445036 -2.6657276  7.138556 ]] [0.00093781]\n",
      "[[1.0738885e-05 1.6067961e-05 5.3620686e-05 9.9991953e-01]] [[-4.2675996 -3.864644  -2.6595366  7.173959 ]] [0.00090799]\n",
      "[[1.0421979e-05 1.5288741e-05 5.2242900e-05 9.9992204e-01]] [[-4.2646594 -3.8814592 -2.6526723  7.2068563]] [0.00088214]\n",
      "[[1.00685038e-05 1.45223075e-05 5.05580138e-05 9.99924898e-01]] [[-4.2653866 -3.8991132 -2.651677   7.240637 ]] [0.00085286]\n",
      "[[9.7868960e-06 1.3944332e-05 4.9119448e-05 9.9992716e-01]] [[-4.2651443 -3.9111161 -2.6519332  7.269249 ]] [0.00082895]\n",
      "[[9.3578274e-06 1.3281927e-05 4.7314315e-05 9.9993002e-01]] [[-4.2734356 -3.9232445 -2.652836   7.3057914]] [0.00079866]\n",
      "[[8.9409159e-06 1.2650653e-05 4.5405246e-05 9.9993300e-01]] [[-4.2827873 -3.9357166 -2.6577976  7.3420186]] [0.00076765]\n",
      "[[8.6359732e-06 1.2115655e-05 4.3684275e-05 9.9993551e-01]] [[-4.2871256 -3.9485638 -2.6660745  7.3723836]] [0.00074087]\n",
      "[[8.3097275e-06 1.1658544e-05 4.1938332e-05 9.9993813e-01]] [[-4.2929487 -3.9543366 -2.6741757  7.405073 ]] [0.00071422]\n",
      "[[8.2870947e-06 1.1507774e-05 4.0955081e-05 9.9993920e-01]] [[-4.282878  -3.9545546 -2.6851022  7.417872 ]] [0.0007024]\n",
      "[[7.8478606e-06 1.0748361e-05 3.8121150e-05 9.9994326e-01]] [[-4.2910666 -3.9765544 -2.710539   7.4641457]] [0.00065984]\n",
      "[[7.5060798e-06 1.0119625e-05 3.5883895e-05 9.9994648e-01]] [[-4.293329  -3.9945662 -2.7287538  7.5064144]] [0.00062576]\n",
      "[[7.1715749e-06 9.5294681e-06 3.3613698e-05 9.9994969e-01]] [[-4.297522  -4.0132585 -2.7527134  7.547813 ]] [0.00059167]\n",
      "[[6.8760887e-06 9.0637041e-06 3.1614778e-05 9.9995244e-01]] [[-4.302927  -4.0266995 -2.777353   7.5844855]] [0.00056213]\n",
      "[[6.5106783e-06 8.5032189e-06 2.9521998e-05 9.9995542e-01]] [[-4.313306  -4.046305  -2.8016145  7.628716 ]] [0.00052954]\n",
      "[[6.1319051e-06 7.9354559e-06 2.7411117e-05 9.9995852e-01]] [[-4.3255816 -4.067746  -2.8281388  7.676382 ]] [0.00049622]\n",
      "[[5.7632346e-06 7.3714227e-06 2.5158279e-05 9.9996173e-01]] [[-4.340157  -4.0940447 -2.8664687  7.7238164]] [0.00046134]\n",
      "[[5.1612651e-06 6.6470643e-06 2.2483579e-05 9.9996567e-01]] [[-4.3749275 -4.1219344 -2.9033244  7.799367 ]] [0.00041704]\n",
      "[[4.8191273e-06 6.2571939e-06 2.1041658e-05 9.9996793e-01]] [[-4.39126   -4.130121  -2.9173484  7.851626 ]] [0.00039264]\n",
      "[[4.3891869e-06 5.8372684e-06 1.9320398e-05 9.9997044e-01]] [[-4.4182243 -4.1331053 -2.9362066  7.9181128]] [0.00036377]\n",
      "[[3.9158972e-06 5.3178801e-06 1.7293261e-05 9.9997342e-01]] [[-4.450776  -4.1447453 -2.9655037  7.9996634]] [0.00032954]\n",
      "[[3.6457727e-06 5.0712497e-06 1.6156795e-05 9.9997509e-01]] [[-4.463445 -4.133425 -2.974672  8.058473]] [0.00031066]\n",
      "[[3.3646345e-06 4.8009319e-06 1.4970333e-05 9.9997687e-01]] [[-4.4793205 -4.12383   -2.986569   8.122848 ]] [0.00029064]\n",
      "[[2.9612534e-06 4.3471478e-06 1.3217760e-05 9.9997950e-01]] [[-4.514209  -4.130302  -3.0182602  8.215669 ]] [0.00026036]\n",
      "[[2.5940346e-06 3.9257275e-06 1.1619726e-05 9.9998188e-01]] [[-4.550134  -4.1357965 -3.050644   8.312144 ]] [0.00023238]\n",
      "[[2.3330381e-06 3.6337099e-06 1.0483299e-05 9.9998355e-01]] [[-4.5745573 -4.131474  -3.0719452  8.393765 ]] [0.00021242]\n",
      "[[2.1763758e-06 3.4649770e-06 9.7937982e-06 9.9998462e-01]] [[-4.5838137 -4.1187687 -3.079725   8.4540205]] [0.00020028]\n",
      "[[1.8956416e-06 3.1022551e-06 8.6134969e-06 9.9998641e-01]] [[-4.621403 -4.128832 -3.107631  8.554536]] [0.00017837]\n",
      "[[1.7091875e-06 2.9180758e-06 7.9487218e-06 9.9998748e-01]] [[-4.643183  -4.108278  -3.1061904  8.636296 ]] [0.00016574]\n",
      "[[1.3777735e-06 2.4832561e-06 6.5650902e-06 9.9998963e-01]] [[-4.704307  -4.115205  -3.1430094  8.790725 ]] [0.00013936]\n",
      "[[1.0991777e-06 2.0906505e-06 5.3877179e-06 9.9999142e-01]] [[-4.766558 -4.123646 -3.176999  8.954381]] [0.00011637]\n",
      "[[8.7887469e-07 1.7654581e-06 4.4536337e-06 9.9999285e-01]] [[-4.8269496 -4.129427  -3.2041166  9.117666 ]] [9.767205e-05]\n",
      "[[7.0391241e-07 1.5035999e-06 3.7198133e-06 9.9999404e-01]] [[-4.8854647 -4.1265016 -3.22069    9.281141 ]] [8.259674e-05]\n",
      "[[5.5839234e-07 1.2671754e-06 3.0552283e-06 9.9999511e-01]] [[-4.9518433 -4.1323595 -3.2522955  9.446356 ]] [6.893133e-05]\n",
      "[[4.6088124e-07 1.1139715e-06 2.6257355e-06 9.9999583e-01]] [[-5.0064373 -4.1238914 -3.2664614  9.583684 ]] [5.990758e-05]\n",
      "[[3.6659418e-07 9.5043958e-07 2.1709209e-06 9.9999654e-01]] [[-5.0759287 -4.1232595 -3.2972772  9.743078 ]] [5.0378334e-05]\n",
      "[[2.8856519e-07 8.0385968e-07 1.7747062e-06 9.9999714e-01]] [[-5.149227  -4.1247234 -3.3327582  9.909115 ]] [4.1988013e-05]\n",
      "[[2.2653164e-07 6.8079595e-07 1.4517346e-06 9.9999762e-01]] [[-5.2233157 -4.1229377 -3.365685  10.077064 ]] [3.5032816e-05]\n",
      "[[1.7615797e-07 5.6800212e-07 1.1670051e-06 9.9999809e-01]] [[-5.2979145 -4.1271706 -3.4070995 10.253968 ]] [2.8757991e-05]\n",
      "[[1.3529750e-07 4.6341495e-07 9.1597735e-07 9.9999845e-01]] [[-5.374808  -4.1436605 -3.4622912 10.440981 ]] [2.3183382e-05]\n",
      "[[1.0533567e-07 3.8146689e-07 7.3085243e-07 9.9999881e-01]] [[-5.445767  -4.1588945 -3.5087073 10.620346 ]] [1.8848474e-05]\n",
      "[[8.2225853e-08 3.1280470e-07 5.8547772e-07 9.9999905e-01]] [[-5.5145555 -4.1784463 -3.5515978 10.799239 ]] [1.5382277e-05]\n",
      "[[6.1565665e-08 2.4979911e-07 4.5196211e-07 9.9999928e-01]] [[-5.6028666 -4.202314  -3.6093721 11.000295 ]] [1.2138054e-05]\n",
      "[[4.6497473e-08 2.0120106e-07 3.5271597e-07 9.9999940e-01]] [[-5.687316 -4.222409 -3.661051 11.196551]] [9.723929e-06]\n",
      "[[3.5162461e-08 1.6228395e-07 2.7558264e-07 9.9999952e-01]] [[-5.770681  -4.241312  -3.7117715 11.392606 ]] [7.779979e-06]\n",
      "[[2.7164559e-08 1.3356080e-07 2.2004436e-07 9.9999964e-01]] [[-5.8453693 -4.2527246 -3.7534525 11.575984 ]] [6.3181224e-06]\n",
      "[[2.0715509e-08 1.0904576e-07 1.7173835e-07 9.9999964e-01]] [[-5.925743  -4.2648582 -3.8106532 11.76664  ]] [5.14752e-06]\n",
      "[[1.5762236e-08 8.8765759e-08 1.3344166e-07 9.9999976e-01]] [[-6.0061164 -4.277733  -3.87007   11.959532 ]] [4.075239e-06]\n",
      "[[1.19134240e-08 7.17459443e-08 1.02737026e-07 9.99999762e-01]] [[-6.088161  -4.2926946 -3.9336534 12.157439 ]] [3.2891676e-06]\n",
      "[[8.9550865e-09 5.7496305e-08 7.7843708e-08 9.9999988e-01]] [[-6.169574  -4.3100743 -4.007092  12.361471 ]] [2.5178983e-06]\n",
      "[[6.8405610e-09 4.6693994e-08 5.9591336e-08 9.9999988e-01]] [[-6.242559  -4.321814  -4.0779185 12.557837 ]] [2.0273396e-06]\n",
      "[[5.2310831e-09 3.8075292e-08 4.5303057e-08 9.9999988e-01]] [[-6.3153367 -4.3303895 -4.1565804 12.753311 ]] [1.6354957e-06]\n",
      "[[3.9691219e-09 3.1229746e-08 3.4364781e-08 9.9999988e-01]] [[-6.3918104 -4.3289843 -4.2333226 12.95291  ]] [1.3263011e-06]\n",
      "[[2.8894849e-09 2.4156611e-08 2.4754339e-08 1.0000000e+00]] [[-6.4751945 -4.3517146 -4.327272  13.186993 ]] [9.140434e-07]\n",
      "[[2.0407689e-09 1.8036648e-08 1.7429082e-08 1.0000000e+00]] [[-6.57943   -4.4003515 -4.4346166 13.430509 ]] [6.7381734e-07]\n",
      "[[1.4345436e-09 1.3490132e-08 1.2306144e-08 1.0000000e+00]] [[-6.6858363 -4.4447246 -4.5365844 13.676583 ]] [4.9780346e-07]\n",
      "[[1.0100978e-09 1.0043311e-08 8.6359409e-09 1.0000000e+00]] [[-6.790128  -4.4932675 -4.6442432 13.923091 ]] [3.6622998e-07]\n",
      "[[4.1783924e-10 5.6131184e-09 3.8043408e-09 1.0000000e+00]] [[-7.385935 -4.788171 -5.177134 14.209989]] [1.8941776e-07]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-13.543879  -6.67982   -6.383598  19.930708]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-14.317587   -7.797583   -7.5055485  21.911566 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-14.95908   -8.075012  -7.606298  22.191847]] [6.9077553e-09]\n",
      "[[6.260018e-05 1.460105e-04 3.235093e-04 9.994679e-01]] [[-3.652848  -2.805938  -2.0103886  6.025362 ]] [0.00502719]\n",
      "[[6.5249318e-05 1.4388299e-04 3.2120515e-04 9.9946970e-01]] [[-3.6123915 -2.821607  -2.0185275  6.024373 ]] [0.00501544]\n",
      "[[6.6194800e-05 1.3852002e-04 3.1295881e-04 9.9948227e-01]] [[-3.586084  -2.847671  -2.0326142  6.036307 ]] [0.00491066]\n",
      "[[6.6572749e-05 1.2956803e-04 3.0076152e-04 9.9950314e-01]] [[-3.5559127 -2.8900018 -2.0478904  6.060806 ]] [0.00473572]\n",
      "[[6.5104665e-05 1.1664439e-04 2.8297849e-04 9.9953532e-01]] [[-3.5314791 -2.9483447 -2.062104   6.1075706]] [0.0044605]\n",
      "[[6.1668128e-05 1.0610780e-04 2.6862524e-04 9.9956363e-01]] [[-3.536895  -2.9942064 -2.0653448  6.156412 ]] [0.00421375]\n",
      "[[5.8555906e-05 9.8272394e-05 2.5732996e-04 9.9958581e-01]] [[-3.5476868 -3.0299256 -2.0673091  6.1974277]] [0.00401847]\n",
      "[[5.490689e-05 8.860496e-05 2.445629e-04 9.996119e-01]] [[-3.557539  -3.0789895 -2.0637057  6.2519445]] [0.00378724]\n",
      "[[5.2599531e-05 8.0457365e-05 2.3407632e-04 9.9963284e-01]] [[-3.552979  -3.1279583 -2.060039   6.299457 ]] [0.00360073]\n",
      "[[5.0617051e-05 7.6286589e-05 2.2695614e-04 9.9964619e-01]] [[-3.5608294 -3.1506202 -2.0603611  6.330039 ]] [0.00348202]\n",
      "[[4.8340244e-05 7.2732124e-05 2.2014494e-04 9.9965882e-01]] [[-3.5764198 -3.167901  -2.060398   6.360485 ]] [0.00336842]\n",
      "[[4.5997796e-05 6.8996043e-05 2.1352390e-04 9.9967146e-01]] [[-3.592676  -3.1872203 -2.0575209  6.3939123]] [0.0032536]\n",
      "[[4.4176159e-05 6.5986264e-05 2.0898916e-04 9.9968088e-01]] [[-3.6045537 -3.203293  -2.0504572  6.422452 ]] [0.00316804]\n",
      "[[4.2451305e-05 6.3350722e-05 2.0410058e-04 9.9969018e-01]] [[-3.6153321 -3.2150035 -2.0450768  6.451511 ]] [0.00308376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.1022849e-05 6.1485589e-05 1.9987173e-04 9.9969769e-01]] [[-3.6241913 -3.2195177 -2.040645   6.4768877]] [0.00301534]\n",
      "[[3.9354294e-05 5.9000879e-05 1.9461724e-04 9.9970704e-01]] [[-3.6342666 -3.229319  -2.035837   6.5083456]] [0.00292953]\n",
      "[[3.9101993e-05 5.8490943e-05 1.9261090e-04 9.9970978e-01]] [[-3.630749  -3.2280502 -2.0362504  6.518298 ]] [0.00290488]\n",
      "[[3.8552866e-05 5.7281890e-05 1.8958026e-04 9.9971455e-01]] [[-3.6289265 -3.2329721 -2.0361445  6.5342684]] [0.00286157]\n",
      "[[3.7313850e-05 5.4998924e-05 1.8416368e-04 9.9972349e-01]] [[-3.6337004 -3.245751  -2.0372403  6.562169 ]] [0.00278012]\n",
      "[[3.6689438e-05 5.4079032e-05 1.8131448e-04 9.9972790e-01]] [[-3.6330714 -3.2451131 -2.0353265  6.5796785]] [0.00274017]\n",
      "[[3.5340581e-05 5.1460716e-05 1.7526864e-04 9.9973792e-01]] [[-3.639122  -3.2633357 -2.0378344  6.6110945]] [0.0026484]\n",
      "[[3.4046348e-05 4.8685823e-05 1.6833049e-04 9.9974889e-01]] [[-3.6471195 -3.2894547 -2.048913   6.640417 ]] [0.00254752]\n",
      "[[3.2988399e-05 4.6649358e-05 1.6315255e-04 9.9975723e-01]] [[-3.6530907 -3.306588  -2.0545614  6.666021 ]] [0.00247121]\n",
      "[[3.1873165e-05 4.4723369e-05 1.5770741e-04 9.9976569e-01]] [[-3.6604042 -3.3216724 -2.0614264  6.693108 ]] [0.00239288]\n",
      "[[3.1102954e-05 4.3416640e-05 1.5391991e-04 9.9977154e-01]] [[-3.663378  -3.329838  -2.0642478  6.7146015]] [0.00233861]\n",
      "[[2.9389364e-05 4.0556315e-05 1.4585139e-04 9.9978417e-01]] [[-3.6791906 -3.3571315 -2.0772343  6.7554717]] [0.00222091]\n",
      "[[2.8571734e-05 3.9409744e-05 1.4260536e-04 9.9978942e-01]] [[-3.6826327 -3.361038  -2.0749695  6.780249 ]] [0.00217202]\n",
      "[[2.6855923e-05 3.6784968e-05 1.3441940e-04 9.9980193e-01]] [[-3.7012763 -3.386673  -2.0907977  6.82355  ]] [0.00205458]\n",
      "[[2.5803538e-05 3.5407396e-05 1.2894819e-04 9.9980992e-01]] [[-3.7146301 -3.3982208 -2.1057305  6.8501787]] [0.00198042]\n",
      "[[2.4924992e-05 3.3982044e-05 1.2389733e-04 9.9981719e-01]] [[-3.722117  -3.4121556 -2.118534   6.87734  ]] [0.00191124]\n",
      "[[2.3918918e-05 3.2142834e-05 1.1789169e-04 9.9982613e-01]] [[-3.7301502 -3.4346306 -2.1350532  6.9105167]] [0.00182731]\n",
      "[[2.2836333e-05 3.0150946e-05 1.1208206e-04 9.9983490e-01]] [[-3.7382455 -3.4603817 -2.1473672  6.948747 ]] [0.00174253]\n",
      "[[2.1440257e-05 2.7759386e-05 1.0511439e-04 9.9984562e-01]] [[-3.7533498 -3.495046  -2.1635714  6.996736 ]] [0.001639]\n",
      "[[1.9927149e-05 2.5363333e-05 9.8031094e-05 9.9985671e-01]] [[-3.7729104 -3.5316885 -2.1797082  7.050374 ]] [0.00153221]\n",
      "[[1.7803372e-05 2.2751216e-05 8.9802685e-05 9.9986959e-01]] [[-3.8076446 -3.5624132 -2.1894174  7.128348 ]] [0.00140511]\n",
      "[[1.5582169e-05 2.0293039e-05 8.1037491e-05 9.9988306e-01]] [[-3.8484662 -3.584316  -2.1996815  7.2208   ]] [0.00127212]\n",
      "[[1.3810319e-05 1.8574761e-05 7.3934745e-05 9.9989367e-01]] [[-3.8839788 -3.587591  -2.206212   7.3060093]] [0.00116651]\n",
      "[[1.1909018e-05 1.6637940e-05 6.5646622e-05 9.9990582e-01]] [[-3.9284418 -3.5940518 -2.2214522  7.4096785]] [0.00104454]\n",
      "[[1.0224379e-05 1.4899641e-05 5.8301142e-05 9.9991655e-01]] [[-3.972555  -3.5959926 -2.231709   7.518097 ]] [0.00093496]\n",
      "[[8.8928500e-06 1.3526009e-05 5.2585514e-05 9.9992502e-01]] [[-4.0109363 -3.5915694 -2.2337427  7.619252 ]] [0.00084817]\n",
      "[[7.4533677e-06 1.1814615e-05 4.5451226e-05 9.9993527e-01]] [[-4.064263  -3.6035912 -2.2562883  7.7425175]] [0.00074124]\n",
      "[[6.2700988e-06 1.0440387e-05 3.9744060e-05 9.9994349e-01]] [[-4.1157846 -3.6058955 -2.2691169  7.8638773]] [0.0006541]\n",
      "[[5.1644479e-06 9.0521226e-06 3.4005843e-05 9.9995172e-01]] [[-4.1751037 -3.613903  -2.29037    7.99856  ]] [0.00056615]\n",
      "[[4.4225426e-06 8.2114475e-06 3.0599735e-05 9.9995673e-01]] [[-4.217974  -3.599159  -2.2836976  8.110779 ]] [0.00051202]\n",
      "[[3.6294675e-06 7.0235442e-06 2.5825180e-05 9.9996352e-01]] [[-4.2771573 -3.6169755 -2.3148935  8.24923  ]] [0.00043811]\n",
      "[[2.9925029e-06 5.9752338e-06 2.1598999e-05 9.9996948e-01]] [[-4.332943  -3.6414301 -2.3564065  8.386427 ]] [0.00037248]\n",
      "[[2.5586469e-06 5.3306344e-06 1.8989542e-05 9.9997318e-01]] [[-4.374316  -3.6403244 -2.3699067  8.501689 ]] [0.00033094]\n",
      "[[2.1208648e-06 4.6591108e-06 1.6380343e-05 9.9997687e-01]] [[-4.42769   -3.6406887 -2.3834317  8.635974 ]] [0.00028853]\n",
      "[[1.7317965e-06 3.9959823e-06 1.3830590e-05 9.9998045e-01]] [[-4.4855995 -3.6494696 -2.4078758  8.780732 ]] [0.00024694]\n",
      "[[1.4062368e-06 3.4074594e-06 1.1602926e-05 9.9998355e-01]] [[-4.544702  -3.6596522 -2.4343626  8.929874 ]] [0.00021016]\n",
      "[[1.1463421e-06 2.8714760e-06 9.6712893e-06 9.9998629e-01]] [[-4.5960555 -3.677805  -2.463469   9.082866 ]] [0.0001777]\n",
      "[[9.3115972e-07 2.3945324e-06 8.0011778e-06 9.9998868e-01]] [[-4.6453485 -3.700836  -2.494435   9.241475 ]] [0.00014915]\n",
      "[[7.1969021e-07 1.9645436e-06 6.3933617e-06 9.9999094e-01]] [[-4.7215    -3.7173064 -2.5373054  9.4229355]] [0.00012152]\n",
      "[[5.5290121e-07 1.6273329e-06 5.1268926e-06 9.9999273e-01]] [[-4.802763 -3.723245 -2.575688  9.605316]] [9.937874e-05]\n",
      "[[4.1410217e-07 1.3139548e-06 3.9979400e-06 9.9999428e-01]] [[-4.8938413 -3.7391572 -2.6264188  9.803307 ]] [7.929567e-05]\n",
      "[[3.1121459e-07 1.0626343e-06 3.1142526e-06 9.9999547e-01]] [[-4.983361  -3.755338  -2.6800997  9.999417 ]] [6.329632e-05]\n",
      "[[2.3127708e-07 8.5137316e-07 2.3824173e-06 9.9999654e-01]] [[-5.0768466 -3.7736123 -2.744592  10.2028   ]] [4.973614e-05]\n",
      "[[1.7171911e-07 6.8446087e-07 1.8286963e-06 9.9999726e-01]] [[-5.171978 -3.789206 -2.806479 10.405425]] [3.9292987e-05]\n",
      "[[1.2621021e-07 5.4530847e-07 1.3882442e-06 9.9999797e-01]] [[-5.270412  -3.80701   -2.8725657 10.6149025]] [3.0619736e-05]\n",
      "[[9.3536045e-08 4.3771263e-07 1.0613148e-06 9.9999845e-01]] [[-5.364912  -3.8216963 -2.935995  10.820005 ]] [2.40719e-05]\n",
      "[[6.6091367e-08 3.3573249e-07 7.7672956e-07 9.9999881e-01]] [[-5.4773526 -3.8520765 -3.0132987 11.054873 ]] [1.8216644e-05]\n",
      "[[4.6657995e-08 2.5637510e-07 5.6140351e-07 9.9999917e-01]] [[-5.5878954 -3.884098  -3.1002998 11.292525 ]] [1.3593163e-05]\n",
      "[[3.2805975e-08 1.9421658e-07 4.0247255e-07 9.9999940e-01]] [[-5.7009315 -3.9225671 -3.1939144 11.531724 ]] [1.0089526e-05]\n",
      "[[2.3040410e-08 1.4691253e-07 2.8889133e-07 9.9999952e-01]] [[-5.813954  -3.9613655 -3.2851527 11.772062 ]] [7.5433627e-06]\n",
      "[[1.6150311e-08 1.1050131e-07 2.0603767e-07 9.9999964e-01]] [[-5.9286876 -4.005598  -3.3825672 12.012639 ]] [5.5894143e-06]\n",
      "[[1.1335349e-08 8.2933120e-08 1.4663067e-07 9.9999976e-01]] [[-6.0430493 -4.05294   -3.4830577 12.252291 ]] [4.105331e-06]\n",
      "[[7.96641419e-09 6.23005647e-08 1.04556925e-07 9.99999881e-01]] [[-6.156702  -4.0999656 -3.5822046 12.491329 ]] [2.9820137e-06]\n",
      "[[5.5763878e-09 4.6392167e-08 7.3542125e-08 9.9999988e-01]] [[-6.2693477 -4.1507597 -3.6900318 12.735376 ]] [2.216531e-06]\n",
      "[[3.8726835e-09 3.3997992e-08 5.1560200e-08 9.9999988e-01]] [[-6.384008  -4.211655  -3.7952065 12.98531  ]] [1.6440895e-06]\n",
      "[[2.6720357e-09 2.4863358e-08 3.6069252e-08 9.9999988e-01]] [[-6.5027776 -4.272223  -3.9001772 13.237647 ]] [1.2254591e-06]\n",
      "[[1.8328644e-09 1.8201982e-08 2.5196060e-08 1.0000000e+00]] [[-6.625346  -4.3296947 -4.004537  13.492041 ]] [8.0210816e-07]\n",
      "[[1.2645853e-09 1.3254415e-08 1.7445080e-08 1.0000000e+00]] [[-6.741729 -4.392143 -4.117417 13.746792]] [5.7797297e-07]\n",
      "[[8.6659668e-10 9.6260973e-09 1.2067707e-08 1.0000000e+00]] [[-6.861699  -4.4540405 -4.227985  14.004747 ]] [4.1579614e-07]\n",
      "[[5.8867711e-10 6.9680066e-09 8.3313125e-09 1.0000000e+00]] [[-6.986208 -4.515002 -4.336311 14.266934]] [2.9837335e-07]\n",
      "[[3.9727482e-10 5.0320756e-09 5.7450897e-09 1.0000000e+00]] [[-7.1142173 -4.575258  -4.442744  14.532176 ]] [2.1376223e-07]\n",
      "[[2.6897115e-10 3.6184447e-09 3.9366199e-09 1.0000000e+00]] [[-7.2384577 -4.6392612 -4.554984  14.797959 ]] [1.5244485e-07]\n",
      "[[1.7994399e-10 2.5945082e-09 2.6955933e-09 1.0000000e+00]] [[-7.369571  -4.7010646 -4.662842  15.068805 ]] [1.0851923e-07]\n",
      "[[1.2085707e-10 1.8498135e-09 1.8306527e-09 1.0000000e+00]] [[-7.496117 -4.767885 -4.778298 15.340296]] [7.678649e-08]\n",
      "[[1.0000000e-10 1.3120195e-09 1.2364675e-09 1.0000000e+00]] [[-7.624906  -4.8356895 -4.895     15.616008 ]] [5.4496805e-08]\n",
      "[[1.0000000e-10 9.2662616e-10 8.3313562e-10 1.0000000e+00]] [[-7.7617755 -4.901105  -5.007459  15.898366 ]] [3.8993306e-08]\n",
      "[[1.0000000e-10 6.5061762e-10 5.5788535e-10 1.0000000e+00]] [[-7.9019    -4.9675484 -5.1213174 16.18555  ]] [2.7951952e-08]\n",
      "[[1.0000000e-10 4.5416185e-10 3.7106374e-10 1.0000000e+00]] [[-8.044103  -5.0354915 -5.237572  16.477076 ]] [2.013029e-08]\n",
      "[[1.0000000e-10 3.1485944e-10 2.4509869e-10 1.0000000e+00]] [[-8.19257   -5.1031694 -5.3536363 16.775724 ]] [1.4615239e-08]\n",
      "[[1.0000000e-10 2.1576851e-10 1.5958612e-10 1.0000000e+00]] [[-8.341137  -5.1764107 -5.4780326 17.080404 ]] [1.0704919e-08]\n",
      "[[1.0000000e-10 2.7338509e-10 2.7492086e-10 1.0000000e+00]] [[-7.7756443 -5.1027923 -5.097191  16.917347 ]] [1.4374819e-08]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-6.7563868 -6.275565  -6.350596  16.96382  ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-7.953463  -6.3233447 -5.4030385 17.687654 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-7.9620533 -6.313654  -5.4039946 17.703564 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-7.973607  -6.311997  -5.4132996 17.726862 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.0055485 -6.3636346 -5.4835587 17.7916   ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.051094  -6.4109993 -5.5479445 17.85827  ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.092654  -6.4553804 -5.609575  17.914589 ]] [6.9077553e-09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.1201105 -6.50337   -5.672362  17.94848  ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.145108  -6.528775  -5.7296624 17.992054 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.167099 -6.545199 -5.765886 18.03469 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.182697  -6.556741  -5.7976327 18.064957 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.197754  -6.567313  -5.8312325 18.093739 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.203061 -6.570788 -5.856919 18.104193]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.1937065 -6.5655227 -5.8702955 18.08938  ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.174487  -6.556907  -5.8819084 18.080278 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.16263  -6.55955  -5.899492 18.095003]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.151593 -6.564656 -5.920339 18.11616 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.151011  -6.5771217 -5.944804  18.154682 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.145868  -6.58115   -5.9515905 18.160746 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.144219  -6.588806  -5.9613576 18.175268 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.130207  -6.587171  -5.9618382 18.162245 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.130657 -6.600775 -5.971305 18.182644]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.974405  -5.548584  -5.6549516 17.830238 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.027713  -6.5234637 -5.9208026 17.985353 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.011545  -6.521422  -5.9170604 17.963678 ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.023139  -6.5440445 -5.92752   17.99039  ]] [6.9077553e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-8.094924 -6.524616 -5.915983 18.012434]] [6.9077553e-09]\n",
      "[[1.0000000e-10 1.0688388e-10 1.0000000e-10 1.0000000e+00]] [[-8.795697  -5.4760466 -5.5909786 17.48323  ]] [7.059146e-09]\n",
      "[[1.e-10 1.e-10 1.e-10 1.e+00]] [[-7.9798875 -6.393459  -5.837655  17.74079  ]] [6.9077553e-09]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-1f389392a490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-97-630d273924f7>\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mobs_curr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_rsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_encr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_dscr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/gym/core.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/gym/envs/box2d/lunar_lander.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwindow_closed_by_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_window\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/gl/xlib.py\u001b[0m in \u001b[0;36mdestroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdestroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibContext13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglx_window\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mglx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglXDestroyWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglx_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/gl/base.py\u001b[0m in \u001b[0;36mdestroy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;31m# Switch back to shadow context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shadow_window\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 \u001b[0mgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shadow_window\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete_texture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexture_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/window/xlib/__init__.py\u001b[0m in \u001b[0;36mswitch_to\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/gl/xlib.py\u001b[0m in \u001b[0;36mset_current\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    326\u001b[0m         glx.glXMakeContextCurrent(\n\u001b[1;32m    327\u001b[0m             self.x_display, self.glx_window, self.glx_window, self.glx_context)\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXlibContext13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/gl/base.py\u001b[0m in \u001b[0;36mset_current\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mgl_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_active_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mglu_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_active_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/gl/gl_info.py\u001b[0m in \u001b[0;36mset_active_context\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m                          c_char_p).value).split()\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_have_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ind_study_project/.env/lib/python3.5/site-packages/pyglet/gl/gl_info.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0mglGetIntegerv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGL_NUM_EXTENSIONS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_extensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 self.extensions = (asstr(cast(glGetStringi(GL_EXTENSIONS, i),\n\u001b[0;32m--> 103\u001b[0;31m                                          c_char_p).value) for i in range(num_extensions.value))\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 self.extensions = asstr(cast(glGetString(GL_EXTENSIONS),\n",
      "\u001b[0;32m/usr/local/lib/python3.5/ctypes/__init__.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(obj, typ)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0m_cast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPYFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpy_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0m_string_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPYFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_void_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_string_at_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True: handler.play(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
